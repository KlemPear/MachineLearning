{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disaster Tweets\n",
    "\n",
    "Classify tweets about disasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import L2\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../datasets/disaster_tweets/train.csv')\n",
    "df = df[['text', 'target']]\n",
    "df = df.rename(columns={\"target\": \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Our Deeds are the Reason of this #earthquake M...      1\n",
       "1             Forest fire near La Ronge Sask. Canada      1\n",
       "2  All residents asked to 'shelter in place' are ...      1\n",
       "3  13,000 people receive #wildfires evacuation or...      1\n",
       "4  Just got sent this photo from Ruby #Alaska as ...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['label'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 1500\n",
    "df_train, df_test = train_test_split(df, random_state=42)\n",
    "vectorizer = CountVectorizer(max_features=max_features)\n",
    "X_train = vectorizer.fit_transform(df_train['text'])\n",
    "X_test = vectorizer.transform(df_test['text'])\n",
    "\n",
    "# data must not be sparse matrix before passing into tensorflow\n",
    "X_train = X_train.toarray()\n",
    "X_test = X_test.toarray()\n",
    "\n",
    "Y_train = np.array(df_train['label'])\n",
    "Y_test = np.array(df_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_45 (Dense)            (None, 1)                 1501      \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,503\n",
      "Trainable params: 1,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.7019 - binary_accuracy: 0.5695 - val_loss: 0.6995 - val_binary_accuracy: 0.5730\n",
      "Epoch 2/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.7007 - binary_accuracy: 0.5695 - val_loss: 0.6984 - val_binary_accuracy: 0.5730\n",
      "Epoch 3/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6995 - binary_accuracy: 0.5695 - val_loss: 0.6974 - val_binary_accuracy: 0.5730\n",
      "Epoch 4/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6984 - binary_accuracy: 0.5695 - val_loss: 0.6964 - val_binary_accuracy: 0.5730\n",
      "Epoch 5/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6973 - binary_accuracy: 0.5695 - val_loss: 0.6954 - val_binary_accuracy: 0.5730\n",
      "Epoch 6/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6963 - binary_accuracy: 0.5695 - val_loss: 0.6945 - val_binary_accuracy: 0.5730\n",
      "Epoch 7/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6952 - binary_accuracy: 0.5695 - val_loss: 0.6936 - val_binary_accuracy: 0.5730\n",
      "Epoch 8/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6941 - binary_accuracy: 0.5695 - val_loss: 0.6926 - val_binary_accuracy: 0.5730\n",
      "Epoch 9/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6931 - binary_accuracy: 0.5695 - val_loss: 0.6917 - val_binary_accuracy: 0.5730\n",
      "Epoch 10/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6920 - binary_accuracy: 0.5695 - val_loss: 0.6907 - val_binary_accuracy: 0.5730\n",
      "Epoch 11/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6910 - binary_accuracy: 0.5695 - val_loss: 0.6898 - val_binary_accuracy: 0.5730\n",
      "Epoch 12/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6900 - binary_accuracy: 0.5695 - val_loss: 0.6889 - val_binary_accuracy: 0.5730\n",
      "Epoch 13/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6890 - binary_accuracy: 0.5695 - val_loss: 0.6880 - val_binary_accuracy: 0.5730\n",
      "Epoch 14/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6879 - binary_accuracy: 0.5695 - val_loss: 0.6870 - val_binary_accuracy: 0.5730\n",
      "Epoch 15/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6869 - binary_accuracy: 0.5695 - val_loss: 0.6861 - val_binary_accuracy: 0.5730\n",
      "Epoch 16/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6859 - binary_accuracy: 0.5695 - val_loss: 0.6852 - val_binary_accuracy: 0.5730\n",
      "Epoch 17/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6849 - binary_accuracy: 0.5695 - val_loss: 0.6843 - val_binary_accuracy: 0.5730\n",
      "Epoch 18/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6839 - binary_accuracy: 0.5695 - val_loss: 0.6834 - val_binary_accuracy: 0.5730\n",
      "Epoch 19/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6829 - binary_accuracy: 0.5695 - val_loss: 0.6825 - val_binary_accuracy: 0.5730\n",
      "Epoch 20/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6819 - binary_accuracy: 0.5695 - val_loss: 0.6817 - val_binary_accuracy: 0.5730\n",
      "Epoch 21/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6809 - binary_accuracy: 0.5695 - val_loss: 0.6808 - val_binary_accuracy: 0.5730\n",
      "Epoch 22/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6800 - binary_accuracy: 0.5695 - val_loss: 0.6800 - val_binary_accuracy: 0.5730\n",
      "Epoch 23/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6790 - binary_accuracy: 0.5695 - val_loss: 0.6791 - val_binary_accuracy: 0.5730\n",
      "Epoch 24/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6780 - binary_accuracy: 0.5695 - val_loss: 0.6783 - val_binary_accuracy: 0.5730\n",
      "Epoch 25/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6771 - binary_accuracy: 0.5695 - val_loss: 0.6774 - val_binary_accuracy: 0.5730\n",
      "Epoch 26/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6761 - binary_accuracy: 0.5695 - val_loss: 0.6765 - val_binary_accuracy: 0.5730\n",
      "Epoch 27/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6751 - binary_accuracy: 0.5695 - val_loss: 0.6757 - val_binary_accuracy: 0.5730\n",
      "Epoch 28/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6742 - binary_accuracy: 0.5695 - val_loss: 0.6749 - val_binary_accuracy: 0.5730\n",
      "Epoch 29/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6732 - binary_accuracy: 0.5695 - val_loss: 0.6740 - val_binary_accuracy: 0.5730\n",
      "Epoch 30/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6723 - binary_accuracy: 0.5695 - val_loss: 0.6732 - val_binary_accuracy: 0.5730\n",
      "Epoch 31/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6714 - binary_accuracy: 0.5695 - val_loss: 0.6723 - val_binary_accuracy: 0.5730\n",
      "Epoch 32/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6704 - binary_accuracy: 0.5695 - val_loss: 0.6715 - val_binary_accuracy: 0.5730\n",
      "Epoch 33/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6695 - binary_accuracy: 0.5695 - val_loss: 0.6707 - val_binary_accuracy: 0.5730\n",
      "Epoch 34/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6686 - binary_accuracy: 0.5695 - val_loss: 0.6699 - val_binary_accuracy: 0.5730\n",
      "Epoch 35/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6677 - binary_accuracy: 0.5695 - val_loss: 0.6691 - val_binary_accuracy: 0.5730\n",
      "Epoch 36/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6667 - binary_accuracy: 0.5695 - val_loss: 0.6683 - val_binary_accuracy: 0.5730\n",
      "Epoch 37/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6658 - binary_accuracy: 0.5696 - val_loss: 0.6675 - val_binary_accuracy: 0.5730\n",
      "Epoch 38/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6649 - binary_accuracy: 0.5696 - val_loss: 0.6667 - val_binary_accuracy: 0.5730\n",
      "Epoch 39/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6641 - binary_accuracy: 0.5696 - val_loss: 0.6659 - val_binary_accuracy: 0.5730\n",
      "Epoch 40/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6632 - binary_accuracy: 0.5696 - val_loss: 0.6652 - val_binary_accuracy: 0.5730\n",
      "Epoch 41/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6623 - binary_accuracy: 0.5696 - val_loss: 0.6644 - val_binary_accuracy: 0.5730\n",
      "Epoch 42/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6614 - binary_accuracy: 0.5696 - val_loss: 0.6636 - val_binary_accuracy: 0.5730\n",
      "Epoch 43/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6606 - binary_accuracy: 0.5696 - val_loss: 0.6629 - val_binary_accuracy: 0.5730\n",
      "Epoch 44/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6597 - binary_accuracy: 0.5696 - val_loss: 0.6622 - val_binary_accuracy: 0.5730\n",
      "Epoch 45/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6588 - binary_accuracy: 0.5696 - val_loss: 0.6614 - val_binary_accuracy: 0.5730\n",
      "Epoch 46/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6580 - binary_accuracy: 0.5696 - val_loss: 0.6607 - val_binary_accuracy: 0.5730\n",
      "Epoch 47/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6571 - binary_accuracy: 0.5696 - val_loss: 0.6599 - val_binary_accuracy: 0.5730\n",
      "Epoch 48/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6563 - binary_accuracy: 0.5696 - val_loss: 0.6592 - val_binary_accuracy: 0.5730\n",
      "Epoch 49/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6555 - binary_accuracy: 0.5696 - val_loss: 0.6585 - val_binary_accuracy: 0.5730\n",
      "Epoch 50/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6546 - binary_accuracy: 0.5696 - val_loss: 0.6578 - val_binary_accuracy: 0.5730\n",
      "Epoch 51/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6538 - binary_accuracy: 0.5696 - val_loss: 0.6570 - val_binary_accuracy: 0.5730\n",
      "Epoch 52/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6529 - binary_accuracy: 0.5698 - val_loss: 0.6563 - val_binary_accuracy: 0.5730\n",
      "Epoch 53/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6521 - binary_accuracy: 0.5698 - val_loss: 0.6556 - val_binary_accuracy: 0.5730\n",
      "Epoch 54/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6513 - binary_accuracy: 0.5700 - val_loss: 0.6549 - val_binary_accuracy: 0.5730\n",
      "Epoch 55/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6505 - binary_accuracy: 0.5702 - val_loss: 0.6542 - val_binary_accuracy: 0.5746\n",
      "Epoch 56/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6497 - binary_accuracy: 0.5705 - val_loss: 0.6535 - val_binary_accuracy: 0.5746\n",
      "Epoch 57/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6489 - binary_accuracy: 0.5705 - val_loss: 0.6528 - val_binary_accuracy: 0.5746\n",
      "Epoch 58/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6481 - binary_accuracy: 0.5707 - val_loss: 0.6522 - val_binary_accuracy: 0.5751\n",
      "Epoch 59/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6473 - binary_accuracy: 0.5709 - val_loss: 0.6515 - val_binary_accuracy: 0.5762\n",
      "Epoch 60/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6465 - binary_accuracy: 0.5719 - val_loss: 0.6508 - val_binary_accuracy: 0.5762\n",
      "Epoch 61/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6457 - binary_accuracy: 0.5719 - val_loss: 0.6502 - val_binary_accuracy: 0.5762\n",
      "Epoch 62/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6450 - binary_accuracy: 0.5723 - val_loss: 0.6495 - val_binary_accuracy: 0.5762\n",
      "Epoch 63/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6442 - binary_accuracy: 0.5728 - val_loss: 0.6489 - val_binary_accuracy: 0.5762\n",
      "Epoch 64/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6434 - binary_accuracy: 0.5730 - val_loss: 0.6482 - val_binary_accuracy: 0.5762\n",
      "Epoch 65/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6427 - binary_accuracy: 0.5737 - val_loss: 0.6476 - val_binary_accuracy: 0.5767\n",
      "Epoch 66/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6419 - binary_accuracy: 0.5737 - val_loss: 0.6469 - val_binary_accuracy: 0.5767\n",
      "Epoch 67/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6412 - binary_accuracy: 0.5740 - val_loss: 0.6463 - val_binary_accuracy: 0.5767\n",
      "Epoch 68/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6404 - binary_accuracy: 0.5742 - val_loss: 0.6457 - val_binary_accuracy: 0.5772\n",
      "Epoch 69/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6397 - binary_accuracy: 0.5744 - val_loss: 0.6450 - val_binary_accuracy: 0.5777\n",
      "Epoch 70/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6389 - binary_accuracy: 0.5744 - val_loss: 0.6444 - val_binary_accuracy: 0.5777\n",
      "Epoch 71/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6382 - binary_accuracy: 0.5744 - val_loss: 0.6438 - val_binary_accuracy: 0.5777\n",
      "Epoch 72/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6375 - binary_accuracy: 0.5751 - val_loss: 0.6432 - val_binary_accuracy: 0.5783\n",
      "Epoch 73/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6368 - binary_accuracy: 0.5756 - val_loss: 0.6426 - val_binary_accuracy: 0.5804\n",
      "Epoch 74/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6361 - binary_accuracy: 0.5761 - val_loss: 0.6420 - val_binary_accuracy: 0.5804\n",
      "Epoch 75/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6353 - binary_accuracy: 0.5779 - val_loss: 0.6414 - val_binary_accuracy: 0.5809\n",
      "Epoch 76/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6346 - binary_accuracy: 0.5786 - val_loss: 0.6409 - val_binary_accuracy: 0.5819\n",
      "Epoch 77/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6339 - binary_accuracy: 0.5789 - val_loss: 0.6403 - val_binary_accuracy: 0.5819\n",
      "Epoch 78/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6332 - binary_accuracy: 0.5794 - val_loss: 0.6397 - val_binary_accuracy: 0.5825\n",
      "Epoch 79/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6325 - binary_accuracy: 0.5805 - val_loss: 0.6391 - val_binary_accuracy: 0.5830\n",
      "Epoch 80/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6319 - binary_accuracy: 0.5807 - val_loss: 0.6386 - val_binary_accuracy: 0.5835\n",
      "Epoch 81/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6312 - binary_accuracy: 0.5833 - val_loss: 0.6380 - val_binary_accuracy: 0.5867\n",
      "Epoch 82/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6305 - binary_accuracy: 0.5843 - val_loss: 0.6374 - val_binary_accuracy: 0.5867\n",
      "Epoch 83/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6298 - binary_accuracy: 0.5845 - val_loss: 0.6369 - val_binary_accuracy: 0.5867\n",
      "Epoch 84/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6292 - binary_accuracy: 0.5852 - val_loss: 0.6363 - val_binary_accuracy: 0.5867\n",
      "Epoch 85/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6285 - binary_accuracy: 0.5873 - val_loss: 0.6358 - val_binary_accuracy: 0.5877\n",
      "Epoch 86/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6278 - binary_accuracy: 0.5910 - val_loss: 0.6352 - val_binary_accuracy: 0.5909\n",
      "Epoch 87/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6271 - binary_accuracy: 0.5927 - val_loss: 0.6347 - val_binary_accuracy: 0.5924\n",
      "Epoch 88/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6265 - binary_accuracy: 0.5941 - val_loss: 0.6342 - val_binary_accuracy: 0.5945\n",
      "Epoch 89/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6258 - binary_accuracy: 0.5957 - val_loss: 0.6337 - val_binary_accuracy: 0.5956\n",
      "Epoch 90/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6252 - binary_accuracy: 0.5977 - val_loss: 0.6331 - val_binary_accuracy: 0.5966\n",
      "Epoch 91/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6246 - binary_accuracy: 0.5985 - val_loss: 0.6326 - val_binary_accuracy: 0.5972\n",
      "Epoch 92/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6239 - binary_accuracy: 0.5998 - val_loss: 0.6321 - val_binary_accuracy: 0.5977\n",
      "Epoch 93/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6233 - binary_accuracy: 0.6006 - val_loss: 0.6316 - val_binary_accuracy: 0.5982\n",
      "Epoch 94/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6227 - binary_accuracy: 0.6012 - val_loss: 0.6310 - val_binary_accuracy: 0.5982\n",
      "Epoch 95/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6221 - binary_accuracy: 0.6043 - val_loss: 0.6305 - val_binary_accuracy: 0.6003\n",
      "Epoch 96/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6214 - binary_accuracy: 0.6057 - val_loss: 0.6300 - val_binary_accuracy: 0.6008\n",
      "Epoch 97/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6208 - binary_accuracy: 0.6080 - val_loss: 0.6295 - val_binary_accuracy: 0.6019\n",
      "Epoch 98/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6202 - binary_accuracy: 0.6090 - val_loss: 0.6290 - val_binary_accuracy: 0.6024\n",
      "Epoch 99/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6196 - binary_accuracy: 0.6094 - val_loss: 0.6286 - val_binary_accuracy: 0.6024\n",
      "Epoch 100/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6190 - binary_accuracy: 0.6097 - val_loss: 0.6281 - val_binary_accuracy: 0.6035\n",
      "Epoch 101/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6184 - binary_accuracy: 0.6104 - val_loss: 0.6276 - val_binary_accuracy: 0.6040\n",
      "Epoch 102/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6179 - binary_accuracy: 0.6113 - val_loss: 0.6271 - val_binary_accuracy: 0.6040\n",
      "Epoch 103/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6173 - binary_accuracy: 0.6115 - val_loss: 0.6267 - val_binary_accuracy: 0.6045\n",
      "Epoch 104/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6167 - binary_accuracy: 0.6127 - val_loss: 0.6262 - val_binary_accuracy: 0.6056\n",
      "Epoch 105/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6161 - binary_accuracy: 0.6136 - val_loss: 0.6258 - val_binary_accuracy: 0.6061\n",
      "Epoch 106/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6156 - binary_accuracy: 0.6141 - val_loss: 0.6253 - val_binary_accuracy: 0.6087\n",
      "Epoch 107/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6150 - binary_accuracy: 0.6160 - val_loss: 0.6249 - val_binary_accuracy: 0.6092\n",
      "Epoch 108/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6144 - binary_accuracy: 0.6178 - val_loss: 0.6244 - val_binary_accuracy: 0.6140\n",
      "Epoch 109/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6139 - binary_accuracy: 0.6224 - val_loss: 0.6240 - val_binary_accuracy: 0.6150\n",
      "Epoch 110/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6133 - binary_accuracy: 0.6234 - val_loss: 0.6236 - val_binary_accuracy: 0.6150\n",
      "Epoch 111/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6128 - binary_accuracy: 0.6250 - val_loss: 0.6231 - val_binary_accuracy: 0.6161\n",
      "Epoch 112/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6122 - binary_accuracy: 0.6266 - val_loss: 0.6227 - val_binary_accuracy: 0.6166\n",
      "Epoch 113/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6117 - binary_accuracy: 0.6271 - val_loss: 0.6223 - val_binary_accuracy: 0.6176\n",
      "Epoch 114/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6111 - binary_accuracy: 0.6280 - val_loss: 0.6219 - val_binary_accuracy: 0.6192\n",
      "Epoch 115/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6106 - binary_accuracy: 0.6292 - val_loss: 0.6215 - val_binary_accuracy: 0.6208\n",
      "Epoch 116/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6101 - binary_accuracy: 0.6299 - val_loss: 0.6210 - val_binary_accuracy: 0.6208\n",
      "Epoch 117/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6095 - binary_accuracy: 0.6306 - val_loss: 0.6206 - val_binary_accuracy: 0.6208\n",
      "Epoch 118/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6090 - binary_accuracy: 0.6308 - val_loss: 0.6202 - val_binary_accuracy: 0.6213\n",
      "Epoch 119/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6085 - binary_accuracy: 0.6313 - val_loss: 0.6198 - val_binary_accuracy: 0.6224\n",
      "Epoch 120/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6080 - binary_accuracy: 0.6323 - val_loss: 0.6194 - val_binary_accuracy: 0.6229\n",
      "Epoch 121/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6074 - binary_accuracy: 0.6329 - val_loss: 0.6190 - val_binary_accuracy: 0.6229\n",
      "Epoch 122/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6069 - binary_accuracy: 0.6334 - val_loss: 0.6186 - val_binary_accuracy: 0.6250\n",
      "Epoch 123/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6064 - binary_accuracy: 0.6337 - val_loss: 0.6182 - val_binary_accuracy: 0.6261\n",
      "Epoch 124/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6346 - val_loss: 0.6178 - val_binary_accuracy: 0.6271\n",
      "Epoch 125/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6054 - binary_accuracy: 0.6358 - val_loss: 0.6174 - val_binary_accuracy: 0.6276\n",
      "Epoch 126/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6049 - binary_accuracy: 0.6365 - val_loss: 0.6170 - val_binary_accuracy: 0.6276\n",
      "Epoch 127/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6044 - binary_accuracy: 0.6392 - val_loss: 0.6166 - val_binary_accuracy: 0.6287\n",
      "Epoch 128/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6039 - binary_accuracy: 0.6404 - val_loss: 0.6163 - val_binary_accuracy: 0.6287\n",
      "Epoch 129/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6034 - binary_accuracy: 0.6420 - val_loss: 0.6159 - val_binary_accuracy: 0.6297\n",
      "Epoch 130/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6029 - binary_accuracy: 0.6430 - val_loss: 0.6155 - val_binary_accuracy: 0.6303\n",
      "Epoch 131/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6024 - binary_accuracy: 0.6439 - val_loss: 0.6151 - val_binary_accuracy: 0.6308\n",
      "Epoch 132/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6020 - binary_accuracy: 0.6451 - val_loss: 0.6147 - val_binary_accuracy: 0.6329\n",
      "Epoch 133/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6015 - binary_accuracy: 0.6458 - val_loss: 0.6144 - val_binary_accuracy: 0.6329\n",
      "Epoch 134/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6010 - binary_accuracy: 0.6467 - val_loss: 0.6140 - val_binary_accuracy: 0.6345\n",
      "Epoch 135/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6005 - binary_accuracy: 0.6477 - val_loss: 0.6137 - val_binary_accuracy: 0.6345\n",
      "Epoch 136/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6001 - binary_accuracy: 0.6488 - val_loss: 0.6133 - val_binary_accuracy: 0.6360\n",
      "Epoch 137/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5996 - binary_accuracy: 0.6499 - val_loss: 0.6129 - val_binary_accuracy: 0.6360\n",
      "Epoch 138/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5991 - binary_accuracy: 0.6507 - val_loss: 0.6126 - val_binary_accuracy: 0.6371\n",
      "Epoch 139/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5987 - binary_accuracy: 0.6520 - val_loss: 0.6123 - val_binary_accuracy: 0.6376\n",
      "Epoch 140/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5982 - binary_accuracy: 0.6534 - val_loss: 0.6119 - val_binary_accuracy: 0.6371\n",
      "Epoch 141/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5978 - binary_accuracy: 0.6542 - val_loss: 0.6116 - val_binary_accuracy: 0.6381\n",
      "Epoch 142/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5974 - binary_accuracy: 0.6546 - val_loss: 0.6113 - val_binary_accuracy: 0.6392\n",
      "Epoch 143/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5969 - binary_accuracy: 0.6555 - val_loss: 0.6109 - val_binary_accuracy: 0.6402\n",
      "Epoch 144/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5965 - binary_accuracy: 0.6597 - val_loss: 0.6106 - val_binary_accuracy: 0.6439\n",
      "Epoch 145/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5960 - binary_accuracy: 0.6611 - val_loss: 0.6102 - val_binary_accuracy: 0.6439\n",
      "Epoch 146/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5956 - binary_accuracy: 0.6616 - val_loss: 0.6099 - val_binary_accuracy: 0.6444\n",
      "Epoch 147/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5951 - binary_accuracy: 0.6621 - val_loss: 0.6096 - val_binary_accuracy: 0.6455\n",
      "Epoch 148/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5947 - binary_accuracy: 0.6632 - val_loss: 0.6093 - val_binary_accuracy: 0.6460\n",
      "Epoch 149/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5943 - binary_accuracy: 0.6637 - val_loss: 0.6089 - val_binary_accuracy: 0.6455\n",
      "Epoch 150/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5939 - binary_accuracy: 0.6640 - val_loss: 0.6086 - val_binary_accuracy: 0.6471\n",
      "Epoch 151/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5935 - binary_accuracy: 0.6649 - val_loss: 0.6083 - val_binary_accuracy: 0.6476\n",
      "Epoch 152/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5931 - binary_accuracy: 0.6656 - val_loss: 0.6080 - val_binary_accuracy: 0.6476\n",
      "Epoch 153/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5926 - binary_accuracy: 0.6670 - val_loss: 0.6077 - val_binary_accuracy: 0.6476\n",
      "Epoch 154/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5922 - binary_accuracy: 0.6677 - val_loss: 0.6074 - val_binary_accuracy: 0.6481\n",
      "Epoch 155/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5918 - binary_accuracy: 0.6682 - val_loss: 0.6071 - val_binary_accuracy: 0.6481\n",
      "Epoch 156/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5914 - binary_accuracy: 0.6691 - val_loss: 0.6068 - val_binary_accuracy: 0.6502\n",
      "Epoch 157/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5910 - binary_accuracy: 0.6712 - val_loss: 0.6066 - val_binary_accuracy: 0.6513\n",
      "Epoch 158/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5906 - binary_accuracy: 0.6717 - val_loss: 0.6063 - val_binary_accuracy: 0.6523\n",
      "Epoch 159/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5902 - binary_accuracy: 0.6724 - val_loss: 0.6060 - val_binary_accuracy: 0.6528\n",
      "Epoch 160/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5898 - binary_accuracy: 0.6733 - val_loss: 0.6057 - val_binary_accuracy: 0.6539\n",
      "Epoch 161/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5894 - binary_accuracy: 0.6754 - val_loss: 0.6054 - val_binary_accuracy: 0.6565\n",
      "Epoch 162/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5891 - binary_accuracy: 0.6761 - val_loss: 0.6051 - val_binary_accuracy: 0.6586\n",
      "Epoch 163/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5887 - binary_accuracy: 0.6774 - val_loss: 0.6048 - val_binary_accuracy: 0.6597\n",
      "Epoch 164/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5883 - binary_accuracy: 0.6779 - val_loss: 0.6045 - val_binary_accuracy: 0.6607\n",
      "Epoch 165/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5879 - binary_accuracy: 0.6793 - val_loss: 0.6043 - val_binary_accuracy: 0.6607\n",
      "Epoch 166/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5875 - binary_accuracy: 0.6795 - val_loss: 0.6040 - val_binary_accuracy: 0.6628\n",
      "Epoch 167/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5872 - binary_accuracy: 0.6802 - val_loss: 0.6037 - val_binary_accuracy: 0.6628\n",
      "Epoch 168/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5868 - binary_accuracy: 0.6809 - val_loss: 0.6034 - val_binary_accuracy: 0.6628\n",
      "Epoch 169/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5864 - binary_accuracy: 0.6816 - val_loss: 0.6031 - val_binary_accuracy: 0.6633\n",
      "Epoch 170/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5860 - binary_accuracy: 0.6823 - val_loss: 0.6029 - val_binary_accuracy: 0.6644\n",
      "Epoch 171/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5857 - binary_accuracy: 0.6831 - val_loss: 0.6026 - val_binary_accuracy: 0.6649\n",
      "Epoch 172/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5853 - binary_accuracy: 0.6835 - val_loss: 0.6023 - val_binary_accuracy: 0.6649\n",
      "Epoch 173/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5849 - binary_accuracy: 0.6838 - val_loss: 0.6021 - val_binary_accuracy: 0.6660\n",
      "Epoch 174/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5846 - binary_accuracy: 0.6844 - val_loss: 0.6019 - val_binary_accuracy: 0.6665\n",
      "Epoch 175/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5842 - binary_accuracy: 0.6851 - val_loss: 0.6016 - val_binary_accuracy: 0.6675\n",
      "Epoch 176/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5839 - binary_accuracy: 0.6861 - val_loss: 0.6014 - val_binary_accuracy: 0.6696\n",
      "Epoch 177/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5835 - binary_accuracy: 0.6870 - val_loss: 0.6011 - val_binary_accuracy: 0.6707\n",
      "Epoch 178/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5831 - binary_accuracy: 0.6882 - val_loss: 0.6009 - val_binary_accuracy: 0.6702\n",
      "Epoch 179/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5828 - binary_accuracy: 0.6882 - val_loss: 0.6006 - val_binary_accuracy: 0.6702\n",
      "Epoch 180/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5824 - binary_accuracy: 0.6882 - val_loss: 0.6003 - val_binary_accuracy: 0.6707\n",
      "Epoch 181/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5821 - binary_accuracy: 0.6889 - val_loss: 0.6001 - val_binary_accuracy: 0.6707\n",
      "Epoch 182/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5817 - binary_accuracy: 0.6889 - val_loss: 0.5998 - val_binary_accuracy: 0.6712\n",
      "Epoch 183/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5814 - binary_accuracy: 0.6898 - val_loss: 0.5996 - val_binary_accuracy: 0.6712\n",
      "Epoch 184/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5811 - binary_accuracy: 0.6905 - val_loss: 0.5994 - val_binary_accuracy: 0.6717\n",
      "Epoch 185/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5807 - binary_accuracy: 0.6905 - val_loss: 0.5991 - val_binary_accuracy: 0.6744\n",
      "Epoch 186/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5804 - binary_accuracy: 0.6908 - val_loss: 0.5989 - val_binary_accuracy: 0.6765\n",
      "Epoch 187/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5801 - binary_accuracy: 0.6922 - val_loss: 0.5987 - val_binary_accuracy: 0.6770\n",
      "Epoch 188/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5797 - binary_accuracy: 0.6924 - val_loss: 0.5984 - val_binary_accuracy: 0.6770\n",
      "Epoch 189/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5794 - binary_accuracy: 0.6926 - val_loss: 0.5982 - val_binary_accuracy: 0.6775\n",
      "Epoch 190/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5791 - binary_accuracy: 0.6949 - val_loss: 0.5980 - val_binary_accuracy: 0.6780\n",
      "Epoch 191/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5787 - binary_accuracy: 0.6950 - val_loss: 0.5977 - val_binary_accuracy: 0.6796\n",
      "Epoch 192/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5784 - binary_accuracy: 0.6956 - val_loss: 0.5975 - val_binary_accuracy: 0.6796\n",
      "Epoch 193/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5781 - binary_accuracy: 0.6963 - val_loss: 0.5973 - val_binary_accuracy: 0.6801\n",
      "Epoch 194/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5778 - binary_accuracy: 0.6966 - val_loss: 0.5971 - val_binary_accuracy: 0.6812\n",
      "Epoch 195/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5775 - binary_accuracy: 0.6975 - val_loss: 0.5968 - val_binary_accuracy: 0.6822\n",
      "Epoch 196/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5771 - binary_accuracy: 0.6980 - val_loss: 0.5966 - val_binary_accuracy: 0.6833\n",
      "Epoch 197/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5768 - binary_accuracy: 0.6982 - val_loss: 0.5964 - val_binary_accuracy: 0.6843\n",
      "Epoch 198/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5765 - binary_accuracy: 0.6992 - val_loss: 0.5962 - val_binary_accuracy: 0.6854\n",
      "Epoch 199/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5762 - binary_accuracy: 0.7001 - val_loss: 0.5960 - val_binary_accuracy: 0.6859\n",
      "Epoch 200/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5759 - binary_accuracy: 0.7001 - val_loss: 0.5958 - val_binary_accuracy: 0.6859\n",
      "Epoch 201/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5756 - binary_accuracy: 0.7012 - val_loss: 0.5955 - val_binary_accuracy: 0.6864\n",
      "Epoch 202/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5753 - binary_accuracy: 0.7015 - val_loss: 0.5953 - val_binary_accuracy: 0.6864\n",
      "Epoch 203/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5750 - binary_accuracy: 0.7017 - val_loss: 0.5951 - val_binary_accuracy: 0.6875\n",
      "Epoch 204/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5747 - binary_accuracy: 0.7026 - val_loss: 0.5949 - val_binary_accuracy: 0.6875\n",
      "Epoch 205/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5744 - binary_accuracy: 0.7036 - val_loss: 0.5947 - val_binary_accuracy: 0.6875\n",
      "Epoch 206/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5741 - binary_accuracy: 0.7045 - val_loss: 0.5945 - val_binary_accuracy: 0.6880\n",
      "Epoch 207/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5738 - binary_accuracy: 0.7049 - val_loss: 0.5943 - val_binary_accuracy: 0.6886\n",
      "Epoch 208/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5735 - binary_accuracy: 0.7052 - val_loss: 0.5941 - val_binary_accuracy: 0.6891\n",
      "Epoch 209/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5732 - binary_accuracy: 0.7056 - val_loss: 0.5939 - val_binary_accuracy: 0.6891\n",
      "Epoch 210/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5729 - binary_accuracy: 0.7056 - val_loss: 0.5937 - val_binary_accuracy: 0.6901\n",
      "Epoch 211/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5726 - binary_accuracy: 0.7059 - val_loss: 0.5935 - val_binary_accuracy: 0.6907\n",
      "Epoch 212/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5724 - binary_accuracy: 0.7066 - val_loss: 0.5933 - val_binary_accuracy: 0.6922\n",
      "Epoch 213/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5721 - binary_accuracy: 0.7068 - val_loss: 0.5931 - val_binary_accuracy: 0.6928\n",
      "Epoch 214/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5718 - binary_accuracy: 0.7068 - val_loss: 0.5929 - val_binary_accuracy: 0.6928\n",
      "Epoch 215/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5715 - binary_accuracy: 0.7071 - val_loss: 0.5927 - val_binary_accuracy: 0.6933\n",
      "Epoch 216/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5713 - binary_accuracy: 0.7075 - val_loss: 0.5925 - val_binary_accuracy: 0.6933\n",
      "Epoch 217/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5710 - binary_accuracy: 0.7080 - val_loss: 0.5924 - val_binary_accuracy: 0.6933\n",
      "Epoch 218/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5707 - binary_accuracy: 0.7080 - val_loss: 0.5922 - val_binary_accuracy: 0.6938\n",
      "Epoch 219/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5704 - binary_accuracy: 0.7082 - val_loss: 0.5920 - val_binary_accuracy: 0.6938\n",
      "Epoch 220/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5701 - binary_accuracy: 0.7091 - val_loss: 0.5918 - val_binary_accuracy: 0.6938\n",
      "Epoch 221/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5699 - binary_accuracy: 0.7098 - val_loss: 0.5916 - val_binary_accuracy: 0.6938\n",
      "Epoch 222/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5696 - binary_accuracy: 0.7103 - val_loss: 0.5914 - val_binary_accuracy: 0.6943\n",
      "Epoch 223/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5693 - binary_accuracy: 0.7115 - val_loss: 0.5912 - val_binary_accuracy: 0.6970\n",
      "Epoch 224/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5691 - binary_accuracy: 0.7120 - val_loss: 0.5911 - val_binary_accuracy: 0.6975\n",
      "Epoch 225/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5688 - binary_accuracy: 0.7122 - val_loss: 0.5909 - val_binary_accuracy: 0.6975\n",
      "Epoch 226/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5685 - binary_accuracy: 0.7126 - val_loss: 0.5907 - val_binary_accuracy: 0.6975\n",
      "Epoch 227/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5682 - binary_accuracy: 0.7126 - val_loss: 0.5905 - val_binary_accuracy: 0.6980\n",
      "Epoch 228/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5680 - binary_accuracy: 0.7133 - val_loss: 0.5904 - val_binary_accuracy: 0.6996\n",
      "Epoch 229/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5677 - binary_accuracy: 0.7138 - val_loss: 0.5902 - val_binary_accuracy: 0.6996\n",
      "Epoch 230/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5675 - binary_accuracy: 0.7147 - val_loss: 0.5900 - val_binary_accuracy: 0.7006\n",
      "Epoch 231/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5672 - binary_accuracy: 0.7148 - val_loss: 0.5899 - val_binary_accuracy: 0.7006\n",
      "Epoch 232/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5669 - binary_accuracy: 0.7159 - val_loss: 0.5897 - val_binary_accuracy: 0.7006\n",
      "Epoch 233/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5667 - binary_accuracy: 0.7168 - val_loss: 0.5895 - val_binary_accuracy: 0.7017\n",
      "Epoch 234/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5664 - binary_accuracy: 0.7178 - val_loss: 0.5894 - val_binary_accuracy: 0.7017\n",
      "Epoch 235/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5662 - binary_accuracy: 0.7187 - val_loss: 0.5892 - val_binary_accuracy: 0.7017\n",
      "Epoch 236/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5659 - binary_accuracy: 0.7196 - val_loss: 0.5891 - val_binary_accuracy: 0.7027\n",
      "Epoch 237/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5657 - binary_accuracy: 0.7199 - val_loss: 0.5889 - val_binary_accuracy: 0.7033\n",
      "Epoch 238/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5654 - binary_accuracy: 0.7199 - val_loss: 0.5887 - val_binary_accuracy: 0.7033\n",
      "Epoch 239/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5652 - binary_accuracy: 0.7203 - val_loss: 0.5886 - val_binary_accuracy: 0.7048\n",
      "Epoch 240/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5649 - binary_accuracy: 0.7208 - val_loss: 0.5884 - val_binary_accuracy: 0.7043\n",
      "Epoch 241/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5647 - binary_accuracy: 0.7210 - val_loss: 0.5882 - val_binary_accuracy: 0.7043\n",
      "Epoch 242/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5644 - binary_accuracy: 0.7215 - val_loss: 0.5881 - val_binary_accuracy: 0.7043\n",
      "Epoch 243/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5642 - binary_accuracy: 0.7218 - val_loss: 0.5879 - val_binary_accuracy: 0.7043\n",
      "Epoch 244/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5639 - binary_accuracy: 0.7224 - val_loss: 0.5877 - val_binary_accuracy: 0.7054\n",
      "Epoch 245/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5637 - binary_accuracy: 0.7227 - val_loss: 0.5876 - val_binary_accuracy: 0.7054\n",
      "Epoch 246/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5635 - binary_accuracy: 0.7229 - val_loss: 0.5874 - val_binary_accuracy: 0.7054\n",
      "Epoch 247/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5632 - binary_accuracy: 0.7229 - val_loss: 0.5872 - val_binary_accuracy: 0.7054\n",
      "Epoch 248/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5630 - binary_accuracy: 0.7231 - val_loss: 0.5871 - val_binary_accuracy: 0.7054\n",
      "Epoch 249/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5627 - binary_accuracy: 0.7238 - val_loss: 0.5869 - val_binary_accuracy: 0.7064\n",
      "Epoch 250/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5625 - binary_accuracy: 0.7241 - val_loss: 0.5868 - val_binary_accuracy: 0.7069\n",
      "Epoch 251/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5623 - binary_accuracy: 0.7241 - val_loss: 0.5866 - val_binary_accuracy: 0.7075\n",
      "Epoch 252/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5620 - binary_accuracy: 0.7248 - val_loss: 0.5865 - val_binary_accuracy: 0.7075\n",
      "Epoch 253/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5618 - binary_accuracy: 0.7250 - val_loss: 0.5863 - val_binary_accuracy: 0.7075\n",
      "Epoch 254/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5616 - binary_accuracy: 0.7250 - val_loss: 0.5862 - val_binary_accuracy: 0.7085\n",
      "Epoch 255/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5613 - binary_accuracy: 0.7257 - val_loss: 0.5861 - val_binary_accuracy: 0.7096\n",
      "Epoch 256/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5611 - binary_accuracy: 0.7259 - val_loss: 0.5859 - val_binary_accuracy: 0.7106\n",
      "Epoch 257/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5609 - binary_accuracy: 0.7262 - val_loss: 0.5858 - val_binary_accuracy: 0.7106\n",
      "Epoch 258/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5607 - binary_accuracy: 0.7264 - val_loss: 0.5856 - val_binary_accuracy: 0.7106\n",
      "Epoch 259/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5604 - binary_accuracy: 0.7278 - val_loss: 0.5855 - val_binary_accuracy: 0.7111\n",
      "Epoch 260/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5602 - binary_accuracy: 0.7285 - val_loss: 0.5854 - val_binary_accuracy: 0.7111\n",
      "Epoch 261/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5600 - binary_accuracy: 0.7290 - val_loss: 0.5852 - val_binary_accuracy: 0.7111\n",
      "Epoch 262/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5598 - binary_accuracy: 0.7297 - val_loss: 0.5851 - val_binary_accuracy: 0.7111\n",
      "Epoch 263/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5595 - binary_accuracy: 0.7303 - val_loss: 0.5850 - val_binary_accuracy: 0.7111\n",
      "Epoch 264/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5593 - binary_accuracy: 0.7308 - val_loss: 0.5848 - val_binary_accuracy: 0.7117\n",
      "Epoch 265/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5591 - binary_accuracy: 0.7306 - val_loss: 0.5847 - val_binary_accuracy: 0.7117\n",
      "Epoch 266/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5589 - binary_accuracy: 0.7306 - val_loss: 0.5845 - val_binary_accuracy: 0.7117\n",
      "Epoch 267/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5587 - binary_accuracy: 0.7308 - val_loss: 0.5844 - val_binary_accuracy: 0.7117\n",
      "Epoch 268/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5585 - binary_accuracy: 0.7310 - val_loss: 0.5843 - val_binary_accuracy: 0.7122\n",
      "Epoch 269/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5582 - binary_accuracy: 0.7317 - val_loss: 0.5841 - val_binary_accuracy: 0.7138\n",
      "Epoch 270/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5580 - binary_accuracy: 0.7324 - val_loss: 0.5840 - val_binary_accuracy: 0.7148\n",
      "Epoch 271/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5578 - binary_accuracy: 0.7331 - val_loss: 0.5839 - val_binary_accuracy: 0.7148\n",
      "Epoch 272/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5576 - binary_accuracy: 0.7336 - val_loss: 0.5838 - val_binary_accuracy: 0.7148\n",
      "Epoch 273/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5574 - binary_accuracy: 0.7339 - val_loss: 0.5836 - val_binary_accuracy: 0.7153\n",
      "Epoch 274/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5572 - binary_accuracy: 0.7343 - val_loss: 0.5835 - val_binary_accuracy: 0.7159\n",
      "Epoch 275/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5570 - binary_accuracy: 0.7348 - val_loss: 0.5834 - val_binary_accuracy: 0.7164\n",
      "Epoch 276/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5568 - binary_accuracy: 0.7350 - val_loss: 0.5832 - val_binary_accuracy: 0.7164\n",
      "Epoch 277/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5566 - binary_accuracy: 0.7348 - val_loss: 0.5831 - val_binary_accuracy: 0.7164\n",
      "Epoch 278/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5564 - binary_accuracy: 0.7350 - val_loss: 0.5830 - val_binary_accuracy: 0.7169\n",
      "Epoch 279/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5562 - binary_accuracy: 0.7350 - val_loss: 0.5828 - val_binary_accuracy: 0.7169\n",
      "Epoch 280/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5560 - binary_accuracy: 0.7350 - val_loss: 0.5827 - val_binary_accuracy: 0.7169\n",
      "Epoch 281/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5558 - binary_accuracy: 0.7350 - val_loss: 0.5826 - val_binary_accuracy: 0.7169\n",
      "Epoch 282/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5556 - binary_accuracy: 0.7357 - val_loss: 0.5825 - val_binary_accuracy: 0.7174\n",
      "Epoch 283/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5554 - binary_accuracy: 0.7364 - val_loss: 0.5823 - val_binary_accuracy: 0.7174\n",
      "Epoch 284/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5552 - binary_accuracy: 0.7371 - val_loss: 0.5822 - val_binary_accuracy: 0.7180\n",
      "Epoch 285/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5550 - binary_accuracy: 0.7373 - val_loss: 0.5821 - val_binary_accuracy: 0.7185\n",
      "Epoch 286/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5548 - binary_accuracy: 0.7376 - val_loss: 0.5820 - val_binary_accuracy: 0.7190\n",
      "Epoch 287/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5546 - binary_accuracy: 0.7373 - val_loss: 0.5819 - val_binary_accuracy: 0.7195\n",
      "Epoch 288/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5544 - binary_accuracy: 0.7376 - val_loss: 0.5817 - val_binary_accuracy: 0.7195\n",
      "Epoch 289/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5542 - binary_accuracy: 0.7376 - val_loss: 0.5816 - val_binary_accuracy: 0.7195\n",
      "Epoch 290/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5540 - binary_accuracy: 0.7381 - val_loss: 0.5815 - val_binary_accuracy: 0.7201\n",
      "Epoch 291/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5538 - binary_accuracy: 0.7383 - val_loss: 0.5814 - val_binary_accuracy: 0.7195\n",
      "Epoch 292/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5536 - binary_accuracy: 0.7388 - val_loss: 0.5813 - val_binary_accuracy: 0.7195\n",
      "Epoch 293/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5534 - binary_accuracy: 0.7390 - val_loss: 0.5811 - val_binary_accuracy: 0.7195\n",
      "Epoch 294/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5532 - binary_accuracy: 0.7392 - val_loss: 0.5810 - val_binary_accuracy: 0.7195\n",
      "Epoch 295/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5530 - binary_accuracy: 0.7395 - val_loss: 0.5809 - val_binary_accuracy: 0.7201\n",
      "Epoch 296/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5528 - binary_accuracy: 0.7397 - val_loss: 0.5808 - val_binary_accuracy: 0.7206\n",
      "Epoch 297/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5527 - binary_accuracy: 0.7397 - val_loss: 0.5807 - val_binary_accuracy: 0.7206\n",
      "Epoch 298/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5525 - binary_accuracy: 0.7402 - val_loss: 0.5806 - val_binary_accuracy: 0.7211\n",
      "Epoch 299/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5523 - binary_accuracy: 0.7406 - val_loss: 0.5805 - val_binary_accuracy: 0.7216\n",
      "Epoch 300/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5521 - binary_accuracy: 0.7413 - val_loss: 0.5804 - val_binary_accuracy: 0.7211\n",
      "Epoch 301/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5519 - binary_accuracy: 0.7416 - val_loss: 0.5802 - val_binary_accuracy: 0.7211\n",
      "Epoch 302/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5517 - binary_accuracy: 0.7418 - val_loss: 0.5801 - val_binary_accuracy: 0.7211\n",
      "Epoch 303/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5515 - binary_accuracy: 0.7418 - val_loss: 0.5800 - val_binary_accuracy: 0.7211\n",
      "Epoch 304/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5514 - binary_accuracy: 0.7420 - val_loss: 0.5799 - val_binary_accuracy: 0.7211\n",
      "Epoch 305/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5512 - binary_accuracy: 0.7423 - val_loss: 0.5798 - val_binary_accuracy: 0.7211\n",
      "Epoch 306/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5510 - binary_accuracy: 0.7420 - val_loss: 0.5797 - val_binary_accuracy: 0.7211\n",
      "Epoch 307/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5508 - binary_accuracy: 0.7425 - val_loss: 0.5796 - val_binary_accuracy: 0.7211\n",
      "Epoch 308/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5506 - binary_accuracy: 0.7430 - val_loss: 0.5794 - val_binary_accuracy: 0.7211\n",
      "Epoch 309/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5504 - binary_accuracy: 0.7439 - val_loss: 0.5793 - val_binary_accuracy: 0.7216\n",
      "Epoch 310/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5503 - binary_accuracy: 0.7441 - val_loss: 0.5792 - val_binary_accuracy: 0.7227\n",
      "Epoch 311/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5501 - binary_accuracy: 0.7444 - val_loss: 0.5791 - val_binary_accuracy: 0.7258\n",
      "Epoch 312/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5499 - binary_accuracy: 0.7451 - val_loss: 0.5790 - val_binary_accuracy: 0.7269\n",
      "Epoch 313/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5497 - binary_accuracy: 0.7448 - val_loss: 0.5789 - val_binary_accuracy: 0.7269\n",
      "Epoch 314/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5495 - binary_accuracy: 0.7450 - val_loss: 0.5788 - val_binary_accuracy: 0.7269\n",
      "Epoch 315/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5494 - binary_accuracy: 0.7450 - val_loss: 0.5787 - val_binary_accuracy: 0.7264\n",
      "Epoch 316/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5492 - binary_accuracy: 0.7451 - val_loss: 0.5786 - val_binary_accuracy: 0.7264\n",
      "Epoch 317/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5490 - binary_accuracy: 0.7455 - val_loss: 0.5785 - val_binary_accuracy: 0.7269\n",
      "Epoch 318/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5488 - binary_accuracy: 0.7455 - val_loss: 0.5784 - val_binary_accuracy: 0.7269\n",
      "Epoch 319/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5487 - binary_accuracy: 0.7455 - val_loss: 0.5783 - val_binary_accuracy: 0.7269\n",
      "Epoch 320/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5485 - binary_accuracy: 0.7458 - val_loss: 0.5782 - val_binary_accuracy: 0.7258\n",
      "Epoch 321/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5483 - binary_accuracy: 0.7458 - val_loss: 0.5781 - val_binary_accuracy: 0.7258\n",
      "Epoch 322/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5481 - binary_accuracy: 0.7460 - val_loss: 0.5780 - val_binary_accuracy: 0.7258\n",
      "Epoch 323/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5480 - binary_accuracy: 0.7460 - val_loss: 0.5779 - val_binary_accuracy: 0.7258\n",
      "Epoch 324/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5478 - binary_accuracy: 0.7462 - val_loss: 0.5778 - val_binary_accuracy: 0.7258\n",
      "Epoch 325/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5476 - binary_accuracy: 0.7464 - val_loss: 0.5777 - val_binary_accuracy: 0.7264\n",
      "Epoch 326/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5475 - binary_accuracy: 0.7465 - val_loss: 0.5776 - val_binary_accuracy: 0.7264\n",
      "Epoch 327/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5473 - binary_accuracy: 0.7465 - val_loss: 0.5775 - val_binary_accuracy: 0.7264\n",
      "Epoch 328/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5471 - binary_accuracy: 0.7465 - val_loss: 0.5773 - val_binary_accuracy: 0.7264\n",
      "Epoch 329/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5470 - binary_accuracy: 0.7465 - val_loss: 0.5772 - val_binary_accuracy: 0.7264\n",
      "Epoch 330/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5468 - binary_accuracy: 0.7465 - val_loss: 0.5771 - val_binary_accuracy: 0.7264\n",
      "Epoch 331/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5466 - binary_accuracy: 0.7471 - val_loss: 0.5770 - val_binary_accuracy: 0.7274\n",
      "Epoch 332/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5465 - binary_accuracy: 0.7472 - val_loss: 0.5769 - val_binary_accuracy: 0.7279\n",
      "Epoch 333/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5463 - binary_accuracy: 0.7472 - val_loss: 0.5768 - val_binary_accuracy: 0.7279\n",
      "Epoch 334/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5461 - binary_accuracy: 0.7472 - val_loss: 0.5767 - val_binary_accuracy: 0.7279\n",
      "Epoch 335/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5460 - binary_accuracy: 0.7472 - val_loss: 0.5767 - val_binary_accuracy: 0.7279\n",
      "Epoch 336/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5458 - binary_accuracy: 0.7474 - val_loss: 0.5766 - val_binary_accuracy: 0.7279\n",
      "Epoch 337/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5456 - binary_accuracy: 0.7478 - val_loss: 0.5765 - val_binary_accuracy: 0.7285\n",
      "Epoch 338/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5455 - binary_accuracy: 0.7481 - val_loss: 0.5764 - val_binary_accuracy: 0.7285\n",
      "Epoch 339/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5453 - binary_accuracy: 0.7479 - val_loss: 0.5763 - val_binary_accuracy: 0.7285\n",
      "Epoch 340/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5452 - binary_accuracy: 0.7479 - val_loss: 0.5762 - val_binary_accuracy: 0.7285\n",
      "Epoch 341/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5450 - binary_accuracy: 0.7481 - val_loss: 0.5761 - val_binary_accuracy: 0.7290\n",
      "Epoch 342/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5448 - binary_accuracy: 0.7481 - val_loss: 0.5760 - val_binary_accuracy: 0.7290\n",
      "Epoch 343/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5447 - binary_accuracy: 0.7483 - val_loss: 0.5759 - val_binary_accuracy: 0.7290\n",
      "Epoch 344/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5445 - binary_accuracy: 0.7483 - val_loss: 0.5758 - val_binary_accuracy: 0.7290\n",
      "Epoch 345/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5443 - binary_accuracy: 0.7486 - val_loss: 0.5757 - val_binary_accuracy: 0.7295\n",
      "Epoch 346/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5442 - binary_accuracy: 0.7488 - val_loss: 0.5756 - val_binary_accuracy: 0.7295\n",
      "Epoch 347/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5440 - binary_accuracy: 0.7488 - val_loss: 0.5755 - val_binary_accuracy: 0.7295\n",
      "Epoch 348/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5439 - binary_accuracy: 0.7490 - val_loss: 0.5754 - val_binary_accuracy: 0.7295\n",
      "Epoch 349/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5437 - binary_accuracy: 0.7490 - val_loss: 0.5753 - val_binary_accuracy: 0.7295\n",
      "Epoch 350/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5436 - binary_accuracy: 0.7492 - val_loss: 0.5752 - val_binary_accuracy: 0.7295\n",
      "Epoch 351/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5434 - binary_accuracy: 0.7492 - val_loss: 0.5751 - val_binary_accuracy: 0.7295\n",
      "Epoch 352/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5433 - binary_accuracy: 0.7495 - val_loss: 0.5750 - val_binary_accuracy: 0.7300\n",
      "Epoch 353/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5431 - binary_accuracy: 0.7500 - val_loss: 0.5750 - val_binary_accuracy: 0.7300\n",
      "Epoch 354/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5430 - binary_accuracy: 0.7500 - val_loss: 0.5749 - val_binary_accuracy: 0.7300\n",
      "Epoch 355/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5428 - binary_accuracy: 0.7499 - val_loss: 0.5748 - val_binary_accuracy: 0.7300\n",
      "Epoch 356/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5427 - binary_accuracy: 0.7504 - val_loss: 0.5747 - val_binary_accuracy: 0.7306\n",
      "Epoch 357/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5425 - binary_accuracy: 0.7507 - val_loss: 0.5746 - val_binary_accuracy: 0.7306\n",
      "Epoch 358/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5424 - binary_accuracy: 0.7507 - val_loss: 0.5745 - val_binary_accuracy: 0.7300\n",
      "Epoch 359/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5422 - binary_accuracy: 0.7507 - val_loss: 0.5744 - val_binary_accuracy: 0.7300\n",
      "Epoch 360/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5420 - binary_accuracy: 0.7506 - val_loss: 0.5744 - val_binary_accuracy: 0.7300\n",
      "Epoch 361/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5419 - binary_accuracy: 0.7509 - val_loss: 0.5743 - val_binary_accuracy: 0.7300\n",
      "Epoch 362/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5417 - binary_accuracy: 0.7509 - val_loss: 0.5742 - val_binary_accuracy: 0.7295\n",
      "Epoch 363/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5416 - binary_accuracy: 0.7507 - val_loss: 0.5741 - val_binary_accuracy: 0.7295\n",
      "Epoch 364/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5414 - binary_accuracy: 0.7507 - val_loss: 0.5740 - val_binary_accuracy: 0.7306\n",
      "Epoch 365/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5413 - binary_accuracy: 0.7507 - val_loss: 0.5739 - val_binary_accuracy: 0.7311\n",
      "Epoch 366/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5411 - binary_accuracy: 0.7511 - val_loss: 0.5738 - val_binary_accuracy: 0.7311\n",
      "Epoch 367/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5410 - binary_accuracy: 0.7514 - val_loss: 0.5738 - val_binary_accuracy: 0.7316\n",
      "Epoch 368/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5408 - binary_accuracy: 0.7514 - val_loss: 0.5737 - val_binary_accuracy: 0.7316\n",
      "Epoch 369/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5407 - binary_accuracy: 0.7516 - val_loss: 0.5736 - val_binary_accuracy: 0.7316\n",
      "Epoch 370/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5405 - binary_accuracy: 0.7520 - val_loss: 0.5735 - val_binary_accuracy: 0.7316\n",
      "Epoch 371/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5404 - binary_accuracy: 0.7521 - val_loss: 0.5734 - val_binary_accuracy: 0.7316\n",
      "Epoch 372/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5403 - binary_accuracy: 0.7520 - val_loss: 0.5733 - val_binary_accuracy: 0.7316\n",
      "Epoch 373/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5401 - binary_accuracy: 0.7521 - val_loss: 0.5732 - val_binary_accuracy: 0.7316\n",
      "Epoch 374/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5400 - binary_accuracy: 0.7521 - val_loss: 0.5732 - val_binary_accuracy: 0.7316\n",
      "Epoch 375/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5398 - binary_accuracy: 0.7523 - val_loss: 0.5731 - val_binary_accuracy: 0.7316\n",
      "Epoch 376/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5397 - binary_accuracy: 0.7525 - val_loss: 0.5730 - val_binary_accuracy: 0.7316\n",
      "Epoch 377/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5395 - binary_accuracy: 0.7527 - val_loss: 0.5729 - val_binary_accuracy: 0.7316\n",
      "Epoch 378/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5394 - binary_accuracy: 0.7530 - val_loss: 0.5729 - val_binary_accuracy: 0.7327\n",
      "Epoch 379/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5393 - binary_accuracy: 0.7537 - val_loss: 0.5728 - val_binary_accuracy: 0.7337\n",
      "Epoch 380/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5391 - binary_accuracy: 0.7539 - val_loss: 0.5727 - val_binary_accuracy: 0.7337\n",
      "Epoch 381/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5390 - binary_accuracy: 0.7537 - val_loss: 0.5726 - val_binary_accuracy: 0.7327\n",
      "Epoch 382/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5388 - binary_accuracy: 0.7537 - val_loss: 0.5725 - val_binary_accuracy: 0.7337\n",
      "Epoch 383/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5387 - binary_accuracy: 0.7537 - val_loss: 0.5725 - val_binary_accuracy: 0.7353\n",
      "Epoch 384/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5386 - binary_accuracy: 0.7542 - val_loss: 0.5724 - val_binary_accuracy: 0.7358\n",
      "Epoch 385/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5384 - binary_accuracy: 0.7546 - val_loss: 0.5723 - val_binary_accuracy: 0.7358\n",
      "Epoch 386/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5383 - binary_accuracy: 0.7548 - val_loss: 0.5722 - val_binary_accuracy: 0.7358\n",
      "Epoch 387/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5381 - binary_accuracy: 0.7544 - val_loss: 0.5722 - val_binary_accuracy: 0.7358\n",
      "Epoch 388/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5380 - binary_accuracy: 0.7546 - val_loss: 0.5721 - val_binary_accuracy: 0.7358\n",
      "Epoch 389/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5379 - binary_accuracy: 0.7548 - val_loss: 0.5720 - val_binary_accuracy: 0.7358\n",
      "Epoch 390/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5377 - binary_accuracy: 0.7548 - val_loss: 0.5720 - val_binary_accuracy: 0.7358\n",
      "Epoch 391/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5376 - binary_accuracy: 0.7549 - val_loss: 0.5719 - val_binary_accuracy: 0.7358\n",
      "Epoch 392/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5375 - binary_accuracy: 0.7553 - val_loss: 0.5718 - val_binary_accuracy: 0.7358\n",
      "Epoch 393/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5373 - binary_accuracy: 0.7555 - val_loss: 0.5717 - val_binary_accuracy: 0.7358\n",
      "Epoch 394/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5372 - binary_accuracy: 0.7555 - val_loss: 0.5717 - val_binary_accuracy: 0.7358\n",
      "Epoch 395/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5371 - binary_accuracy: 0.7555 - val_loss: 0.5716 - val_binary_accuracy: 0.7358\n",
      "Epoch 396/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5369 - binary_accuracy: 0.7558 - val_loss: 0.5715 - val_binary_accuracy: 0.7358\n",
      "Epoch 397/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5368 - binary_accuracy: 0.7560 - val_loss: 0.5714 - val_binary_accuracy: 0.7358\n",
      "Epoch 398/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5367 - binary_accuracy: 0.7563 - val_loss: 0.5713 - val_binary_accuracy: 0.7358\n",
      "Epoch 399/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5365 - binary_accuracy: 0.7565 - val_loss: 0.5713 - val_binary_accuracy: 0.7358\n",
      "Epoch 400/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5364 - binary_accuracy: 0.7565 - val_loss: 0.5712 - val_binary_accuracy: 0.7358\n",
      "Epoch 401/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5363 - binary_accuracy: 0.7563 - val_loss: 0.5711 - val_binary_accuracy: 0.7358\n",
      "Epoch 402/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5362 - binary_accuracy: 0.7560 - val_loss: 0.5711 - val_binary_accuracy: 0.7358\n",
      "Epoch 403/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5360 - binary_accuracy: 0.7560 - val_loss: 0.5710 - val_binary_accuracy: 0.7358\n",
      "Epoch 404/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5359 - binary_accuracy: 0.7562 - val_loss: 0.5709 - val_binary_accuracy: 0.7358\n",
      "Epoch 405/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5358 - binary_accuracy: 0.7563 - val_loss: 0.5708 - val_binary_accuracy: 0.7358\n",
      "Epoch 406/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5356 - binary_accuracy: 0.7563 - val_loss: 0.5708 - val_binary_accuracy: 0.7363\n",
      "Epoch 407/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5355 - binary_accuracy: 0.7563 - val_loss: 0.5707 - val_binary_accuracy: 0.7363\n",
      "Epoch 408/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5354 - binary_accuracy: 0.7567 - val_loss: 0.5706 - val_binary_accuracy: 0.7369\n",
      "Epoch 409/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5353 - binary_accuracy: 0.7569 - val_loss: 0.5706 - val_binary_accuracy: 0.7369\n",
      "Epoch 410/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5351 - binary_accuracy: 0.7571 - val_loss: 0.5705 - val_binary_accuracy: 0.7369\n",
      "Epoch 411/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5350 - binary_accuracy: 0.7572 - val_loss: 0.5705 - val_binary_accuracy: 0.7379\n",
      "Epoch 412/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5349 - binary_accuracy: 0.7581 - val_loss: 0.5704 - val_binary_accuracy: 0.7384\n",
      "Epoch 413/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5347 - binary_accuracy: 0.7586 - val_loss: 0.5703 - val_binary_accuracy: 0.7384\n",
      "Epoch 414/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5346 - binary_accuracy: 0.7588 - val_loss: 0.5702 - val_binary_accuracy: 0.7384\n",
      "Epoch 415/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5345 - binary_accuracy: 0.7588 - val_loss: 0.5702 - val_binary_accuracy: 0.7384\n",
      "Epoch 416/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5344 - binary_accuracy: 0.7588 - val_loss: 0.5701 - val_binary_accuracy: 0.7384\n",
      "Epoch 417/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5342 - binary_accuracy: 0.7585 - val_loss: 0.5700 - val_binary_accuracy: 0.7379\n",
      "Epoch 418/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5341 - binary_accuracy: 0.7585 - val_loss: 0.5700 - val_binary_accuracy: 0.7379\n",
      "Epoch 419/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5340 - binary_accuracy: 0.7586 - val_loss: 0.5699 - val_binary_accuracy: 0.7379\n",
      "Epoch 420/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5338 - binary_accuracy: 0.7586 - val_loss: 0.5698 - val_binary_accuracy: 0.7384\n",
      "Epoch 421/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5337 - binary_accuracy: 0.7586 - val_loss: 0.5698 - val_binary_accuracy: 0.7390\n",
      "Epoch 422/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5336 - binary_accuracy: 0.7586 - val_loss: 0.5697 - val_binary_accuracy: 0.7395\n",
      "Epoch 423/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5335 - binary_accuracy: 0.7586 - val_loss: 0.5696 - val_binary_accuracy: 0.7384\n",
      "Epoch 424/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5334 - binary_accuracy: 0.7586 - val_loss: 0.5696 - val_binary_accuracy: 0.7395\n",
      "Epoch 425/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5332 - binary_accuracy: 0.7586 - val_loss: 0.5695 - val_binary_accuracy: 0.7390\n",
      "Epoch 426/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5331 - binary_accuracy: 0.7586 - val_loss: 0.5695 - val_binary_accuracy: 0.7400\n",
      "Epoch 427/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5330 - binary_accuracy: 0.7590 - val_loss: 0.5694 - val_binary_accuracy: 0.7400\n",
      "Epoch 428/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5329 - binary_accuracy: 0.7586 - val_loss: 0.5694 - val_binary_accuracy: 0.7405\n",
      "Epoch 429/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5327 - binary_accuracy: 0.7586 - val_loss: 0.5693 - val_binary_accuracy: 0.7400\n",
      "Epoch 430/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5326 - binary_accuracy: 0.7590 - val_loss: 0.5692 - val_binary_accuracy: 0.7405\n",
      "Epoch 431/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5325 - binary_accuracy: 0.7590 - val_loss: 0.5691 - val_binary_accuracy: 0.7411\n",
      "Epoch 432/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5324 - binary_accuracy: 0.7590 - val_loss: 0.5691 - val_binary_accuracy: 0.7411\n",
      "Epoch 433/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5322 - binary_accuracy: 0.7586 - val_loss: 0.5690 - val_binary_accuracy: 0.7416\n",
      "Epoch 434/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5321 - binary_accuracy: 0.7586 - val_loss: 0.5689 - val_binary_accuracy: 0.7421\n",
      "Epoch 435/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5320 - binary_accuracy: 0.7585 - val_loss: 0.5688 - val_binary_accuracy: 0.7421\n",
      "Epoch 436/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5319 - binary_accuracy: 0.7585 - val_loss: 0.5688 - val_binary_accuracy: 0.7421\n",
      "Epoch 437/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5318 - binary_accuracy: 0.7588 - val_loss: 0.5687 - val_binary_accuracy: 0.7421\n",
      "Epoch 438/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5317 - binary_accuracy: 0.7590 - val_loss: 0.5686 - val_binary_accuracy: 0.7421\n",
      "Epoch 439/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5315 - binary_accuracy: 0.7592 - val_loss: 0.5686 - val_binary_accuracy: 0.7426\n",
      "Epoch 440/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5314 - binary_accuracy: 0.7595 - val_loss: 0.5685 - val_binary_accuracy: 0.7426\n",
      "Epoch 441/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5313 - binary_accuracy: 0.7599 - val_loss: 0.5684 - val_binary_accuracy: 0.7432\n",
      "Epoch 442/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5312 - binary_accuracy: 0.7600 - val_loss: 0.5684 - val_binary_accuracy: 0.7437\n",
      "Epoch 443/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5311 - binary_accuracy: 0.7600 - val_loss: 0.5683 - val_binary_accuracy: 0.7437\n",
      "Epoch 444/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5310 - binary_accuracy: 0.7599 - val_loss: 0.5682 - val_binary_accuracy: 0.7437\n",
      "Epoch 445/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5308 - binary_accuracy: 0.7597 - val_loss: 0.5682 - val_binary_accuracy: 0.7437\n",
      "Epoch 446/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5307 - binary_accuracy: 0.7600 - val_loss: 0.5681 - val_binary_accuracy: 0.7437\n",
      "Epoch 447/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5306 - binary_accuracy: 0.7602 - val_loss: 0.5681 - val_binary_accuracy: 0.7437\n",
      "Epoch 448/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5305 - binary_accuracy: 0.7602 - val_loss: 0.5680 - val_binary_accuracy: 0.7437\n",
      "Epoch 449/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5304 - binary_accuracy: 0.7602 - val_loss: 0.5680 - val_binary_accuracy: 0.7437\n",
      "Epoch 450/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5303 - binary_accuracy: 0.7606 - val_loss: 0.5679 - val_binary_accuracy: 0.7437\n",
      "Epoch 451/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5301 - binary_accuracy: 0.7607 - val_loss: 0.5678 - val_binary_accuracy: 0.7447\n",
      "Epoch 452/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5300 - binary_accuracy: 0.7609 - val_loss: 0.5678 - val_binary_accuracy: 0.7447\n",
      "Epoch 453/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5299 - binary_accuracy: 0.7613 - val_loss: 0.5677 - val_binary_accuracy: 0.7458\n",
      "Epoch 454/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5298 - binary_accuracy: 0.7616 - val_loss: 0.5677 - val_binary_accuracy: 0.7458\n",
      "Epoch 455/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5297 - binary_accuracy: 0.7618 - val_loss: 0.5676 - val_binary_accuracy: 0.7463\n",
      "Epoch 456/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5296 - binary_accuracy: 0.7618 - val_loss: 0.5676 - val_binary_accuracy: 0.7474\n",
      "Epoch 457/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5295 - binary_accuracy: 0.7620 - val_loss: 0.5675 - val_binary_accuracy: 0.7479\n",
      "Epoch 458/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5294 - binary_accuracy: 0.7616 - val_loss: 0.5675 - val_binary_accuracy: 0.7479\n",
      "Epoch 459/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5292 - binary_accuracy: 0.7621 - val_loss: 0.5674 - val_binary_accuracy: 0.7479\n",
      "Epoch 460/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5291 - binary_accuracy: 0.7621 - val_loss: 0.5673 - val_binary_accuracy: 0.7479\n",
      "Epoch 461/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5290 - binary_accuracy: 0.7623 - val_loss: 0.5673 - val_binary_accuracy: 0.7474\n",
      "Epoch 462/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5289 - binary_accuracy: 0.7625 - val_loss: 0.5672 - val_binary_accuracy: 0.7468\n",
      "Epoch 463/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5288 - binary_accuracy: 0.7628 - val_loss: 0.5671 - val_binary_accuracy: 0.7484\n",
      "Epoch 464/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5287 - binary_accuracy: 0.7628 - val_loss: 0.5671 - val_binary_accuracy: 0.7484\n",
      "Epoch 465/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5286 - binary_accuracy: 0.7632 - val_loss: 0.5670 - val_binary_accuracy: 0.7489\n",
      "Epoch 466/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5285 - binary_accuracy: 0.7632 - val_loss: 0.5670 - val_binary_accuracy: 0.7489\n",
      "Epoch 467/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5283 - binary_accuracy: 0.7632 - val_loss: 0.5669 - val_binary_accuracy: 0.7489\n",
      "Epoch 468/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5282 - binary_accuracy: 0.7632 - val_loss: 0.5668 - val_binary_accuracy: 0.7489\n",
      "Epoch 469/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5281 - binary_accuracy: 0.7632 - val_loss: 0.5668 - val_binary_accuracy: 0.7489\n",
      "Epoch 470/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5280 - binary_accuracy: 0.7632 - val_loss: 0.5667 - val_binary_accuracy: 0.7489\n",
      "Epoch 471/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5279 - binary_accuracy: 0.7632 - val_loss: 0.5667 - val_binary_accuracy: 0.7489\n",
      "Epoch 472/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5278 - binary_accuracy: 0.7632 - val_loss: 0.5666 - val_binary_accuracy: 0.7489\n",
      "Epoch 473/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5277 - binary_accuracy: 0.7635 - val_loss: 0.5666 - val_binary_accuracy: 0.7489\n",
      "Epoch 474/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5276 - binary_accuracy: 0.7635 - val_loss: 0.5665 - val_binary_accuracy: 0.7489\n",
      "Epoch 475/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5275 - binary_accuracy: 0.7635 - val_loss: 0.5665 - val_binary_accuracy: 0.7479\n",
      "Epoch 476/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5274 - binary_accuracy: 0.7637 - val_loss: 0.5664 - val_binary_accuracy: 0.7484\n",
      "Epoch 477/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5273 - binary_accuracy: 0.7637 - val_loss: 0.5664 - val_binary_accuracy: 0.7495\n",
      "Epoch 478/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5271 - binary_accuracy: 0.7641 - val_loss: 0.5663 - val_binary_accuracy: 0.7495\n",
      "Epoch 479/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5270 - binary_accuracy: 0.7642 - val_loss: 0.5662 - val_binary_accuracy: 0.7495\n",
      "Epoch 480/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5269 - binary_accuracy: 0.7644 - val_loss: 0.5662 - val_binary_accuracy: 0.7495\n",
      "Epoch 481/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5268 - binary_accuracy: 0.7644 - val_loss: 0.5661 - val_binary_accuracy: 0.7495\n",
      "Epoch 482/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5267 - binary_accuracy: 0.7644 - val_loss: 0.5661 - val_binary_accuracy: 0.7495\n",
      "Epoch 483/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5266 - binary_accuracy: 0.7644 - val_loss: 0.5660 - val_binary_accuracy: 0.7495\n",
      "Epoch 484/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5265 - binary_accuracy: 0.7644 - val_loss: 0.5660 - val_binary_accuracy: 0.7495\n",
      "Epoch 485/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5264 - binary_accuracy: 0.7646 - val_loss: 0.5659 - val_binary_accuracy: 0.7495\n",
      "Epoch 486/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5263 - binary_accuracy: 0.7646 - val_loss: 0.5658 - val_binary_accuracy: 0.7495\n",
      "Epoch 487/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5262 - binary_accuracy: 0.7646 - val_loss: 0.5658 - val_binary_accuracy: 0.7500\n",
      "Epoch 488/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5261 - binary_accuracy: 0.7648 - val_loss: 0.5657 - val_binary_accuracy: 0.7500\n",
      "Epoch 489/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5260 - binary_accuracy: 0.7648 - val_loss: 0.5657 - val_binary_accuracy: 0.7500\n",
      "Epoch 490/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5259 - binary_accuracy: 0.7646 - val_loss: 0.5656 - val_binary_accuracy: 0.7500\n",
      "Epoch 491/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5258 - binary_accuracy: 0.7648 - val_loss: 0.5655 - val_binary_accuracy: 0.7511\n",
      "Epoch 492/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5257 - binary_accuracy: 0.7651 - val_loss: 0.5655 - val_binary_accuracy: 0.7516\n",
      "Epoch 493/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5256 - binary_accuracy: 0.7649 - val_loss: 0.5654 - val_binary_accuracy: 0.7516\n",
      "Epoch 494/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5255 - binary_accuracy: 0.7649 - val_loss: 0.5654 - val_binary_accuracy: 0.7511\n",
      "Epoch 495/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5254 - binary_accuracy: 0.7648 - val_loss: 0.5653 - val_binary_accuracy: 0.7511\n",
      "Epoch 496/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5252 - binary_accuracy: 0.7646 - val_loss: 0.5652 - val_binary_accuracy: 0.7511\n",
      "Epoch 497/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5251 - binary_accuracy: 0.7646 - val_loss: 0.5652 - val_binary_accuracy: 0.7516\n",
      "Epoch 498/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5250 - binary_accuracy: 0.7646 - val_loss: 0.5651 - val_binary_accuracy: 0.7516\n",
      "Epoch 499/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5249 - binary_accuracy: 0.7646 - val_loss: 0.5651 - val_binary_accuracy: 0.7516\n",
      "Epoch 500/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5248 - binary_accuracy: 0.7648 - val_loss: 0.5650 - val_binary_accuracy: 0.7516\n",
      "Epoch 501/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5247 - binary_accuracy: 0.7648 - val_loss: 0.5650 - val_binary_accuracy: 0.7516\n",
      "Epoch 502/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5246 - binary_accuracy: 0.7651 - val_loss: 0.5649 - val_binary_accuracy: 0.7516\n",
      "Epoch 503/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5245 - binary_accuracy: 0.7649 - val_loss: 0.5648 - val_binary_accuracy: 0.7521\n",
      "Epoch 504/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5244 - binary_accuracy: 0.7649 - val_loss: 0.5648 - val_binary_accuracy: 0.7521\n",
      "Epoch 505/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5243 - binary_accuracy: 0.7646 - val_loss: 0.5647 - val_binary_accuracy: 0.7516\n",
      "Epoch 506/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5242 - binary_accuracy: 0.7649 - val_loss: 0.5647 - val_binary_accuracy: 0.7516\n",
      "Epoch 507/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5241 - binary_accuracy: 0.7649 - val_loss: 0.5646 - val_binary_accuracy: 0.7526\n",
      "Epoch 508/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5240 - binary_accuracy: 0.7649 - val_loss: 0.5646 - val_binary_accuracy: 0.7526\n",
      "Epoch 509/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5239 - binary_accuracy: 0.7653 - val_loss: 0.5645 - val_binary_accuracy: 0.7526\n",
      "Epoch 510/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5238 - binary_accuracy: 0.7653 - val_loss: 0.5645 - val_binary_accuracy: 0.7526\n",
      "Epoch 511/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5237 - binary_accuracy: 0.7651 - val_loss: 0.5644 - val_binary_accuracy: 0.7526\n",
      "Epoch 512/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5236 - binary_accuracy: 0.7651 - val_loss: 0.5644 - val_binary_accuracy: 0.7526\n",
      "Epoch 513/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5235 - binary_accuracy: 0.7655 - val_loss: 0.5643 - val_binary_accuracy: 0.7526\n",
      "Epoch 514/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5234 - binary_accuracy: 0.7662 - val_loss: 0.5642 - val_binary_accuracy: 0.7526\n",
      "Epoch 515/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5233 - binary_accuracy: 0.7667 - val_loss: 0.5642 - val_binary_accuracy: 0.7526\n",
      "Epoch 516/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5232 - binary_accuracy: 0.7665 - val_loss: 0.5642 - val_binary_accuracy: 0.7526\n",
      "Epoch 517/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5231 - binary_accuracy: 0.7665 - val_loss: 0.5641 - val_binary_accuracy: 0.7526\n",
      "Epoch 518/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5230 - binary_accuracy: 0.7667 - val_loss: 0.5641 - val_binary_accuracy: 0.7526\n",
      "Epoch 519/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5229 - binary_accuracy: 0.7667 - val_loss: 0.5640 - val_binary_accuracy: 0.7526\n",
      "Epoch 520/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5228 - binary_accuracy: 0.7667 - val_loss: 0.5640 - val_binary_accuracy: 0.7526\n",
      "Epoch 521/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5227 - binary_accuracy: 0.7672 - val_loss: 0.5639 - val_binary_accuracy: 0.7526\n",
      "Epoch 522/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5226 - binary_accuracy: 0.7679 - val_loss: 0.5639 - val_binary_accuracy: 0.7526\n",
      "Epoch 523/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5225 - binary_accuracy: 0.7679 - val_loss: 0.5638 - val_binary_accuracy: 0.7526\n",
      "Epoch 524/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5224 - binary_accuracy: 0.7683 - val_loss: 0.5638 - val_binary_accuracy: 0.7526\n",
      "Epoch 525/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5223 - binary_accuracy: 0.7681 - val_loss: 0.5637 - val_binary_accuracy: 0.7526\n",
      "Epoch 526/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5222 - binary_accuracy: 0.7677 - val_loss: 0.5637 - val_binary_accuracy: 0.7526\n",
      "Epoch 527/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5221 - binary_accuracy: 0.7681 - val_loss: 0.5636 - val_binary_accuracy: 0.7526\n",
      "Epoch 528/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5220 - binary_accuracy: 0.7681 - val_loss: 0.5636 - val_binary_accuracy: 0.7532\n",
      "Epoch 529/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5219 - binary_accuracy: 0.7686 - val_loss: 0.5635 - val_binary_accuracy: 0.7532\n",
      "Epoch 530/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5219 - binary_accuracy: 0.7686 - val_loss: 0.5635 - val_binary_accuracy: 0.7532\n",
      "Epoch 531/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5218 - binary_accuracy: 0.7686 - val_loss: 0.5634 - val_binary_accuracy: 0.7532\n",
      "Epoch 532/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5217 - binary_accuracy: 0.7690 - val_loss: 0.5633 - val_binary_accuracy: 0.7532\n",
      "Epoch 533/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5216 - binary_accuracy: 0.7688 - val_loss: 0.5633 - val_binary_accuracy: 0.7532\n",
      "Epoch 534/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5215 - binary_accuracy: 0.7688 - val_loss: 0.5632 - val_binary_accuracy: 0.7537\n",
      "Epoch 535/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5214 - binary_accuracy: 0.7688 - val_loss: 0.5632 - val_binary_accuracy: 0.7537\n",
      "Epoch 536/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5213 - binary_accuracy: 0.7686 - val_loss: 0.5631 - val_binary_accuracy: 0.7537\n",
      "Epoch 537/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5212 - binary_accuracy: 0.7688 - val_loss: 0.5631 - val_binary_accuracy: 0.7537\n",
      "Epoch 538/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5211 - binary_accuracy: 0.7691 - val_loss: 0.5630 - val_binary_accuracy: 0.7542\n",
      "Epoch 539/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5210 - binary_accuracy: 0.7695 - val_loss: 0.5630 - val_binary_accuracy: 0.7542\n",
      "Epoch 540/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5209 - binary_accuracy: 0.7693 - val_loss: 0.5630 - val_binary_accuracy: 0.7542\n",
      "Epoch 541/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5208 - binary_accuracy: 0.7695 - val_loss: 0.5629 - val_binary_accuracy: 0.7542\n",
      "Epoch 542/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5207 - binary_accuracy: 0.7695 - val_loss: 0.5629 - val_binary_accuracy: 0.7542\n",
      "Epoch 543/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5206 - binary_accuracy: 0.7695 - val_loss: 0.5628 - val_binary_accuracy: 0.7542\n",
      "Epoch 544/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5205 - binary_accuracy: 0.7693 - val_loss: 0.5628 - val_binary_accuracy: 0.7542\n",
      "Epoch 545/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5204 - binary_accuracy: 0.7693 - val_loss: 0.5627 - val_binary_accuracy: 0.7542\n",
      "Epoch 546/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5203 - binary_accuracy: 0.7695 - val_loss: 0.5627 - val_binary_accuracy: 0.7542\n",
      "Epoch 547/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5202 - binary_accuracy: 0.7697 - val_loss: 0.5626 - val_binary_accuracy: 0.7542\n",
      "Epoch 548/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5201 - binary_accuracy: 0.7697 - val_loss: 0.5626 - val_binary_accuracy: 0.7542\n",
      "Epoch 549/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5200 - binary_accuracy: 0.7697 - val_loss: 0.5625 - val_binary_accuracy: 0.7542\n",
      "Epoch 550/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5200 - binary_accuracy: 0.7700 - val_loss: 0.5625 - val_binary_accuracy: 0.7542\n",
      "Epoch 551/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5199 - binary_accuracy: 0.7702 - val_loss: 0.5624 - val_binary_accuracy: 0.7537\n",
      "Epoch 552/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5198 - binary_accuracy: 0.7702 - val_loss: 0.5624 - val_binary_accuracy: 0.7537\n",
      "Epoch 553/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5197 - binary_accuracy: 0.7704 - val_loss: 0.5623 - val_binary_accuracy: 0.7537\n",
      "Epoch 554/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5196 - binary_accuracy: 0.7705 - val_loss: 0.5623 - val_binary_accuracy: 0.7537\n",
      "Epoch 555/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5195 - binary_accuracy: 0.7707 - val_loss: 0.5623 - val_binary_accuracy: 0.7542\n",
      "Epoch 556/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5194 - binary_accuracy: 0.7707 - val_loss: 0.5622 - val_binary_accuracy: 0.7542\n",
      "Epoch 557/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5193 - binary_accuracy: 0.7709 - val_loss: 0.5622 - val_binary_accuracy: 0.7537\n",
      "Epoch 558/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5192 - binary_accuracy: 0.7707 - val_loss: 0.5621 - val_binary_accuracy: 0.7537\n",
      "Epoch 559/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5191 - binary_accuracy: 0.7711 - val_loss: 0.5621 - val_binary_accuracy: 0.7542\n",
      "Epoch 560/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5190 - binary_accuracy: 0.7716 - val_loss: 0.5620 - val_binary_accuracy: 0.7542\n",
      "Epoch 561/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5189 - binary_accuracy: 0.7714 - val_loss: 0.5619 - val_binary_accuracy: 0.7542\n",
      "Epoch 562/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5189 - binary_accuracy: 0.7711 - val_loss: 0.5619 - val_binary_accuracy: 0.7547\n",
      "Epoch 563/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5188 - binary_accuracy: 0.7712 - val_loss: 0.5619 - val_binary_accuracy: 0.7553\n",
      "Epoch 564/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5187 - binary_accuracy: 0.7716 - val_loss: 0.5618 - val_binary_accuracy: 0.7553\n",
      "Epoch 565/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5186 - binary_accuracy: 0.7716 - val_loss: 0.5618 - val_binary_accuracy: 0.7547\n",
      "Epoch 566/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5185 - binary_accuracy: 0.7718 - val_loss: 0.5617 - val_binary_accuracy: 0.7547\n",
      "Epoch 567/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5184 - binary_accuracy: 0.7719 - val_loss: 0.5617 - val_binary_accuracy: 0.7547\n",
      "Epoch 568/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5183 - binary_accuracy: 0.7719 - val_loss: 0.5616 - val_binary_accuracy: 0.7547\n",
      "Epoch 569/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5182 - binary_accuracy: 0.7719 - val_loss: 0.5616 - val_binary_accuracy: 0.7547\n",
      "Epoch 570/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5181 - binary_accuracy: 0.7719 - val_loss: 0.5615 - val_binary_accuracy: 0.7547\n",
      "Epoch 571/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5180 - binary_accuracy: 0.7723 - val_loss: 0.5615 - val_binary_accuracy: 0.7553\n",
      "Epoch 572/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5180 - binary_accuracy: 0.7725 - val_loss: 0.5614 - val_binary_accuracy: 0.7553\n",
      "Epoch 573/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5179 - binary_accuracy: 0.7726 - val_loss: 0.5614 - val_binary_accuracy: 0.7553\n",
      "Epoch 574/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5178 - binary_accuracy: 0.7726 - val_loss: 0.5614 - val_binary_accuracy: 0.7553\n",
      "Epoch 575/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5177 - binary_accuracy: 0.7726 - val_loss: 0.5613 - val_binary_accuracy: 0.7568\n",
      "Epoch 576/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5176 - binary_accuracy: 0.7732 - val_loss: 0.5613 - val_binary_accuracy: 0.7568\n",
      "Epoch 577/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5175 - binary_accuracy: 0.7732 - val_loss: 0.5612 - val_binary_accuracy: 0.7568\n",
      "Epoch 578/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5174 - binary_accuracy: 0.7730 - val_loss: 0.5612 - val_binary_accuracy: 0.7574\n",
      "Epoch 579/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5173 - binary_accuracy: 0.7730 - val_loss: 0.5611 - val_binary_accuracy: 0.7574\n",
      "Epoch 580/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5173 - binary_accuracy: 0.7730 - val_loss: 0.5611 - val_binary_accuracy: 0.7574\n",
      "Epoch 581/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5172 - binary_accuracy: 0.7730 - val_loss: 0.5610 - val_binary_accuracy: 0.7568\n",
      "Epoch 582/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5171 - binary_accuracy: 0.7732 - val_loss: 0.5610 - val_binary_accuracy: 0.7568\n",
      "Epoch 583/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5170 - binary_accuracy: 0.7732 - val_loss: 0.5609 - val_binary_accuracy: 0.7574\n",
      "Epoch 584/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5169 - binary_accuracy: 0.7730 - val_loss: 0.5609 - val_binary_accuracy: 0.7568\n",
      "Epoch 585/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5168 - binary_accuracy: 0.7730 - val_loss: 0.5608 - val_binary_accuracy: 0.7574\n",
      "Epoch 586/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5167 - binary_accuracy: 0.7730 - val_loss: 0.5608 - val_binary_accuracy: 0.7574\n",
      "Epoch 587/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5166 - binary_accuracy: 0.7732 - val_loss: 0.5608 - val_binary_accuracy: 0.7579\n",
      "Epoch 588/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5165 - binary_accuracy: 0.7732 - val_loss: 0.5607 - val_binary_accuracy: 0.7584\n",
      "Epoch 589/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5165 - binary_accuracy: 0.7733 - val_loss: 0.5606 - val_binary_accuracy: 0.7584\n",
      "Epoch 590/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5164 - binary_accuracy: 0.7737 - val_loss: 0.5606 - val_binary_accuracy: 0.7584\n",
      "Epoch 591/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5163 - binary_accuracy: 0.7737 - val_loss: 0.5605 - val_binary_accuracy: 0.7584\n",
      "Epoch 592/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5162 - binary_accuracy: 0.7735 - val_loss: 0.5605 - val_binary_accuracy: 0.7584\n",
      "Epoch 593/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5161 - binary_accuracy: 0.7733 - val_loss: 0.5604 - val_binary_accuracy: 0.7579\n",
      "Epoch 594/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5160 - binary_accuracy: 0.7733 - val_loss: 0.5604 - val_binary_accuracy: 0.7574\n",
      "Epoch 595/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5159 - binary_accuracy: 0.7732 - val_loss: 0.5604 - val_binary_accuracy: 0.7574\n",
      "Epoch 596/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5158 - binary_accuracy: 0.7732 - val_loss: 0.5603 - val_binary_accuracy: 0.7574\n",
      "Epoch 597/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5158 - binary_accuracy: 0.7733 - val_loss: 0.5603 - val_binary_accuracy: 0.7579\n",
      "Epoch 598/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5157 - binary_accuracy: 0.7737 - val_loss: 0.5602 - val_binary_accuracy: 0.7584\n",
      "Epoch 599/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5156 - binary_accuracy: 0.7739 - val_loss: 0.5602 - val_binary_accuracy: 0.7595\n",
      "Epoch 600/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5155 - binary_accuracy: 0.7739 - val_loss: 0.5601 - val_binary_accuracy: 0.7600\n",
      "Epoch 601/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5154 - binary_accuracy: 0.7744 - val_loss: 0.5601 - val_binary_accuracy: 0.7600\n",
      "Epoch 602/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5153 - binary_accuracy: 0.7749 - val_loss: 0.5600 - val_binary_accuracy: 0.7600\n",
      "Epoch 603/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5152 - binary_accuracy: 0.7749 - val_loss: 0.5600 - val_binary_accuracy: 0.7600\n",
      "Epoch 604/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5152 - binary_accuracy: 0.7747 - val_loss: 0.5600 - val_binary_accuracy: 0.7600\n",
      "Epoch 605/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5151 - binary_accuracy: 0.7744 - val_loss: 0.5599 - val_binary_accuracy: 0.7600\n",
      "Epoch 606/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5150 - binary_accuracy: 0.7744 - val_loss: 0.5599 - val_binary_accuracy: 0.7595\n",
      "Epoch 607/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5149 - binary_accuracy: 0.7747 - val_loss: 0.5598 - val_binary_accuracy: 0.7600\n",
      "Epoch 608/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5148 - binary_accuracy: 0.7751 - val_loss: 0.5598 - val_binary_accuracy: 0.7600\n",
      "Epoch 609/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5147 - binary_accuracy: 0.7754 - val_loss: 0.5597 - val_binary_accuracy: 0.7600\n",
      "Epoch 610/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5146 - binary_accuracy: 0.7753 - val_loss: 0.5597 - val_binary_accuracy: 0.7595\n",
      "Epoch 611/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5146 - binary_accuracy: 0.7753 - val_loss: 0.5596 - val_binary_accuracy: 0.7600\n",
      "Epoch 612/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5145 - binary_accuracy: 0.7749 - val_loss: 0.5596 - val_binary_accuracy: 0.7600\n",
      "Epoch 613/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5144 - binary_accuracy: 0.7749 - val_loss: 0.5595 - val_binary_accuracy: 0.7600\n",
      "Epoch 614/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5143 - binary_accuracy: 0.7751 - val_loss: 0.5595 - val_binary_accuracy: 0.7600\n",
      "Epoch 615/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5142 - binary_accuracy: 0.7751 - val_loss: 0.5594 - val_binary_accuracy: 0.7600\n",
      "Epoch 616/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5141 - binary_accuracy: 0.7754 - val_loss: 0.5594 - val_binary_accuracy: 0.7595\n",
      "Epoch 617/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5140 - binary_accuracy: 0.7754 - val_loss: 0.5593 - val_binary_accuracy: 0.7595\n",
      "Epoch 618/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5140 - binary_accuracy: 0.7756 - val_loss: 0.5593 - val_binary_accuracy: 0.7589\n",
      "Epoch 619/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5139 - binary_accuracy: 0.7756 - val_loss: 0.5592 - val_binary_accuracy: 0.7595\n",
      "Epoch 620/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5138 - binary_accuracy: 0.7761 - val_loss: 0.5592 - val_binary_accuracy: 0.7589\n",
      "Epoch 621/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5137 - binary_accuracy: 0.7761 - val_loss: 0.5592 - val_binary_accuracy: 0.7600\n",
      "Epoch 622/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5136 - binary_accuracy: 0.7761 - val_loss: 0.5591 - val_binary_accuracy: 0.7600\n",
      "Epoch 623/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5135 - binary_accuracy: 0.7760 - val_loss: 0.5591 - val_binary_accuracy: 0.7600\n",
      "Epoch 624/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5135 - binary_accuracy: 0.7760 - val_loss: 0.5590 - val_binary_accuracy: 0.7600\n",
      "Epoch 625/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5134 - binary_accuracy: 0.7760 - val_loss: 0.5590 - val_binary_accuracy: 0.7600\n",
      "Epoch 626/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5133 - binary_accuracy: 0.7761 - val_loss: 0.5589 - val_binary_accuracy: 0.7600\n",
      "Epoch 627/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5132 - binary_accuracy: 0.7760 - val_loss: 0.5589 - val_binary_accuracy: 0.7595\n",
      "Epoch 628/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5131 - binary_accuracy: 0.7760 - val_loss: 0.5588 - val_binary_accuracy: 0.7600\n",
      "Epoch 629/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5130 - binary_accuracy: 0.7760 - val_loss: 0.5588 - val_binary_accuracy: 0.7595\n",
      "Epoch 630/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5130 - binary_accuracy: 0.7760 - val_loss: 0.5587 - val_binary_accuracy: 0.7600\n",
      "Epoch 631/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5129 - binary_accuracy: 0.7760 - val_loss: 0.5587 - val_binary_accuracy: 0.7600\n",
      "Epoch 632/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5128 - binary_accuracy: 0.7760 - val_loss: 0.5586 - val_binary_accuracy: 0.7600\n",
      "Epoch 633/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5127 - binary_accuracy: 0.7761 - val_loss: 0.5586 - val_binary_accuracy: 0.7600\n",
      "Epoch 634/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5126 - binary_accuracy: 0.7761 - val_loss: 0.5585 - val_binary_accuracy: 0.7600\n",
      "Epoch 635/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5125 - binary_accuracy: 0.7761 - val_loss: 0.5585 - val_binary_accuracy: 0.7600\n",
      "Epoch 636/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5125 - binary_accuracy: 0.7763 - val_loss: 0.5585 - val_binary_accuracy: 0.7600\n",
      "Epoch 637/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5124 - binary_accuracy: 0.7763 - val_loss: 0.5584 - val_binary_accuracy: 0.7600\n",
      "Epoch 638/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5123 - binary_accuracy: 0.7763 - val_loss: 0.5584 - val_binary_accuracy: 0.7605\n",
      "Epoch 639/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5122 - binary_accuracy: 0.7768 - val_loss: 0.5583 - val_binary_accuracy: 0.7605\n",
      "Epoch 640/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5121 - binary_accuracy: 0.7768 - val_loss: 0.5583 - val_binary_accuracy: 0.7605\n",
      "Epoch 641/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5121 - binary_accuracy: 0.7774 - val_loss: 0.5583 - val_binary_accuracy: 0.7605\n",
      "Epoch 642/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5120 - binary_accuracy: 0.7775 - val_loss: 0.5582 - val_binary_accuracy: 0.7605\n",
      "Epoch 643/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5119 - binary_accuracy: 0.7774 - val_loss: 0.5582 - val_binary_accuracy: 0.7605\n",
      "Epoch 644/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5118 - binary_accuracy: 0.7774 - val_loss: 0.5581 - val_binary_accuracy: 0.7605\n",
      "Epoch 645/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5117 - binary_accuracy: 0.7777 - val_loss: 0.5581 - val_binary_accuracy: 0.7605\n",
      "Epoch 646/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5116 - binary_accuracy: 0.7775 - val_loss: 0.5580 - val_binary_accuracy: 0.7610\n",
      "Epoch 647/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5116 - binary_accuracy: 0.7775 - val_loss: 0.5580 - val_binary_accuracy: 0.7610\n",
      "Epoch 648/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5115 - binary_accuracy: 0.7775 - val_loss: 0.5580 - val_binary_accuracy: 0.7610\n",
      "Epoch 649/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5114 - binary_accuracy: 0.7777 - val_loss: 0.5579 - val_binary_accuracy: 0.7610\n",
      "Epoch 650/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5113 - binary_accuracy: 0.7775 - val_loss: 0.5579 - val_binary_accuracy: 0.7610\n",
      "Epoch 651/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5112 - binary_accuracy: 0.7775 - val_loss: 0.5579 - val_binary_accuracy: 0.7610\n",
      "Epoch 652/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5112 - binary_accuracy: 0.7775 - val_loss: 0.5578 - val_binary_accuracy: 0.7610\n",
      "Epoch 653/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5111 - binary_accuracy: 0.7775 - val_loss: 0.5578 - val_binary_accuracy: 0.7616\n",
      "Epoch 654/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5110 - binary_accuracy: 0.7774 - val_loss: 0.5577 - val_binary_accuracy: 0.7616\n",
      "Epoch 655/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5109 - binary_accuracy: 0.7775 - val_loss: 0.5577 - val_binary_accuracy: 0.7610\n",
      "Epoch 656/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5108 - binary_accuracy: 0.7784 - val_loss: 0.5577 - val_binary_accuracy: 0.7610\n",
      "Epoch 657/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5108 - binary_accuracy: 0.7793 - val_loss: 0.5576 - val_binary_accuracy: 0.7616\n",
      "Epoch 658/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5107 - binary_accuracy: 0.7791 - val_loss: 0.5576 - val_binary_accuracy: 0.7610\n",
      "Epoch 659/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5106 - binary_accuracy: 0.7788 - val_loss: 0.5575 - val_binary_accuracy: 0.7610\n",
      "Epoch 660/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5105 - binary_accuracy: 0.7784 - val_loss: 0.5575 - val_binary_accuracy: 0.7610\n",
      "Epoch 661/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5105 - binary_accuracy: 0.7784 - val_loss: 0.5575 - val_binary_accuracy: 0.7610\n",
      "Epoch 662/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5104 - binary_accuracy: 0.7784 - val_loss: 0.5574 - val_binary_accuracy: 0.7616\n",
      "Epoch 663/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5103 - binary_accuracy: 0.7784 - val_loss: 0.5574 - val_binary_accuracy: 0.7610\n",
      "Epoch 664/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5102 - binary_accuracy: 0.7784 - val_loss: 0.5573 - val_binary_accuracy: 0.7610\n",
      "Epoch 665/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5101 - binary_accuracy: 0.7789 - val_loss: 0.5573 - val_binary_accuracy: 0.7626\n",
      "Epoch 666/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5101 - binary_accuracy: 0.7793 - val_loss: 0.5572 - val_binary_accuracy: 0.7626\n",
      "Epoch 667/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5100 - binary_accuracy: 0.7789 - val_loss: 0.5572 - val_binary_accuracy: 0.7616\n",
      "Epoch 668/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5099 - binary_accuracy: 0.7788 - val_loss: 0.5571 - val_binary_accuracy: 0.7616\n",
      "Epoch 669/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5098 - binary_accuracy: 0.7791 - val_loss: 0.5571 - val_binary_accuracy: 0.7616\n",
      "Epoch 670/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5097 - binary_accuracy: 0.7793 - val_loss: 0.5570 - val_binary_accuracy: 0.7616\n",
      "Epoch 671/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5097 - binary_accuracy: 0.7793 - val_loss: 0.5570 - val_binary_accuracy: 0.7621\n",
      "Epoch 672/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5096 - binary_accuracy: 0.7795 - val_loss: 0.5569 - val_binary_accuracy: 0.7621\n",
      "Epoch 673/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5095 - binary_accuracy: 0.7791 - val_loss: 0.5569 - val_binary_accuracy: 0.7616\n",
      "Epoch 674/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5094 - binary_accuracy: 0.7791 - val_loss: 0.5569 - val_binary_accuracy: 0.7616\n",
      "Epoch 675/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5094 - binary_accuracy: 0.7793 - val_loss: 0.5568 - val_binary_accuracy: 0.7610\n",
      "Epoch 676/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5093 - binary_accuracy: 0.7793 - val_loss: 0.5568 - val_binary_accuracy: 0.7610\n",
      "Epoch 677/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5092 - binary_accuracy: 0.7793 - val_loss: 0.5568 - val_binary_accuracy: 0.7610\n",
      "Epoch 678/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5091 - binary_accuracy: 0.7793 - val_loss: 0.5567 - val_binary_accuracy: 0.7610\n",
      "Epoch 679/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5090 - binary_accuracy: 0.7793 - val_loss: 0.5567 - val_binary_accuracy: 0.7621\n",
      "Epoch 680/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5090 - binary_accuracy: 0.7795 - val_loss: 0.5567 - val_binary_accuracy: 0.7616\n",
      "Epoch 681/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5089 - binary_accuracy: 0.7796 - val_loss: 0.5566 - val_binary_accuracy: 0.7616\n",
      "Epoch 682/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5088 - binary_accuracy: 0.7796 - val_loss: 0.5566 - val_binary_accuracy: 0.7626\n",
      "Epoch 683/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5087 - binary_accuracy: 0.7800 - val_loss: 0.5566 - val_binary_accuracy: 0.7626\n",
      "Epoch 684/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5087 - binary_accuracy: 0.7802 - val_loss: 0.5565 - val_binary_accuracy: 0.7626\n",
      "Epoch 685/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5086 - binary_accuracy: 0.7802 - val_loss: 0.5565 - val_binary_accuracy: 0.7621\n",
      "Epoch 686/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5085 - binary_accuracy: 0.7803 - val_loss: 0.5564 - val_binary_accuracy: 0.7621\n",
      "Epoch 687/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5084 - binary_accuracy: 0.7800 - val_loss: 0.5564 - val_binary_accuracy: 0.7621\n",
      "Epoch 688/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5084 - binary_accuracy: 0.7800 - val_loss: 0.5564 - val_binary_accuracy: 0.7621\n",
      "Epoch 689/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5083 - binary_accuracy: 0.7803 - val_loss: 0.5563 - val_binary_accuracy: 0.7621\n",
      "Epoch 690/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5082 - binary_accuracy: 0.7803 - val_loss: 0.5563 - val_binary_accuracy: 0.7616\n",
      "Epoch 691/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5081 - binary_accuracy: 0.7798 - val_loss: 0.5563 - val_binary_accuracy: 0.7621\n",
      "Epoch 692/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5080 - binary_accuracy: 0.7796 - val_loss: 0.5563 - val_binary_accuracy: 0.7621\n",
      "Epoch 693/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5080 - binary_accuracy: 0.7796 - val_loss: 0.5562 - val_binary_accuracy: 0.7621\n",
      "Epoch 694/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5079 - binary_accuracy: 0.7800 - val_loss: 0.5562 - val_binary_accuracy: 0.7621\n",
      "Epoch 695/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5078 - binary_accuracy: 0.7803 - val_loss: 0.5562 - val_binary_accuracy: 0.7621\n",
      "Epoch 696/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5077 - binary_accuracy: 0.7807 - val_loss: 0.5561 - val_binary_accuracy: 0.7616\n",
      "Epoch 697/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5077 - binary_accuracy: 0.7809 - val_loss: 0.5561 - val_binary_accuracy: 0.7621\n",
      "Epoch 698/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5076 - binary_accuracy: 0.7810 - val_loss: 0.5560 - val_binary_accuracy: 0.7626\n",
      "Epoch 699/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5075 - binary_accuracy: 0.7809 - val_loss: 0.5560 - val_binary_accuracy: 0.7621\n",
      "Epoch 700/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5074 - binary_accuracy: 0.7807 - val_loss: 0.5560 - val_binary_accuracy: 0.7626\n",
      "Epoch 701/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5074 - binary_accuracy: 0.7812 - val_loss: 0.5559 - val_binary_accuracy: 0.7621\n",
      "Epoch 702/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5073 - binary_accuracy: 0.7816 - val_loss: 0.5559 - val_binary_accuracy: 0.7616\n",
      "Epoch 703/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5072 - binary_accuracy: 0.7814 - val_loss: 0.5559 - val_binary_accuracy: 0.7616\n",
      "Epoch 704/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5071 - binary_accuracy: 0.7817 - val_loss: 0.5558 - val_binary_accuracy: 0.7621\n",
      "Epoch 705/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5071 - binary_accuracy: 0.7817 - val_loss: 0.5558 - val_binary_accuracy: 0.7621\n",
      "Epoch 706/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5070 - binary_accuracy: 0.7817 - val_loss: 0.5558 - val_binary_accuracy: 0.7621\n",
      "Epoch 707/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5069 - binary_accuracy: 0.7817 - val_loss: 0.5557 - val_binary_accuracy: 0.7626\n",
      "Epoch 708/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5068 - binary_accuracy: 0.7819 - val_loss: 0.5557 - val_binary_accuracy: 0.7626\n",
      "Epoch 709/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5068 - binary_accuracy: 0.7821 - val_loss: 0.5557 - val_binary_accuracy: 0.7626\n",
      "Epoch 710/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5067 - binary_accuracy: 0.7821 - val_loss: 0.5556 - val_binary_accuracy: 0.7626\n",
      "Epoch 711/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5066 - binary_accuracy: 0.7821 - val_loss: 0.5556 - val_binary_accuracy: 0.7631\n",
      "Epoch 712/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5065 - binary_accuracy: 0.7821 - val_loss: 0.5556 - val_binary_accuracy: 0.7637\n",
      "Epoch 713/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5065 - binary_accuracy: 0.7821 - val_loss: 0.5555 - val_binary_accuracy: 0.7637\n",
      "Epoch 714/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5064 - binary_accuracy: 0.7821 - val_loss: 0.5555 - val_binary_accuracy: 0.7631\n",
      "Epoch 715/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5063 - binary_accuracy: 0.7819 - val_loss: 0.5555 - val_binary_accuracy: 0.7626\n",
      "Epoch 716/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5062 - binary_accuracy: 0.7819 - val_loss: 0.5554 - val_binary_accuracy: 0.7621\n",
      "Epoch 717/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5062 - binary_accuracy: 0.7819 - val_loss: 0.5554 - val_binary_accuracy: 0.7626\n",
      "Epoch 718/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5061 - binary_accuracy: 0.7824 - val_loss: 0.5554 - val_binary_accuracy: 0.7631\n",
      "Epoch 719/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5060 - binary_accuracy: 0.7824 - val_loss: 0.5553 - val_binary_accuracy: 0.7621\n",
      "Epoch 720/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5060 - binary_accuracy: 0.7830 - val_loss: 0.5553 - val_binary_accuracy: 0.7626\n",
      "Epoch 721/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5059 - binary_accuracy: 0.7830 - val_loss: 0.5552 - val_binary_accuracy: 0.7637\n",
      "Epoch 722/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5058 - binary_accuracy: 0.7830 - val_loss: 0.5552 - val_binary_accuracy: 0.7642\n",
      "Epoch 723/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5058 - binary_accuracy: 0.7830 - val_loss: 0.5552 - val_binary_accuracy: 0.7637\n",
      "Epoch 724/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5057 - binary_accuracy: 0.7830 - val_loss: 0.5551 - val_binary_accuracy: 0.7637\n",
      "Epoch 725/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5056 - binary_accuracy: 0.7830 - val_loss: 0.5551 - val_binary_accuracy: 0.7626\n",
      "Epoch 726/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5055 - binary_accuracy: 0.7828 - val_loss: 0.5551 - val_binary_accuracy: 0.7621\n",
      "Epoch 727/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5054 - binary_accuracy: 0.7824 - val_loss: 0.5550 - val_binary_accuracy: 0.7621\n",
      "Epoch 728/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5054 - binary_accuracy: 0.7821 - val_loss: 0.5550 - val_binary_accuracy: 0.7621\n",
      "Epoch 729/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5053 - binary_accuracy: 0.7821 - val_loss: 0.5549 - val_binary_accuracy: 0.7626\n",
      "Epoch 730/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5052 - binary_accuracy: 0.7821 - val_loss: 0.5549 - val_binary_accuracy: 0.7626\n",
      "Epoch 731/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5052 - binary_accuracy: 0.7821 - val_loss: 0.5549 - val_binary_accuracy: 0.7626\n",
      "Epoch 732/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5051 - binary_accuracy: 0.7824 - val_loss: 0.5548 - val_binary_accuracy: 0.7631\n",
      "Epoch 733/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5050 - binary_accuracy: 0.7831 - val_loss: 0.5548 - val_binary_accuracy: 0.7637\n",
      "Epoch 734/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5049 - binary_accuracy: 0.7833 - val_loss: 0.5548 - val_binary_accuracy: 0.7637\n",
      "Epoch 735/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5049 - binary_accuracy: 0.7840 - val_loss: 0.5548 - val_binary_accuracy: 0.7642\n",
      "Epoch 736/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5048 - binary_accuracy: 0.7839 - val_loss: 0.5547 - val_binary_accuracy: 0.7642\n",
      "Epoch 737/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5047 - binary_accuracy: 0.7833 - val_loss: 0.5547 - val_binary_accuracy: 0.7647\n",
      "Epoch 738/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5046 - binary_accuracy: 0.7835 - val_loss: 0.5546 - val_binary_accuracy: 0.7647\n",
      "Epoch 739/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5046 - binary_accuracy: 0.7839 - val_loss: 0.5546 - val_binary_accuracy: 0.7647\n",
      "Epoch 740/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5045 - binary_accuracy: 0.7840 - val_loss: 0.5545 - val_binary_accuracy: 0.7647\n",
      "Epoch 741/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5044 - binary_accuracy: 0.7839 - val_loss: 0.5545 - val_binary_accuracy: 0.7647\n",
      "Epoch 742/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5044 - binary_accuracy: 0.7839 - val_loss: 0.5544 - val_binary_accuracy: 0.7647\n",
      "Epoch 743/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5043 - binary_accuracy: 0.7839 - val_loss: 0.5544 - val_binary_accuracy: 0.7647\n",
      "Epoch 744/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5042 - binary_accuracy: 0.7840 - val_loss: 0.5544 - val_binary_accuracy: 0.7647\n",
      "Epoch 745/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5041 - binary_accuracy: 0.7842 - val_loss: 0.5544 - val_binary_accuracy: 0.7642\n",
      "Epoch 746/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5041 - binary_accuracy: 0.7842 - val_loss: 0.5543 - val_binary_accuracy: 0.7647\n",
      "Epoch 747/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5040 - binary_accuracy: 0.7842 - val_loss: 0.5543 - val_binary_accuracy: 0.7647\n",
      "Epoch 748/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5039 - binary_accuracy: 0.7840 - val_loss: 0.5542 - val_binary_accuracy: 0.7647\n",
      "Epoch 749/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5039 - binary_accuracy: 0.7840 - val_loss: 0.5542 - val_binary_accuracy: 0.7647\n",
      "Epoch 750/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5038 - binary_accuracy: 0.7840 - val_loss: 0.5542 - val_binary_accuracy: 0.7647\n",
      "Epoch 751/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5037 - binary_accuracy: 0.7847 - val_loss: 0.5541 - val_binary_accuracy: 0.7642\n",
      "Epoch 752/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5036 - binary_accuracy: 0.7847 - val_loss: 0.5541 - val_binary_accuracy: 0.7642\n",
      "Epoch 753/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5036 - binary_accuracy: 0.7849 - val_loss: 0.5541 - val_binary_accuracy: 0.7642\n",
      "Epoch 754/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5035 - binary_accuracy: 0.7851 - val_loss: 0.5540 - val_binary_accuracy: 0.7642\n",
      "Epoch 755/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5034 - binary_accuracy: 0.7853 - val_loss: 0.5540 - val_binary_accuracy: 0.7647\n",
      "Epoch 756/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5034 - binary_accuracy: 0.7854 - val_loss: 0.5540 - val_binary_accuracy: 0.7647\n",
      "Epoch 757/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5033 - binary_accuracy: 0.7853 - val_loss: 0.5539 - val_binary_accuracy: 0.7652\n",
      "Epoch 758/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5032 - binary_accuracy: 0.7854 - val_loss: 0.5539 - val_binary_accuracy: 0.7647\n",
      "Epoch 759/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5032 - binary_accuracy: 0.7854 - val_loss: 0.5539 - val_binary_accuracy: 0.7647\n",
      "Epoch 760/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5031 - binary_accuracy: 0.7856 - val_loss: 0.5538 - val_binary_accuracy: 0.7647\n",
      "Epoch 761/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5030 - binary_accuracy: 0.7853 - val_loss: 0.5538 - val_binary_accuracy: 0.7647\n",
      "Epoch 762/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5029 - binary_accuracy: 0.7853 - val_loss: 0.5537 - val_binary_accuracy: 0.7647\n",
      "Epoch 763/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5029 - binary_accuracy: 0.7856 - val_loss: 0.5537 - val_binary_accuracy: 0.7647\n",
      "Epoch 764/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5028 - binary_accuracy: 0.7858 - val_loss: 0.5537 - val_binary_accuracy: 0.7647\n",
      "Epoch 765/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5027 - binary_accuracy: 0.7856 - val_loss: 0.5536 - val_binary_accuracy: 0.7647\n",
      "Epoch 766/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5027 - binary_accuracy: 0.7856 - val_loss: 0.5536 - val_binary_accuracy: 0.7642\n",
      "Epoch 767/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5026 - binary_accuracy: 0.7854 - val_loss: 0.5536 - val_binary_accuracy: 0.7642\n",
      "Epoch 768/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5025 - binary_accuracy: 0.7854 - val_loss: 0.5535 - val_binary_accuracy: 0.7642\n",
      "Epoch 769/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5024 - binary_accuracy: 0.7858 - val_loss: 0.5535 - val_binary_accuracy: 0.7642\n",
      "Epoch 770/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5024 - binary_accuracy: 0.7858 - val_loss: 0.5535 - val_binary_accuracy: 0.7647\n",
      "Epoch 771/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5023 - binary_accuracy: 0.7858 - val_loss: 0.5535 - val_binary_accuracy: 0.7647\n",
      "Epoch 772/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5022 - binary_accuracy: 0.7858 - val_loss: 0.5534 - val_binary_accuracy: 0.7652\n",
      "Epoch 773/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5022 - binary_accuracy: 0.7860 - val_loss: 0.5534 - val_binary_accuracy: 0.7647\n",
      "Epoch 774/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5021 - binary_accuracy: 0.7860 - val_loss: 0.5533 - val_binary_accuracy: 0.7652\n",
      "Epoch 775/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5020 - binary_accuracy: 0.7858 - val_loss: 0.5533 - val_binary_accuracy: 0.7652\n",
      "Epoch 776/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5020 - binary_accuracy: 0.7860 - val_loss: 0.5533 - val_binary_accuracy: 0.7652\n",
      "Epoch 777/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5019 - binary_accuracy: 0.7858 - val_loss: 0.5532 - val_binary_accuracy: 0.7652\n",
      "Epoch 778/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5018 - binary_accuracy: 0.7858 - val_loss: 0.5532 - val_binary_accuracy: 0.7652\n",
      "Epoch 779/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5018 - binary_accuracy: 0.7860 - val_loss: 0.5532 - val_binary_accuracy: 0.7658\n",
      "Epoch 780/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5017 - binary_accuracy: 0.7863 - val_loss: 0.5531 - val_binary_accuracy: 0.7658\n",
      "Epoch 781/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5016 - binary_accuracy: 0.7863 - val_loss: 0.5531 - val_binary_accuracy: 0.7658\n",
      "Epoch 782/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5015 - binary_accuracy: 0.7863 - val_loss: 0.5531 - val_binary_accuracy: 0.7658\n",
      "Epoch 783/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5015 - binary_accuracy: 0.7863 - val_loss: 0.5530 - val_binary_accuracy: 0.7658\n",
      "Epoch 784/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5014 - binary_accuracy: 0.7863 - val_loss: 0.5530 - val_binary_accuracy: 0.7658\n",
      "Epoch 785/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5013 - binary_accuracy: 0.7863 - val_loss: 0.5529 - val_binary_accuracy: 0.7658\n",
      "Epoch 786/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5013 - binary_accuracy: 0.7863 - val_loss: 0.5529 - val_binary_accuracy: 0.7658\n",
      "Epoch 787/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5012 - binary_accuracy: 0.7861 - val_loss: 0.5529 - val_binary_accuracy: 0.7658\n",
      "Epoch 788/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5011 - binary_accuracy: 0.7861 - val_loss: 0.5528 - val_binary_accuracy: 0.7658\n",
      "Epoch 789/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5011 - binary_accuracy: 0.7861 - val_loss: 0.5528 - val_binary_accuracy: 0.7663\n",
      "Epoch 790/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5010 - binary_accuracy: 0.7861 - val_loss: 0.5528 - val_binary_accuracy: 0.7663\n",
      "Epoch 791/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5009 - binary_accuracy: 0.7865 - val_loss: 0.5527 - val_binary_accuracy: 0.7663\n",
      "Epoch 792/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5009 - binary_accuracy: 0.7865 - val_loss: 0.5527 - val_binary_accuracy: 0.7663\n",
      "Epoch 793/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5008 - binary_accuracy: 0.7867 - val_loss: 0.5527 - val_binary_accuracy: 0.7668\n",
      "Epoch 794/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5007 - binary_accuracy: 0.7865 - val_loss: 0.5527 - val_binary_accuracy: 0.7668\n",
      "Epoch 795/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5007 - binary_accuracy: 0.7867 - val_loss: 0.5526 - val_binary_accuracy: 0.7673\n",
      "Epoch 796/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5006 - binary_accuracy: 0.7867 - val_loss: 0.5526 - val_binary_accuracy: 0.7673\n",
      "Epoch 797/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5005 - binary_accuracy: 0.7867 - val_loss: 0.5526 - val_binary_accuracy: 0.7668\n",
      "Epoch 798/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5004 - binary_accuracy: 0.7867 - val_loss: 0.5525 - val_binary_accuracy: 0.7668\n",
      "Epoch 799/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5004 - binary_accuracy: 0.7867 - val_loss: 0.5525 - val_binary_accuracy: 0.7668\n",
      "Epoch 800/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5003 - binary_accuracy: 0.7868 - val_loss: 0.5525 - val_binary_accuracy: 0.7668\n",
      "Epoch 801/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5002 - binary_accuracy: 0.7870 - val_loss: 0.5525 - val_binary_accuracy: 0.7668\n",
      "Epoch 802/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5002 - binary_accuracy: 0.7870 - val_loss: 0.5525 - val_binary_accuracy: 0.7668\n",
      "Epoch 803/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5001 - binary_accuracy: 0.7872 - val_loss: 0.5524 - val_binary_accuracy: 0.7668\n",
      "Epoch 804/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5000 - binary_accuracy: 0.7872 - val_loss: 0.5524 - val_binary_accuracy: 0.7668\n",
      "Epoch 805/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5000 - binary_accuracy: 0.7870 - val_loss: 0.5524 - val_binary_accuracy: 0.7668\n",
      "Epoch 806/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4999 - binary_accuracy: 0.7872 - val_loss: 0.5524 - val_binary_accuracy: 0.7668\n",
      "Epoch 807/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4998 - binary_accuracy: 0.7874 - val_loss: 0.5523 - val_binary_accuracy: 0.7663\n",
      "Epoch 808/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4998 - binary_accuracy: 0.7870 - val_loss: 0.5523 - val_binary_accuracy: 0.7663\n",
      "Epoch 809/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4997 - binary_accuracy: 0.7872 - val_loss: 0.5523 - val_binary_accuracy: 0.7663\n",
      "Epoch 810/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4996 - binary_accuracy: 0.7874 - val_loss: 0.5522 - val_binary_accuracy: 0.7663\n",
      "Epoch 811/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4996 - binary_accuracy: 0.7881 - val_loss: 0.5522 - val_binary_accuracy: 0.7663\n",
      "Epoch 812/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4995 - binary_accuracy: 0.7879 - val_loss: 0.5522 - val_binary_accuracy: 0.7663\n",
      "Epoch 813/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4994 - binary_accuracy: 0.7879 - val_loss: 0.5521 - val_binary_accuracy: 0.7663\n",
      "Epoch 814/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4994 - binary_accuracy: 0.7879 - val_loss: 0.5521 - val_binary_accuracy: 0.7658\n",
      "Epoch 815/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4993 - binary_accuracy: 0.7884 - val_loss: 0.5521 - val_binary_accuracy: 0.7658\n",
      "Epoch 816/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4992 - binary_accuracy: 0.7886 - val_loss: 0.5520 - val_binary_accuracy: 0.7668\n",
      "Epoch 817/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4992 - binary_accuracy: 0.7884 - val_loss: 0.5520 - val_binary_accuracy: 0.7668\n",
      "Epoch 818/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4991 - binary_accuracy: 0.7882 - val_loss: 0.5520 - val_binary_accuracy: 0.7668\n",
      "Epoch 819/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4990 - binary_accuracy: 0.7884 - val_loss: 0.5519 - val_binary_accuracy: 0.7668\n",
      "Epoch 820/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4990 - binary_accuracy: 0.7884 - val_loss: 0.5519 - val_binary_accuracy: 0.7668\n",
      "Epoch 821/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4989 - binary_accuracy: 0.7884 - val_loss: 0.5519 - val_binary_accuracy: 0.7668\n",
      "Epoch 822/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4988 - binary_accuracy: 0.7886 - val_loss: 0.5519 - val_binary_accuracy: 0.7668\n",
      "Epoch 823/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4988 - binary_accuracy: 0.7884 - val_loss: 0.5518 - val_binary_accuracy: 0.7663\n",
      "Epoch 824/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4987 - binary_accuracy: 0.7884 - val_loss: 0.5518 - val_binary_accuracy: 0.7663\n",
      "Epoch 825/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4986 - binary_accuracy: 0.7886 - val_loss: 0.5518 - val_binary_accuracy: 0.7663\n",
      "Epoch 826/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4986 - binary_accuracy: 0.7888 - val_loss: 0.5518 - val_binary_accuracy: 0.7663\n",
      "Epoch 827/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4985 - binary_accuracy: 0.7888 - val_loss: 0.5518 - val_binary_accuracy: 0.7663\n",
      "Epoch 828/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4984 - binary_accuracy: 0.7889 - val_loss: 0.5517 - val_binary_accuracy: 0.7663\n",
      "Epoch 829/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4984 - binary_accuracy: 0.7888 - val_loss: 0.5517 - val_binary_accuracy: 0.7663\n",
      "Epoch 830/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4983 - binary_accuracy: 0.7888 - val_loss: 0.5516 - val_binary_accuracy: 0.7663\n",
      "Epoch 831/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4982 - binary_accuracy: 0.7886 - val_loss: 0.5516 - val_binary_accuracy: 0.7663\n",
      "Epoch 832/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4982 - binary_accuracy: 0.7889 - val_loss: 0.5516 - val_binary_accuracy: 0.7663\n",
      "Epoch 833/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4981 - binary_accuracy: 0.7889 - val_loss: 0.5515 - val_binary_accuracy: 0.7668\n",
      "Epoch 834/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4980 - binary_accuracy: 0.7889 - val_loss: 0.5515 - val_binary_accuracy: 0.7668\n",
      "Epoch 835/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4980 - binary_accuracy: 0.7893 - val_loss: 0.5515 - val_binary_accuracy: 0.7668\n",
      "Epoch 836/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4979 - binary_accuracy: 0.7889 - val_loss: 0.5514 - val_binary_accuracy: 0.7663\n",
      "Epoch 837/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4978 - binary_accuracy: 0.7891 - val_loss: 0.5514 - val_binary_accuracy: 0.7663\n",
      "Epoch 838/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4978 - binary_accuracy: 0.7893 - val_loss: 0.5514 - val_binary_accuracy: 0.7668\n",
      "Epoch 839/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4977 - binary_accuracy: 0.7893 - val_loss: 0.5513 - val_binary_accuracy: 0.7668\n",
      "Epoch 840/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4976 - binary_accuracy: 0.7895 - val_loss: 0.5513 - val_binary_accuracy: 0.7673\n",
      "Epoch 841/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4976 - binary_accuracy: 0.7893 - val_loss: 0.5513 - val_binary_accuracy: 0.7663\n",
      "Epoch 842/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4975 - binary_accuracy: 0.7895 - val_loss: 0.5512 - val_binary_accuracy: 0.7668\n",
      "Epoch 843/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4975 - binary_accuracy: 0.7895 - val_loss: 0.5512 - val_binary_accuracy: 0.7668\n",
      "Epoch 844/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4974 - binary_accuracy: 0.7895 - val_loss: 0.5512 - val_binary_accuracy: 0.7663\n",
      "Epoch 845/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4973 - binary_accuracy: 0.7895 - val_loss: 0.5512 - val_binary_accuracy: 0.7668\n",
      "Epoch 846/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4973 - binary_accuracy: 0.7895 - val_loss: 0.5511 - val_binary_accuracy: 0.7668\n",
      "Epoch 847/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4972 - binary_accuracy: 0.7895 - val_loss: 0.5511 - val_binary_accuracy: 0.7668\n",
      "Epoch 848/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4971 - binary_accuracy: 0.7896 - val_loss: 0.5511 - val_binary_accuracy: 0.7673\n",
      "Epoch 849/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4971 - binary_accuracy: 0.7895 - val_loss: 0.5511 - val_binary_accuracy: 0.7668\n",
      "Epoch 850/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4970 - binary_accuracy: 0.7898 - val_loss: 0.5510 - val_binary_accuracy: 0.7668\n",
      "Epoch 851/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4969 - binary_accuracy: 0.7902 - val_loss: 0.5510 - val_binary_accuracy: 0.7679\n",
      "Epoch 852/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4969 - binary_accuracy: 0.7903 - val_loss: 0.5510 - val_binary_accuracy: 0.7679\n",
      "Epoch 853/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4968 - binary_accuracy: 0.7907 - val_loss: 0.5509 - val_binary_accuracy: 0.7684\n",
      "Epoch 854/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4967 - binary_accuracy: 0.7907 - val_loss: 0.5509 - val_binary_accuracy: 0.7684\n",
      "Epoch 855/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4967 - binary_accuracy: 0.7909 - val_loss: 0.5509 - val_binary_accuracy: 0.7684\n",
      "Epoch 856/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4966 - binary_accuracy: 0.7909 - val_loss: 0.5509 - val_binary_accuracy: 0.7684\n",
      "Epoch 857/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4966 - binary_accuracy: 0.7907 - val_loss: 0.5508 - val_binary_accuracy: 0.7684\n",
      "Epoch 858/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4965 - binary_accuracy: 0.7907 - val_loss: 0.5508 - val_binary_accuracy: 0.7684\n",
      "Epoch 859/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4964 - binary_accuracy: 0.7907 - val_loss: 0.5508 - val_binary_accuracy: 0.7689\n",
      "Epoch 860/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4964 - binary_accuracy: 0.7910 - val_loss: 0.5507 - val_binary_accuracy: 0.7689\n",
      "Epoch 861/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4963 - binary_accuracy: 0.7914 - val_loss: 0.5507 - val_binary_accuracy: 0.7689\n",
      "Epoch 862/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4962 - binary_accuracy: 0.7914 - val_loss: 0.5507 - val_binary_accuracy: 0.7694\n",
      "Epoch 863/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4962 - binary_accuracy: 0.7914 - val_loss: 0.5506 - val_binary_accuracy: 0.7694\n",
      "Epoch 864/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4961 - binary_accuracy: 0.7910 - val_loss: 0.5506 - val_binary_accuracy: 0.7694\n",
      "Epoch 865/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4960 - binary_accuracy: 0.7912 - val_loss: 0.5506 - val_binary_accuracy: 0.7694\n",
      "Epoch 866/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4960 - binary_accuracy: 0.7912 - val_loss: 0.5505 - val_binary_accuracy: 0.7689\n",
      "Epoch 867/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4959 - binary_accuracy: 0.7914 - val_loss: 0.5505 - val_binary_accuracy: 0.7689\n",
      "Epoch 868/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4959 - binary_accuracy: 0.7912 - val_loss: 0.5505 - val_binary_accuracy: 0.7689\n",
      "Epoch 869/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4958 - binary_accuracy: 0.7914 - val_loss: 0.5504 - val_binary_accuracy: 0.7689\n",
      "Epoch 870/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4957 - binary_accuracy: 0.7914 - val_loss: 0.5504 - val_binary_accuracy: 0.7689\n",
      "Epoch 871/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4957 - binary_accuracy: 0.7916 - val_loss: 0.5504 - val_binary_accuracy: 0.7689\n",
      "Epoch 872/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4956 - binary_accuracy: 0.7916 - val_loss: 0.5503 - val_binary_accuracy: 0.7689\n",
      "Epoch 873/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4955 - binary_accuracy: 0.7916 - val_loss: 0.5503 - val_binary_accuracy: 0.7689\n",
      "Epoch 874/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4955 - binary_accuracy: 0.7916 - val_loss: 0.5503 - val_binary_accuracy: 0.7689\n",
      "Epoch 875/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4954 - binary_accuracy: 0.7916 - val_loss: 0.5502 - val_binary_accuracy: 0.7689\n",
      "Epoch 876/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4953 - binary_accuracy: 0.7923 - val_loss: 0.5502 - val_binary_accuracy: 0.7689\n",
      "Epoch 877/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4953 - binary_accuracy: 0.7930 - val_loss: 0.5502 - val_binary_accuracy: 0.7689\n",
      "Epoch 878/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4952 - binary_accuracy: 0.7928 - val_loss: 0.5502 - val_binary_accuracy: 0.7684\n",
      "Epoch 879/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4952 - binary_accuracy: 0.7928 - val_loss: 0.5501 - val_binary_accuracy: 0.7684\n",
      "Epoch 880/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4951 - binary_accuracy: 0.7930 - val_loss: 0.5501 - val_binary_accuracy: 0.7684\n",
      "Epoch 881/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4950 - binary_accuracy: 0.7930 - val_loss: 0.5501 - val_binary_accuracy: 0.7684\n",
      "Epoch 882/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4950 - binary_accuracy: 0.7931 - val_loss: 0.5501 - val_binary_accuracy: 0.7684\n",
      "Epoch 883/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4949 - binary_accuracy: 0.7928 - val_loss: 0.5500 - val_binary_accuracy: 0.7684\n",
      "Epoch 884/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4948 - binary_accuracy: 0.7930 - val_loss: 0.5500 - val_binary_accuracy: 0.7684\n",
      "Epoch 885/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4948 - binary_accuracy: 0.7935 - val_loss: 0.5500 - val_binary_accuracy: 0.7689\n",
      "Epoch 886/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4947 - binary_accuracy: 0.7935 - val_loss: 0.5500 - val_binary_accuracy: 0.7689\n",
      "Epoch 887/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4947 - binary_accuracy: 0.7935 - val_loss: 0.5499 - val_binary_accuracy: 0.7689\n",
      "Epoch 888/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4946 - binary_accuracy: 0.7935 - val_loss: 0.5499 - val_binary_accuracy: 0.7689\n",
      "Epoch 889/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4945 - binary_accuracy: 0.7931 - val_loss: 0.5499 - val_binary_accuracy: 0.7689\n",
      "Epoch 890/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4945 - binary_accuracy: 0.7931 - val_loss: 0.5499 - val_binary_accuracy: 0.7689\n",
      "Epoch 891/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4944 - binary_accuracy: 0.7931 - val_loss: 0.5498 - val_binary_accuracy: 0.7689\n",
      "Epoch 892/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4943 - binary_accuracy: 0.7930 - val_loss: 0.5498 - val_binary_accuracy: 0.7684\n",
      "Epoch 893/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4943 - binary_accuracy: 0.7930 - val_loss: 0.5497 - val_binary_accuracy: 0.7684\n",
      "Epoch 894/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4942 - binary_accuracy: 0.7930 - val_loss: 0.5497 - val_binary_accuracy: 0.7689\n",
      "Epoch 895/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4942 - binary_accuracy: 0.7930 - val_loss: 0.5497 - val_binary_accuracy: 0.7689\n",
      "Epoch 896/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4941 - binary_accuracy: 0.7931 - val_loss: 0.5496 - val_binary_accuracy: 0.7689\n",
      "Epoch 897/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4940 - binary_accuracy: 0.7931 - val_loss: 0.5496 - val_binary_accuracy: 0.7689\n",
      "Epoch 898/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4940 - binary_accuracy: 0.7930 - val_loss: 0.5496 - val_binary_accuracy: 0.7689\n",
      "Epoch 899/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4939 - binary_accuracy: 0.7933 - val_loss: 0.5496 - val_binary_accuracy: 0.7689\n",
      "Epoch 900/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4938 - binary_accuracy: 0.7937 - val_loss: 0.5495 - val_binary_accuracy: 0.7689\n",
      "Epoch 901/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4938 - binary_accuracy: 0.7940 - val_loss: 0.5495 - val_binary_accuracy: 0.7694\n",
      "Epoch 902/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4937 - binary_accuracy: 0.7938 - val_loss: 0.5495 - val_binary_accuracy: 0.7694\n",
      "Epoch 903/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4937 - binary_accuracy: 0.7938 - val_loss: 0.5494 - val_binary_accuracy: 0.7689\n",
      "Epoch 904/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4936 - binary_accuracy: 0.7937 - val_loss: 0.5494 - val_binary_accuracy: 0.7689\n",
      "Epoch 905/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4935 - binary_accuracy: 0.7938 - val_loss: 0.5494 - val_binary_accuracy: 0.7689\n",
      "Epoch 906/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4935 - binary_accuracy: 0.7940 - val_loss: 0.5493 - val_binary_accuracy: 0.7684\n",
      "Epoch 907/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4934 - binary_accuracy: 0.7938 - val_loss: 0.5493 - val_binary_accuracy: 0.7684\n",
      "Epoch 908/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4934 - binary_accuracy: 0.7937 - val_loss: 0.5493 - val_binary_accuracy: 0.7684\n",
      "Epoch 909/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4933 - binary_accuracy: 0.7942 - val_loss: 0.5492 - val_binary_accuracy: 0.7689\n",
      "Epoch 910/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4932 - binary_accuracy: 0.7940 - val_loss: 0.5492 - val_binary_accuracy: 0.7689\n",
      "Epoch 911/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4932 - binary_accuracy: 0.7942 - val_loss: 0.5491 - val_binary_accuracy: 0.7700\n",
      "Epoch 912/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4931 - binary_accuracy: 0.7942 - val_loss: 0.5491 - val_binary_accuracy: 0.7694\n",
      "Epoch 913/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4931 - binary_accuracy: 0.7944 - val_loss: 0.5491 - val_binary_accuracy: 0.7700\n",
      "Epoch 914/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4930 - binary_accuracy: 0.7944 - val_loss: 0.5491 - val_binary_accuracy: 0.7705\n",
      "Epoch 915/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4929 - binary_accuracy: 0.7945 - val_loss: 0.5490 - val_binary_accuracy: 0.7705\n",
      "Epoch 916/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4929 - binary_accuracy: 0.7947 - val_loss: 0.5490 - val_binary_accuracy: 0.7705\n",
      "Epoch 917/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4928 - binary_accuracy: 0.7952 - val_loss: 0.5490 - val_binary_accuracy: 0.7705\n",
      "Epoch 918/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4927 - binary_accuracy: 0.7951 - val_loss: 0.5490 - val_binary_accuracy: 0.7705\n",
      "Epoch 919/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4927 - binary_accuracy: 0.7956 - val_loss: 0.5490 - val_binary_accuracy: 0.7705\n",
      "Epoch 920/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4926 - binary_accuracy: 0.7958 - val_loss: 0.5490 - val_binary_accuracy: 0.7710\n",
      "Epoch 921/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4926 - binary_accuracy: 0.7958 - val_loss: 0.5489 - val_binary_accuracy: 0.7710\n",
      "Epoch 922/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4925 - binary_accuracy: 0.7954 - val_loss: 0.5489 - val_binary_accuracy: 0.7705\n",
      "Epoch 923/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4924 - binary_accuracy: 0.7952 - val_loss: 0.5489 - val_binary_accuracy: 0.7710\n",
      "Epoch 924/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4924 - binary_accuracy: 0.7958 - val_loss: 0.5489 - val_binary_accuracy: 0.7710\n",
      "Epoch 925/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4923 - binary_accuracy: 0.7959 - val_loss: 0.5489 - val_binary_accuracy: 0.7710\n",
      "Epoch 926/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4923 - binary_accuracy: 0.7958 - val_loss: 0.5488 - val_binary_accuracy: 0.7705\n",
      "Epoch 927/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4922 - binary_accuracy: 0.7961 - val_loss: 0.5488 - val_binary_accuracy: 0.7694\n",
      "Epoch 928/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4921 - binary_accuracy: 0.7956 - val_loss: 0.5488 - val_binary_accuracy: 0.7694\n",
      "Epoch 929/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4921 - binary_accuracy: 0.7952 - val_loss: 0.5487 - val_binary_accuracy: 0.7694\n",
      "Epoch 930/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4920 - binary_accuracy: 0.7959 - val_loss: 0.5487 - val_binary_accuracy: 0.7694\n",
      "Epoch 931/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4920 - binary_accuracy: 0.7965 - val_loss: 0.5487 - val_binary_accuracy: 0.7721\n",
      "Epoch 932/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4919 - binary_accuracy: 0.7965 - val_loss: 0.5486 - val_binary_accuracy: 0.7721\n",
      "Epoch 933/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4918 - binary_accuracy: 0.7965 - val_loss: 0.5486 - val_binary_accuracy: 0.7721\n",
      "Epoch 934/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4918 - binary_accuracy: 0.7965 - val_loss: 0.5486 - val_binary_accuracy: 0.7726\n",
      "Epoch 935/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4917 - binary_accuracy: 0.7965 - val_loss: 0.5485 - val_binary_accuracy: 0.7721\n",
      "Epoch 936/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4917 - binary_accuracy: 0.7966 - val_loss: 0.5485 - val_binary_accuracy: 0.7721\n",
      "Epoch 937/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4916 - binary_accuracy: 0.7966 - val_loss: 0.5485 - val_binary_accuracy: 0.7721\n",
      "Epoch 938/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4915 - binary_accuracy: 0.7966 - val_loss: 0.5484 - val_binary_accuracy: 0.7715\n",
      "Epoch 939/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4915 - binary_accuracy: 0.7966 - val_loss: 0.5484 - val_binary_accuracy: 0.7710\n",
      "Epoch 940/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4914 - binary_accuracy: 0.7968 - val_loss: 0.5484 - val_binary_accuracy: 0.7710\n",
      "Epoch 941/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4914 - binary_accuracy: 0.7966 - val_loss: 0.5483 - val_binary_accuracy: 0.7710\n",
      "Epoch 942/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4913 - binary_accuracy: 0.7965 - val_loss: 0.5483 - val_binary_accuracy: 0.7715\n",
      "Epoch 943/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4913 - binary_accuracy: 0.7966 - val_loss: 0.5483 - val_binary_accuracy: 0.7721\n",
      "Epoch 944/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4912 - binary_accuracy: 0.7966 - val_loss: 0.5483 - val_binary_accuracy: 0.7726\n",
      "Epoch 945/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4911 - binary_accuracy: 0.7970 - val_loss: 0.5482 - val_binary_accuracy: 0.7715\n",
      "Epoch 946/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4911 - binary_accuracy: 0.7970 - val_loss: 0.5482 - val_binary_accuracy: 0.7721\n",
      "Epoch 947/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4910 - binary_accuracy: 0.7968 - val_loss: 0.5482 - val_binary_accuracy: 0.7721\n",
      "Epoch 948/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4910 - binary_accuracy: 0.7966 - val_loss: 0.5481 - val_binary_accuracy: 0.7721\n",
      "Epoch 949/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4909 - binary_accuracy: 0.7965 - val_loss: 0.5481 - val_binary_accuracy: 0.7721\n",
      "Epoch 950/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4908 - binary_accuracy: 0.7965 - val_loss: 0.5481 - val_binary_accuracy: 0.7721\n",
      "Epoch 951/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4908 - binary_accuracy: 0.7965 - val_loss: 0.5481 - val_binary_accuracy: 0.7715\n",
      "Epoch 952/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4907 - binary_accuracy: 0.7966 - val_loss: 0.5481 - val_binary_accuracy: 0.7721\n",
      "Epoch 953/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4907 - binary_accuracy: 0.7968 - val_loss: 0.5480 - val_binary_accuracy: 0.7721\n",
      "Epoch 954/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4906 - binary_accuracy: 0.7970 - val_loss: 0.5480 - val_binary_accuracy: 0.7731\n",
      "Epoch 955/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4906 - binary_accuracy: 0.7972 - val_loss: 0.5480 - val_binary_accuracy: 0.7731\n",
      "Epoch 956/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4905 - binary_accuracy: 0.7973 - val_loss: 0.5480 - val_binary_accuracy: 0.7726\n",
      "Epoch 957/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4904 - binary_accuracy: 0.7973 - val_loss: 0.5480 - val_binary_accuracy: 0.7721\n",
      "Epoch 958/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4904 - binary_accuracy: 0.7977 - val_loss: 0.5479 - val_binary_accuracy: 0.7731\n",
      "Epoch 959/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4903 - binary_accuracy: 0.7977 - val_loss: 0.5479 - val_binary_accuracy: 0.7731\n",
      "Epoch 960/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4903 - binary_accuracy: 0.7977 - val_loss: 0.5479 - val_binary_accuracy: 0.7726\n",
      "Epoch 961/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4902 - binary_accuracy: 0.7979 - val_loss: 0.5478 - val_binary_accuracy: 0.7726\n",
      "Epoch 962/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4901 - binary_accuracy: 0.7979 - val_loss: 0.5478 - val_binary_accuracy: 0.7721\n",
      "Epoch 963/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4901 - binary_accuracy: 0.7979 - val_loss: 0.5478 - val_binary_accuracy: 0.7726\n",
      "Epoch 964/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4900 - binary_accuracy: 0.7977 - val_loss: 0.5477 - val_binary_accuracy: 0.7726\n",
      "Epoch 965/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4900 - binary_accuracy: 0.7977 - val_loss: 0.5477 - val_binary_accuracy: 0.7726\n",
      "Epoch 966/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4899 - binary_accuracy: 0.7977 - val_loss: 0.5477 - val_binary_accuracy: 0.7726\n",
      "Epoch 967/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4899 - binary_accuracy: 0.7977 - val_loss: 0.5477 - val_binary_accuracy: 0.7726\n",
      "Epoch 968/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4898 - binary_accuracy: 0.7979 - val_loss: 0.5477 - val_binary_accuracy: 0.7731\n",
      "Epoch 969/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4897 - binary_accuracy: 0.7979 - val_loss: 0.5476 - val_binary_accuracy: 0.7731\n",
      "Epoch 970/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4897 - binary_accuracy: 0.7979 - val_loss: 0.5476 - val_binary_accuracy: 0.7731\n",
      "Epoch 971/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4896 - binary_accuracy: 0.7979 - val_loss: 0.5475 - val_binary_accuracy: 0.7731\n",
      "Epoch 972/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4896 - binary_accuracy: 0.7979 - val_loss: 0.5475 - val_binary_accuracy: 0.7731\n",
      "Epoch 973/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4895 - binary_accuracy: 0.7980 - val_loss: 0.5475 - val_binary_accuracy: 0.7731\n",
      "Epoch 974/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4894 - binary_accuracy: 0.7982 - val_loss: 0.5475 - val_binary_accuracy: 0.7731\n",
      "Epoch 975/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4894 - binary_accuracy: 0.7982 - val_loss: 0.5474 - val_binary_accuracy: 0.7736\n",
      "Epoch 976/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4893 - binary_accuracy: 0.7982 - val_loss: 0.5474 - val_binary_accuracy: 0.7731\n",
      "Epoch 977/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4893 - binary_accuracy: 0.7982 - val_loss: 0.5474 - val_binary_accuracy: 0.7731\n",
      "Epoch 978/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4892 - binary_accuracy: 0.7984 - val_loss: 0.5474 - val_binary_accuracy: 0.7736\n",
      "Epoch 979/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4892 - binary_accuracy: 0.7984 - val_loss: 0.5473 - val_binary_accuracy: 0.7731\n",
      "Epoch 980/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4891 - binary_accuracy: 0.7982 - val_loss: 0.5473 - val_binary_accuracy: 0.7731\n",
      "Epoch 981/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4890 - binary_accuracy: 0.7982 - val_loss: 0.5473 - val_binary_accuracy: 0.7731\n",
      "Epoch 982/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4890 - binary_accuracy: 0.7986 - val_loss: 0.5473 - val_binary_accuracy: 0.7726\n",
      "Epoch 983/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4889 - binary_accuracy: 0.7986 - val_loss: 0.5472 - val_binary_accuracy: 0.7731\n",
      "Epoch 984/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4889 - binary_accuracy: 0.7986 - val_loss: 0.5472 - val_binary_accuracy: 0.7731\n",
      "Epoch 985/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4888 - binary_accuracy: 0.7984 - val_loss: 0.5472 - val_binary_accuracy: 0.7731\n",
      "Epoch 986/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4888 - binary_accuracy: 0.7986 - val_loss: 0.5472 - val_binary_accuracy: 0.7731\n",
      "Epoch 987/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4887 - binary_accuracy: 0.7984 - val_loss: 0.5471 - val_binary_accuracy: 0.7731\n",
      "Epoch 988/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4887 - binary_accuracy: 0.7986 - val_loss: 0.5471 - val_binary_accuracy: 0.7731\n",
      "Epoch 989/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4886 - binary_accuracy: 0.7984 - val_loss: 0.5471 - val_binary_accuracy: 0.7731\n",
      "Epoch 990/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4885 - binary_accuracy: 0.7984 - val_loss: 0.5471 - val_binary_accuracy: 0.7731\n",
      "Epoch 991/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4885 - binary_accuracy: 0.7986 - val_loss: 0.5470 - val_binary_accuracy: 0.7731\n",
      "Epoch 992/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4884 - binary_accuracy: 0.7986 - val_loss: 0.5470 - val_binary_accuracy: 0.7731\n",
      "Epoch 993/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4884 - binary_accuracy: 0.7986 - val_loss: 0.5469 - val_binary_accuracy: 0.7731\n",
      "Epoch 994/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4883 - binary_accuracy: 0.7987 - val_loss: 0.5469 - val_binary_accuracy: 0.7742\n",
      "Epoch 995/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4883 - binary_accuracy: 0.7986 - val_loss: 0.5469 - val_binary_accuracy: 0.7742\n",
      "Epoch 996/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4882 - binary_accuracy: 0.7987 - val_loss: 0.5469 - val_binary_accuracy: 0.7742\n",
      "Epoch 997/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4881 - binary_accuracy: 0.7984 - val_loss: 0.5468 - val_binary_accuracy: 0.7742\n",
      "Epoch 998/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4881 - binary_accuracy: 0.7987 - val_loss: 0.5468 - val_binary_accuracy: 0.7742\n",
      "Epoch 999/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4880 - binary_accuracy: 0.7987 - val_loss: 0.5468 - val_binary_accuracy: 0.7742\n",
      "Epoch 1000/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4880 - binary_accuracy: 0.7993 - val_loss: 0.5467 - val_binary_accuracy: 0.7742\n",
      "Epoch 1001/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4879 - binary_accuracy: 0.7993 - val_loss: 0.5467 - val_binary_accuracy: 0.7752\n",
      "Epoch 1002/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4879 - binary_accuracy: 0.7994 - val_loss: 0.5467 - val_binary_accuracy: 0.7747\n",
      "Epoch 1003/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4878 - binary_accuracy: 0.7994 - val_loss: 0.5467 - val_binary_accuracy: 0.7747\n",
      "Epoch 1004/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4878 - binary_accuracy: 0.7993 - val_loss: 0.5466 - val_binary_accuracy: 0.7747\n",
      "Epoch 1005/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4877 - binary_accuracy: 0.7993 - val_loss: 0.5466 - val_binary_accuracy: 0.7747\n",
      "Epoch 1006/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4876 - binary_accuracy: 0.7991 - val_loss: 0.5466 - val_binary_accuracy: 0.7752\n",
      "Epoch 1007/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4876 - binary_accuracy: 0.7993 - val_loss: 0.5466 - val_binary_accuracy: 0.7752\n",
      "Epoch 1008/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4875 - binary_accuracy: 0.7994 - val_loss: 0.5465 - val_binary_accuracy: 0.7752\n",
      "Epoch 1009/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4875 - binary_accuracy: 0.7993 - val_loss: 0.5465 - val_binary_accuracy: 0.7763\n",
      "Epoch 1010/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4874 - binary_accuracy: 0.7998 - val_loss: 0.5465 - val_binary_accuracy: 0.7763\n",
      "Epoch 1011/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4874 - binary_accuracy: 0.8000 - val_loss: 0.5465 - val_binary_accuracy: 0.7768\n",
      "Epoch 1012/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4873 - binary_accuracy: 0.8000 - val_loss: 0.5465 - val_binary_accuracy: 0.7768\n",
      "Epoch 1013/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4873 - binary_accuracy: 0.7996 - val_loss: 0.5464 - val_binary_accuracy: 0.7763\n",
      "Epoch 1014/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4872 - binary_accuracy: 0.7994 - val_loss: 0.5464 - val_binary_accuracy: 0.7763\n",
      "Epoch 1015/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4871 - binary_accuracy: 0.7991 - val_loss: 0.5464 - val_binary_accuracy: 0.7757\n",
      "Epoch 1016/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4871 - binary_accuracy: 0.7993 - val_loss: 0.5463 - val_binary_accuracy: 0.7757\n",
      "Epoch 1017/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4870 - binary_accuracy: 0.7994 - val_loss: 0.5463 - val_binary_accuracy: 0.7757\n",
      "Epoch 1018/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4870 - binary_accuracy: 0.7994 - val_loss: 0.5463 - val_binary_accuracy: 0.7757\n",
      "Epoch 1019/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4869 - binary_accuracy: 0.7994 - val_loss: 0.5462 - val_binary_accuracy: 0.7757\n",
      "Epoch 1020/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4869 - binary_accuracy: 0.7994 - val_loss: 0.5462 - val_binary_accuracy: 0.7757\n",
      "Epoch 1021/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4868 - binary_accuracy: 0.7996 - val_loss: 0.5462 - val_binary_accuracy: 0.7763\n",
      "Epoch 1022/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4868 - binary_accuracy: 0.7996 - val_loss: 0.5461 - val_binary_accuracy: 0.7757\n",
      "Epoch 1023/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4867 - binary_accuracy: 0.7998 - val_loss: 0.5461 - val_binary_accuracy: 0.7757\n",
      "Epoch 1024/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4866 - binary_accuracy: 0.7994 - val_loss: 0.5461 - val_binary_accuracy: 0.7757\n",
      "Epoch 1025/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4866 - binary_accuracy: 0.7996 - val_loss: 0.5461 - val_binary_accuracy: 0.7757\n",
      "Epoch 1026/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4865 - binary_accuracy: 0.7998 - val_loss: 0.5460 - val_binary_accuracy: 0.7752\n",
      "Epoch 1027/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4865 - binary_accuracy: 0.7998 - val_loss: 0.5460 - val_binary_accuracy: 0.7752\n",
      "Epoch 1028/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4864 - binary_accuracy: 0.8000 - val_loss: 0.5460 - val_binary_accuracy: 0.7752\n",
      "Epoch 1029/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4864 - binary_accuracy: 0.7998 - val_loss: 0.5460 - val_binary_accuracy: 0.7752\n",
      "Epoch 1030/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4863 - binary_accuracy: 0.7996 - val_loss: 0.5460 - val_binary_accuracy: 0.7752\n",
      "Epoch 1031/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4863 - binary_accuracy: 0.7996 - val_loss: 0.5459 - val_binary_accuracy: 0.7768\n",
      "Epoch 1032/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4862 - binary_accuracy: 0.8000 - val_loss: 0.5459 - val_binary_accuracy: 0.7773\n",
      "Epoch 1033/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4861 - binary_accuracy: 0.8000 - val_loss: 0.5459 - val_binary_accuracy: 0.7773\n",
      "Epoch 1034/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4861 - binary_accuracy: 0.8001 - val_loss: 0.5458 - val_binary_accuracy: 0.7784\n",
      "Epoch 1035/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4860 - binary_accuracy: 0.8003 - val_loss: 0.5458 - val_binary_accuracy: 0.7784\n",
      "Epoch 1036/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4860 - binary_accuracy: 0.8003 - val_loss: 0.5458 - val_binary_accuracy: 0.7784\n",
      "Epoch 1037/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4859 - binary_accuracy: 0.8001 - val_loss: 0.5458 - val_binary_accuracy: 0.7784\n",
      "Epoch 1038/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4859 - binary_accuracy: 0.8005 - val_loss: 0.5457 - val_binary_accuracy: 0.7784\n",
      "Epoch 1039/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4858 - binary_accuracy: 0.8007 - val_loss: 0.5457 - val_binary_accuracy: 0.7778\n",
      "Epoch 1040/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4858 - binary_accuracy: 0.8007 - val_loss: 0.5457 - val_binary_accuracy: 0.7784\n",
      "Epoch 1041/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4857 - binary_accuracy: 0.8007 - val_loss: 0.5456 - val_binary_accuracy: 0.7784\n",
      "Epoch 1042/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4857 - binary_accuracy: 0.8007 - val_loss: 0.5456 - val_binary_accuracy: 0.7789\n",
      "Epoch 1043/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4856 - binary_accuracy: 0.8007 - val_loss: 0.5456 - val_binary_accuracy: 0.7789\n",
      "Epoch 1044/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4856 - binary_accuracy: 0.8010 - val_loss: 0.5456 - val_binary_accuracy: 0.7784\n",
      "Epoch 1045/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4855 - binary_accuracy: 0.8010 - val_loss: 0.5455 - val_binary_accuracy: 0.7778\n",
      "Epoch 1046/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4854 - binary_accuracy: 0.8008 - val_loss: 0.5455 - val_binary_accuracy: 0.7778\n",
      "Epoch 1047/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4854 - binary_accuracy: 0.8008 - val_loss: 0.5455 - val_binary_accuracy: 0.7778\n",
      "Epoch 1048/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4853 - binary_accuracy: 0.8008 - val_loss: 0.5455 - val_binary_accuracy: 0.7778\n",
      "Epoch 1049/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4853 - binary_accuracy: 0.8007 - val_loss: 0.5454 - val_binary_accuracy: 0.7778\n",
      "Epoch 1050/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4852 - binary_accuracy: 0.8007 - val_loss: 0.5454 - val_binary_accuracy: 0.7778\n",
      "Epoch 1051/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4852 - binary_accuracy: 0.8010 - val_loss: 0.5454 - val_binary_accuracy: 0.7784\n",
      "Epoch 1052/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4851 - binary_accuracy: 0.8010 - val_loss: 0.5454 - val_binary_accuracy: 0.7784\n",
      "Epoch 1053/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4851 - binary_accuracy: 0.8010 - val_loss: 0.5453 - val_binary_accuracy: 0.7784\n",
      "Epoch 1054/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4850 - binary_accuracy: 0.8008 - val_loss: 0.5453 - val_binary_accuracy: 0.7778\n",
      "Epoch 1055/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4850 - binary_accuracy: 0.8012 - val_loss: 0.5453 - val_binary_accuracy: 0.7778\n",
      "Epoch 1056/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4849 - binary_accuracy: 0.8012 - val_loss: 0.5453 - val_binary_accuracy: 0.7778\n",
      "Epoch 1057/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4849 - binary_accuracy: 0.8012 - val_loss: 0.5453 - val_binary_accuracy: 0.7778\n",
      "Epoch 1058/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4848 - binary_accuracy: 0.8012 - val_loss: 0.5453 - val_binary_accuracy: 0.7778\n",
      "Epoch 1059/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4847 - binary_accuracy: 0.8012 - val_loss: 0.5452 - val_binary_accuracy: 0.7778\n",
      "Epoch 1060/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4847 - binary_accuracy: 0.8012 - val_loss: 0.5452 - val_binary_accuracy: 0.7784\n",
      "Epoch 1061/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4846 - binary_accuracy: 0.8012 - val_loss: 0.5452 - val_binary_accuracy: 0.7784\n",
      "Epoch 1062/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4846 - binary_accuracy: 0.8010 - val_loss: 0.5452 - val_binary_accuracy: 0.7784\n",
      "Epoch 1063/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4845 - binary_accuracy: 0.8010 - val_loss: 0.5451 - val_binary_accuracy: 0.7784\n",
      "Epoch 1064/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4845 - binary_accuracy: 0.8010 - val_loss: 0.5451 - val_binary_accuracy: 0.7784\n",
      "Epoch 1065/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4844 - binary_accuracy: 0.8015 - val_loss: 0.5451 - val_binary_accuracy: 0.7784\n",
      "Epoch 1066/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4844 - binary_accuracy: 0.8017 - val_loss: 0.5451 - val_binary_accuracy: 0.7789\n",
      "Epoch 1067/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4843 - binary_accuracy: 0.8022 - val_loss: 0.5451 - val_binary_accuracy: 0.7789\n",
      "Epoch 1068/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4843 - binary_accuracy: 0.8022 - val_loss: 0.5450 - val_binary_accuracy: 0.7789\n",
      "Epoch 1069/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4842 - binary_accuracy: 0.8024 - val_loss: 0.5450 - val_binary_accuracy: 0.7789\n",
      "Epoch 1070/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4842 - binary_accuracy: 0.8024 - val_loss: 0.5450 - val_binary_accuracy: 0.7789\n",
      "Epoch 1071/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4841 - binary_accuracy: 0.8024 - val_loss: 0.5450 - val_binary_accuracy: 0.7789\n",
      "Epoch 1072/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4841 - binary_accuracy: 0.8022 - val_loss: 0.5449 - val_binary_accuracy: 0.7789\n",
      "Epoch 1073/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4840 - binary_accuracy: 0.8022 - val_loss: 0.5449 - val_binary_accuracy: 0.7799\n",
      "Epoch 1074/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4840 - binary_accuracy: 0.8028 - val_loss: 0.5449 - val_binary_accuracy: 0.7799\n",
      "Epoch 1075/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4839 - binary_accuracy: 0.8028 - val_loss: 0.5449 - val_binary_accuracy: 0.7794\n",
      "Epoch 1076/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4839 - binary_accuracy: 0.8028 - val_loss: 0.5449 - val_binary_accuracy: 0.7794\n",
      "Epoch 1077/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4838 - binary_accuracy: 0.8029 - val_loss: 0.5449 - val_binary_accuracy: 0.7794\n",
      "Epoch 1078/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4838 - binary_accuracy: 0.8031 - val_loss: 0.5448 - val_binary_accuracy: 0.7794\n",
      "Epoch 1079/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4837 - binary_accuracy: 0.8033 - val_loss: 0.5448 - val_binary_accuracy: 0.7794\n",
      "Epoch 1080/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4836 - binary_accuracy: 0.8033 - val_loss: 0.5448 - val_binary_accuracy: 0.7794\n",
      "Epoch 1081/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4836 - binary_accuracy: 0.8029 - val_loss: 0.5448 - val_binary_accuracy: 0.7789\n",
      "Epoch 1082/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4835 - binary_accuracy: 0.8026 - val_loss: 0.5447 - val_binary_accuracy: 0.7784\n",
      "Epoch 1083/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4835 - binary_accuracy: 0.8021 - val_loss: 0.5447 - val_binary_accuracy: 0.7784\n",
      "Epoch 1084/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4834 - binary_accuracy: 0.8021 - val_loss: 0.5447 - val_binary_accuracy: 0.7784\n",
      "Epoch 1085/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4834 - binary_accuracy: 0.8021 - val_loss: 0.5447 - val_binary_accuracy: 0.7784\n",
      "Epoch 1086/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4833 - binary_accuracy: 0.8021 - val_loss: 0.5446 - val_binary_accuracy: 0.7784\n",
      "Epoch 1087/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4833 - binary_accuracy: 0.8026 - val_loss: 0.5446 - val_binary_accuracy: 0.7789\n",
      "Epoch 1088/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4832 - binary_accuracy: 0.8026 - val_loss: 0.5446 - val_binary_accuracy: 0.7789\n",
      "Epoch 1089/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4832 - binary_accuracy: 0.8024 - val_loss: 0.5446 - val_binary_accuracy: 0.7789\n",
      "Epoch 1090/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4831 - binary_accuracy: 0.8024 - val_loss: 0.5445 - val_binary_accuracy: 0.7789\n",
      "Epoch 1091/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4831 - binary_accuracy: 0.8026 - val_loss: 0.5445 - val_binary_accuracy: 0.7789\n",
      "Epoch 1092/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4830 - binary_accuracy: 0.8026 - val_loss: 0.5445 - val_binary_accuracy: 0.7784\n",
      "Epoch 1093/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4830 - binary_accuracy: 0.8022 - val_loss: 0.5445 - val_binary_accuracy: 0.7784\n",
      "Epoch 1094/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4829 - binary_accuracy: 0.8022 - val_loss: 0.5445 - val_binary_accuracy: 0.7784\n",
      "Epoch 1095/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4829 - binary_accuracy: 0.8019 - val_loss: 0.5445 - val_binary_accuracy: 0.7784\n",
      "Epoch 1096/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4828 - binary_accuracy: 0.8019 - val_loss: 0.5444 - val_binary_accuracy: 0.7784\n",
      "Epoch 1097/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4828 - binary_accuracy: 0.8024 - val_loss: 0.5444 - val_binary_accuracy: 0.7789\n",
      "Epoch 1098/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4827 - binary_accuracy: 0.8029 - val_loss: 0.5444 - val_binary_accuracy: 0.7789\n",
      "Epoch 1099/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4827 - binary_accuracy: 0.8029 - val_loss: 0.5444 - val_binary_accuracy: 0.7789\n",
      "Epoch 1100/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4826 - binary_accuracy: 0.8029 - val_loss: 0.5443 - val_binary_accuracy: 0.7789\n",
      "Epoch 1101/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4826 - binary_accuracy: 0.8026 - val_loss: 0.5443 - val_binary_accuracy: 0.7789\n",
      "Epoch 1102/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4825 - binary_accuracy: 0.8028 - val_loss: 0.5443 - val_binary_accuracy: 0.7789\n",
      "Epoch 1103/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4825 - binary_accuracy: 0.8028 - val_loss: 0.5443 - val_binary_accuracy: 0.7789\n",
      "Epoch 1104/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4824 - binary_accuracy: 0.8028 - val_loss: 0.5443 - val_binary_accuracy: 0.7789\n",
      "Epoch 1105/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4823 - binary_accuracy: 0.8029 - val_loss: 0.5443 - val_binary_accuracy: 0.7789\n",
      "Epoch 1106/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4823 - binary_accuracy: 0.8029 - val_loss: 0.5442 - val_binary_accuracy: 0.7789\n",
      "Epoch 1107/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4823 - binary_accuracy: 0.8029 - val_loss: 0.5442 - val_binary_accuracy: 0.7789\n",
      "Epoch 1108/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4822 - binary_accuracy: 0.8031 - val_loss: 0.5442 - val_binary_accuracy: 0.7789\n",
      "Epoch 1109/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4821 - binary_accuracy: 0.8031 - val_loss: 0.5441 - val_binary_accuracy: 0.7794\n",
      "Epoch 1110/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4821 - binary_accuracy: 0.8031 - val_loss: 0.5441 - val_binary_accuracy: 0.7794\n",
      "Epoch 1111/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4821 - binary_accuracy: 0.8036 - val_loss: 0.5441 - val_binary_accuracy: 0.7799\n",
      "Epoch 1112/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4820 - binary_accuracy: 0.8042 - val_loss: 0.5441 - val_binary_accuracy: 0.7799\n",
      "Epoch 1113/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4819 - binary_accuracy: 0.8042 - val_loss: 0.5441 - val_binary_accuracy: 0.7799\n",
      "Epoch 1114/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4819 - binary_accuracy: 0.8040 - val_loss: 0.5441 - val_binary_accuracy: 0.7794\n",
      "Epoch 1115/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4819 - binary_accuracy: 0.8038 - val_loss: 0.5440 - val_binary_accuracy: 0.7794\n",
      "Epoch 1116/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4818 - binary_accuracy: 0.8038 - val_loss: 0.5440 - val_binary_accuracy: 0.7794\n",
      "Epoch 1117/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4818 - binary_accuracy: 0.8036 - val_loss: 0.5440 - val_binary_accuracy: 0.7794\n",
      "Epoch 1118/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4817 - binary_accuracy: 0.8038 - val_loss: 0.5439 - val_binary_accuracy: 0.7794\n",
      "Epoch 1119/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4816 - binary_accuracy: 0.8038 - val_loss: 0.5439 - val_binary_accuracy: 0.7794\n",
      "Epoch 1120/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4816 - binary_accuracy: 0.8038 - val_loss: 0.5439 - val_binary_accuracy: 0.7794\n",
      "Epoch 1121/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4815 - binary_accuracy: 0.8038 - val_loss: 0.5439 - val_binary_accuracy: 0.7794\n",
      "Epoch 1122/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4815 - binary_accuracy: 0.8036 - val_loss: 0.5439 - val_binary_accuracy: 0.7794\n",
      "Epoch 1123/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4815 - binary_accuracy: 0.8038 - val_loss: 0.5439 - val_binary_accuracy: 0.7794\n",
      "Epoch 1124/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4814 - binary_accuracy: 0.8038 - val_loss: 0.5439 - val_binary_accuracy: 0.7794\n",
      "Epoch 1125/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4814 - binary_accuracy: 0.8038 - val_loss: 0.5439 - val_binary_accuracy: 0.7794\n",
      "Epoch 1126/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4813 - binary_accuracy: 0.8036 - val_loss: 0.5438 - val_binary_accuracy: 0.7794\n",
      "Epoch 1127/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4813 - binary_accuracy: 0.8038 - val_loss: 0.5438 - val_binary_accuracy: 0.7789\n",
      "Epoch 1128/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4812 - binary_accuracy: 0.8038 - val_loss: 0.5438 - val_binary_accuracy: 0.7794\n",
      "Epoch 1129/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4811 - binary_accuracy: 0.8038 - val_loss: 0.5437 - val_binary_accuracy: 0.7789\n",
      "Epoch 1130/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4811 - binary_accuracy: 0.8038 - val_loss: 0.5437 - val_binary_accuracy: 0.7789\n",
      "Epoch 1131/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4811 - binary_accuracy: 0.8038 - val_loss: 0.5437 - val_binary_accuracy: 0.7789\n",
      "Epoch 1132/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4810 - binary_accuracy: 0.8038 - val_loss: 0.5437 - val_binary_accuracy: 0.7789\n",
      "Epoch 1133/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4810 - binary_accuracy: 0.8036 - val_loss: 0.5437 - val_binary_accuracy: 0.7799\n",
      "Epoch 1134/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4809 - binary_accuracy: 0.8036 - val_loss: 0.5437 - val_binary_accuracy: 0.7799\n",
      "Epoch 1135/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4809 - binary_accuracy: 0.8036 - val_loss: 0.5436 - val_binary_accuracy: 0.7799\n",
      "Epoch 1136/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4808 - binary_accuracy: 0.8042 - val_loss: 0.5436 - val_binary_accuracy: 0.7799\n",
      "Epoch 1137/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4808 - binary_accuracy: 0.8042 - val_loss: 0.5436 - val_binary_accuracy: 0.7799\n",
      "Epoch 1138/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4807 - binary_accuracy: 0.8043 - val_loss: 0.5436 - val_binary_accuracy: 0.7794\n",
      "Epoch 1139/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4807 - binary_accuracy: 0.8043 - val_loss: 0.5435 - val_binary_accuracy: 0.7789\n",
      "Epoch 1140/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4806 - binary_accuracy: 0.8042 - val_loss: 0.5435 - val_binary_accuracy: 0.7789\n",
      "Epoch 1141/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4806 - binary_accuracy: 0.8042 - val_loss: 0.5435 - val_binary_accuracy: 0.7789\n",
      "Epoch 1142/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4805 - binary_accuracy: 0.8042 - val_loss: 0.5435 - val_binary_accuracy: 0.7789\n",
      "Epoch 1143/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4805 - binary_accuracy: 0.8042 - val_loss: 0.5434 - val_binary_accuracy: 0.7789\n",
      "Epoch 1144/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4804 - binary_accuracy: 0.8042 - val_loss: 0.5434 - val_binary_accuracy: 0.7789\n",
      "Epoch 1145/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4804 - binary_accuracy: 0.8040 - val_loss: 0.5434 - val_binary_accuracy: 0.7789\n",
      "Epoch 1146/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4803 - binary_accuracy: 0.8040 - val_loss: 0.5433 - val_binary_accuracy: 0.7789\n",
      "Epoch 1147/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4803 - binary_accuracy: 0.8040 - val_loss: 0.5433 - val_binary_accuracy: 0.7789\n",
      "Epoch 1148/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4802 - binary_accuracy: 0.8040 - val_loss: 0.5433 - val_binary_accuracy: 0.7789\n",
      "Epoch 1149/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4802 - binary_accuracy: 0.8038 - val_loss: 0.5433 - val_binary_accuracy: 0.7789\n",
      "Epoch 1150/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4801 - binary_accuracy: 0.8040 - val_loss: 0.5433 - val_binary_accuracy: 0.7789\n",
      "Epoch 1151/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4801 - binary_accuracy: 0.8045 - val_loss: 0.5432 - val_binary_accuracy: 0.7789\n",
      "Epoch 1152/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4800 - binary_accuracy: 0.8043 - val_loss: 0.5432 - val_binary_accuracy: 0.7794\n",
      "Epoch 1153/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4800 - binary_accuracy: 0.8047 - val_loss: 0.5432 - val_binary_accuracy: 0.7799\n",
      "Epoch 1154/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4799 - binary_accuracy: 0.8049 - val_loss: 0.5432 - val_binary_accuracy: 0.7799\n",
      "Epoch 1155/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4799 - binary_accuracy: 0.8047 - val_loss: 0.5432 - val_binary_accuracy: 0.7799\n",
      "Epoch 1156/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4798 - binary_accuracy: 0.8047 - val_loss: 0.5432 - val_binary_accuracy: 0.7799\n",
      "Epoch 1157/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4798 - binary_accuracy: 0.8049 - val_loss: 0.5431 - val_binary_accuracy: 0.7799\n",
      "Epoch 1158/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4797 - binary_accuracy: 0.8049 - val_loss: 0.5431 - val_binary_accuracy: 0.7799\n",
      "Epoch 1159/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4797 - binary_accuracy: 0.8049 - val_loss: 0.5431 - val_binary_accuracy: 0.7799\n",
      "Epoch 1160/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4796 - binary_accuracy: 0.8050 - val_loss: 0.5431 - val_binary_accuracy: 0.7799\n",
      "Epoch 1161/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4796 - binary_accuracy: 0.8049 - val_loss: 0.5430 - val_binary_accuracy: 0.7799\n",
      "Epoch 1162/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4795 - binary_accuracy: 0.8050 - val_loss: 0.5430 - val_binary_accuracy: 0.7799\n",
      "Epoch 1163/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4795 - binary_accuracy: 0.8050 - val_loss: 0.5430 - val_binary_accuracy: 0.7799\n",
      "Epoch 1164/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4794 - binary_accuracy: 0.8049 - val_loss: 0.5430 - val_binary_accuracy: 0.7799\n",
      "Epoch 1165/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4794 - binary_accuracy: 0.8049 - val_loss: 0.5430 - val_binary_accuracy: 0.7799\n",
      "Epoch 1166/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4794 - binary_accuracy: 0.8049 - val_loss: 0.5430 - val_binary_accuracy: 0.7799\n",
      "Epoch 1167/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4793 - binary_accuracy: 0.8049 - val_loss: 0.5429 - val_binary_accuracy: 0.7799\n",
      "Epoch 1168/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4793 - binary_accuracy: 0.8047 - val_loss: 0.5429 - val_binary_accuracy: 0.7799\n",
      "Epoch 1169/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4792 - binary_accuracy: 0.8047 - val_loss: 0.5429 - val_binary_accuracy: 0.7799\n",
      "Epoch 1170/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4791 - binary_accuracy: 0.8043 - val_loss: 0.5429 - val_binary_accuracy: 0.7799\n",
      "Epoch 1171/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4791 - binary_accuracy: 0.8047 - val_loss: 0.5429 - val_binary_accuracy: 0.7799\n",
      "Epoch 1172/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4791 - binary_accuracy: 0.8054 - val_loss: 0.5429 - val_binary_accuracy: 0.7799\n",
      "Epoch 1173/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4790 - binary_accuracy: 0.8057 - val_loss: 0.5429 - val_binary_accuracy: 0.7799\n",
      "Epoch 1174/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4790 - binary_accuracy: 0.8063 - val_loss: 0.5429 - val_binary_accuracy: 0.7805\n",
      "Epoch 1175/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4789 - binary_accuracy: 0.8063 - val_loss: 0.5428 - val_binary_accuracy: 0.7805\n",
      "Epoch 1176/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4789 - binary_accuracy: 0.8056 - val_loss: 0.5428 - val_binary_accuracy: 0.7805\n",
      "Epoch 1177/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4788 - binary_accuracy: 0.8045 - val_loss: 0.5428 - val_binary_accuracy: 0.7805\n",
      "Epoch 1178/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4788 - binary_accuracy: 0.8042 - val_loss: 0.5428 - val_binary_accuracy: 0.7794\n",
      "Epoch 1179/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4787 - binary_accuracy: 0.8040 - val_loss: 0.5428 - val_binary_accuracy: 0.7789\n",
      "Epoch 1180/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4787 - binary_accuracy: 0.8040 - val_loss: 0.5427 - val_binary_accuracy: 0.7789\n",
      "Epoch 1181/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4786 - binary_accuracy: 0.8042 - val_loss: 0.5427 - val_binary_accuracy: 0.7789\n",
      "Epoch 1182/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4786 - binary_accuracy: 0.8042 - val_loss: 0.5427 - val_binary_accuracy: 0.7789\n",
      "Epoch 1183/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4785 - binary_accuracy: 0.8043 - val_loss: 0.5426 - val_binary_accuracy: 0.7789\n",
      "Epoch 1184/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4785 - binary_accuracy: 0.8040 - val_loss: 0.5426 - val_binary_accuracy: 0.7789\n",
      "Epoch 1185/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4784 - binary_accuracy: 0.8040 - val_loss: 0.5426 - val_binary_accuracy: 0.7789\n",
      "Epoch 1186/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4784 - binary_accuracy: 0.8040 - val_loss: 0.5426 - val_binary_accuracy: 0.7789\n",
      "Epoch 1187/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4783 - binary_accuracy: 0.8045 - val_loss: 0.5426 - val_binary_accuracy: 0.7794\n",
      "Epoch 1188/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4783 - binary_accuracy: 0.8040 - val_loss: 0.5425 - val_binary_accuracy: 0.7794\n",
      "Epoch 1189/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4782 - binary_accuracy: 0.8040 - val_loss: 0.5425 - val_binary_accuracy: 0.7789\n",
      "Epoch 1190/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4782 - binary_accuracy: 0.8042 - val_loss: 0.5425 - val_binary_accuracy: 0.7789\n",
      "Epoch 1191/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4782 - binary_accuracy: 0.8042 - val_loss: 0.5425 - val_binary_accuracy: 0.7789\n",
      "Epoch 1192/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4781 - binary_accuracy: 0.8043 - val_loss: 0.5425 - val_binary_accuracy: 0.7794\n",
      "Epoch 1193/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4781 - binary_accuracy: 0.8047 - val_loss: 0.5424 - val_binary_accuracy: 0.7794\n",
      "Epoch 1194/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4780 - binary_accuracy: 0.8047 - val_loss: 0.5424 - val_binary_accuracy: 0.7794\n",
      "Epoch 1195/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4780 - binary_accuracy: 0.8045 - val_loss: 0.5424 - val_binary_accuracy: 0.7794\n",
      "Epoch 1196/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4779 - binary_accuracy: 0.8049 - val_loss: 0.5424 - val_binary_accuracy: 0.7794\n",
      "Epoch 1197/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4779 - binary_accuracy: 0.8050 - val_loss: 0.5424 - val_binary_accuracy: 0.7794\n",
      "Epoch 1198/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4778 - binary_accuracy: 0.8050 - val_loss: 0.5423 - val_binary_accuracy: 0.7794\n",
      "Epoch 1199/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4778 - binary_accuracy: 0.8050 - val_loss: 0.5423 - val_binary_accuracy: 0.7794\n",
      "Epoch 1200/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4777 - binary_accuracy: 0.8054 - val_loss: 0.5423 - val_binary_accuracy: 0.7794\n",
      "Epoch 1201/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4777 - binary_accuracy: 0.8057 - val_loss: 0.5423 - val_binary_accuracy: 0.7794\n",
      "Epoch 1202/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4776 - binary_accuracy: 0.8057 - val_loss: 0.5423 - val_binary_accuracy: 0.7794\n",
      "Epoch 1203/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4776 - binary_accuracy: 0.8061 - val_loss: 0.5422 - val_binary_accuracy: 0.7794\n",
      "Epoch 1204/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4775 - binary_accuracy: 0.8059 - val_loss: 0.5422 - val_binary_accuracy: 0.7794\n",
      "Epoch 1205/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4775 - binary_accuracy: 0.8061 - val_loss: 0.5422 - val_binary_accuracy: 0.7794\n",
      "Epoch 1206/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4774 - binary_accuracy: 0.8057 - val_loss: 0.5421 - val_binary_accuracy: 0.7794\n",
      "Epoch 1207/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4774 - binary_accuracy: 0.8059 - val_loss: 0.5421 - val_binary_accuracy: 0.7799\n",
      "Epoch 1208/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4774 - binary_accuracy: 0.8059 - val_loss: 0.5421 - val_binary_accuracy: 0.7799\n",
      "Epoch 1209/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4773 - binary_accuracy: 0.8054 - val_loss: 0.5421 - val_binary_accuracy: 0.7794\n",
      "Epoch 1210/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4773 - binary_accuracy: 0.8052 - val_loss: 0.5421 - val_binary_accuracy: 0.7794\n",
      "Epoch 1211/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4772 - binary_accuracy: 0.8054 - val_loss: 0.5421 - val_binary_accuracy: 0.7794\n",
      "Epoch 1212/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4772 - binary_accuracy: 0.8061 - val_loss: 0.5421 - val_binary_accuracy: 0.7799\n",
      "Epoch 1213/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4771 - binary_accuracy: 0.8063 - val_loss: 0.5421 - val_binary_accuracy: 0.7799\n",
      "Epoch 1214/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4771 - binary_accuracy: 0.8063 - val_loss: 0.5421 - val_binary_accuracy: 0.7799\n",
      "Epoch 1215/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4770 - binary_accuracy: 0.8066 - val_loss: 0.5421 - val_binary_accuracy: 0.7805\n",
      "Epoch 1216/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4770 - binary_accuracy: 0.8066 - val_loss: 0.5421 - val_binary_accuracy: 0.7810\n",
      "Epoch 1217/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4769 - binary_accuracy: 0.8064 - val_loss: 0.5420 - val_binary_accuracy: 0.7810\n",
      "Epoch 1218/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4769 - binary_accuracy: 0.8063 - val_loss: 0.5420 - val_binary_accuracy: 0.7810\n",
      "Epoch 1219/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4769 - binary_accuracy: 0.8066 - val_loss: 0.5420 - val_binary_accuracy: 0.7810\n",
      "Epoch 1220/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4768 - binary_accuracy: 0.8068 - val_loss: 0.5420 - val_binary_accuracy: 0.7810\n",
      "Epoch 1221/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4768 - binary_accuracy: 0.8070 - val_loss: 0.5420 - val_binary_accuracy: 0.7810\n",
      "Epoch 1222/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4767 - binary_accuracy: 0.8066 - val_loss: 0.5419 - val_binary_accuracy: 0.7810\n",
      "Epoch 1223/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4767 - binary_accuracy: 0.8068 - val_loss: 0.5419 - val_binary_accuracy: 0.7805\n",
      "Epoch 1224/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4766 - binary_accuracy: 0.8068 - val_loss: 0.5419 - val_binary_accuracy: 0.7805\n",
      "Epoch 1225/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4766 - binary_accuracy: 0.8063 - val_loss: 0.5419 - val_binary_accuracy: 0.7799\n",
      "Epoch 1226/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4765 - binary_accuracy: 0.8061 - val_loss: 0.5419 - val_binary_accuracy: 0.7799\n",
      "Epoch 1227/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4765 - binary_accuracy: 0.8063 - val_loss: 0.5419 - val_binary_accuracy: 0.7799\n",
      "Epoch 1228/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4764 - binary_accuracy: 0.8063 - val_loss: 0.5419 - val_binary_accuracy: 0.7799\n",
      "Epoch 1229/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4764 - binary_accuracy: 0.8063 - val_loss: 0.5418 - val_binary_accuracy: 0.7799\n",
      "Epoch 1230/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4763 - binary_accuracy: 0.8063 - val_loss: 0.5418 - val_binary_accuracy: 0.7799\n",
      "Epoch 1231/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4763 - binary_accuracy: 0.8061 - val_loss: 0.5418 - val_binary_accuracy: 0.7799\n",
      "Epoch 1232/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4763 - binary_accuracy: 0.8063 - val_loss: 0.5418 - val_binary_accuracy: 0.7805\n",
      "Epoch 1233/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4762 - binary_accuracy: 0.8064 - val_loss: 0.5418 - val_binary_accuracy: 0.7805\n",
      "Epoch 1234/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4762 - binary_accuracy: 0.8063 - val_loss: 0.5418 - val_binary_accuracy: 0.7805\n",
      "Epoch 1235/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4761 - binary_accuracy: 0.8063 - val_loss: 0.5418 - val_binary_accuracy: 0.7805\n",
      "Epoch 1236/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4761 - binary_accuracy: 0.8061 - val_loss: 0.5417 - val_binary_accuracy: 0.7805\n",
      "Epoch 1237/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4760 - binary_accuracy: 0.8061 - val_loss: 0.5417 - val_binary_accuracy: 0.7805\n",
      "Epoch 1238/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4760 - binary_accuracy: 0.8063 - val_loss: 0.5417 - val_binary_accuracy: 0.7810\n",
      "Epoch 1239/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4759 - binary_accuracy: 0.8066 - val_loss: 0.5417 - val_binary_accuracy: 0.7815\n",
      "Epoch 1240/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4759 - binary_accuracy: 0.8066 - val_loss: 0.5417 - val_binary_accuracy: 0.7815\n",
      "Epoch 1241/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4758 - binary_accuracy: 0.8064 - val_loss: 0.5416 - val_binary_accuracy: 0.7815\n",
      "Epoch 1242/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4758 - binary_accuracy: 0.8066 - val_loss: 0.5416 - val_binary_accuracy: 0.7815\n",
      "Epoch 1243/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4758 - binary_accuracy: 0.8066 - val_loss: 0.5416 - val_binary_accuracy: 0.7815\n",
      "Epoch 1244/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4757 - binary_accuracy: 0.8070 - val_loss: 0.5416 - val_binary_accuracy: 0.7815\n",
      "Epoch 1245/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4757 - binary_accuracy: 0.8071 - val_loss: 0.5415 - val_binary_accuracy: 0.7815\n",
      "Epoch 1246/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4756 - binary_accuracy: 0.8073 - val_loss: 0.5415 - val_binary_accuracy: 0.7815\n",
      "Epoch 1247/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4756 - binary_accuracy: 0.8071 - val_loss: 0.5415 - val_binary_accuracy: 0.7810\n",
      "Epoch 1248/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4755 - binary_accuracy: 0.8070 - val_loss: 0.5415 - val_binary_accuracy: 0.7805\n",
      "Epoch 1249/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4755 - binary_accuracy: 0.8071 - val_loss: 0.5414 - val_binary_accuracy: 0.7805\n",
      "Epoch 1250/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4754 - binary_accuracy: 0.8073 - val_loss: 0.5414 - val_binary_accuracy: 0.7810\n",
      "Epoch 1251/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4754 - binary_accuracy: 0.8073 - val_loss: 0.5414 - val_binary_accuracy: 0.7810\n",
      "Epoch 1252/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4754 - binary_accuracy: 0.8071 - val_loss: 0.5414 - val_binary_accuracy: 0.7810\n",
      "Epoch 1253/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4753 - binary_accuracy: 0.8071 - val_loss: 0.5414 - val_binary_accuracy: 0.7805\n",
      "Epoch 1254/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4753 - binary_accuracy: 0.8073 - val_loss: 0.5414 - val_binary_accuracy: 0.7805\n",
      "Epoch 1255/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4752 - binary_accuracy: 0.8070 - val_loss: 0.5414 - val_binary_accuracy: 0.7805\n",
      "Epoch 1256/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4752 - binary_accuracy: 0.8070 - val_loss: 0.5414 - val_binary_accuracy: 0.7805\n",
      "Epoch 1257/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4751 - binary_accuracy: 0.8070 - val_loss: 0.5414 - val_binary_accuracy: 0.7805\n",
      "Epoch 1258/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4751 - binary_accuracy: 0.8070 - val_loss: 0.5414 - val_binary_accuracy: 0.7805\n",
      "Epoch 1259/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4751 - binary_accuracy: 0.8071 - val_loss: 0.5414 - val_binary_accuracy: 0.7815\n",
      "Epoch 1260/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4750 - binary_accuracy: 0.8071 - val_loss: 0.5413 - val_binary_accuracy: 0.7815\n",
      "Epoch 1261/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4750 - binary_accuracy: 0.8070 - val_loss: 0.5413 - val_binary_accuracy: 0.7810\n",
      "Epoch 1262/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4749 - binary_accuracy: 0.8070 - val_loss: 0.5413 - val_binary_accuracy: 0.7810\n",
      "Epoch 1263/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4749 - binary_accuracy: 0.8070 - val_loss: 0.5413 - val_binary_accuracy: 0.7805\n",
      "Epoch 1264/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4748 - binary_accuracy: 0.8068 - val_loss: 0.5413 - val_binary_accuracy: 0.7805\n",
      "Epoch 1265/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4748 - binary_accuracy: 0.8070 - val_loss: 0.5412 - val_binary_accuracy: 0.7805\n",
      "Epoch 1266/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4747 - binary_accuracy: 0.8070 - val_loss: 0.5412 - val_binary_accuracy: 0.7799\n",
      "Epoch 1267/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4747 - binary_accuracy: 0.8071 - val_loss: 0.5412 - val_binary_accuracy: 0.7805\n",
      "Epoch 1268/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4746 - binary_accuracy: 0.8070 - val_loss: 0.5412 - val_binary_accuracy: 0.7799\n",
      "Epoch 1269/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4746 - binary_accuracy: 0.8066 - val_loss: 0.5412 - val_binary_accuracy: 0.7805\n",
      "Epoch 1270/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4746 - binary_accuracy: 0.8068 - val_loss: 0.5412 - val_binary_accuracy: 0.7805\n",
      "Epoch 1271/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4745 - binary_accuracy: 0.8066 - val_loss: 0.5412 - val_binary_accuracy: 0.7810\n",
      "Epoch 1272/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4745 - binary_accuracy: 0.8068 - val_loss: 0.5412 - val_binary_accuracy: 0.7815\n",
      "Epoch 1273/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4744 - binary_accuracy: 0.8068 - val_loss: 0.5411 - val_binary_accuracy: 0.7820\n",
      "Epoch 1274/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4744 - binary_accuracy: 0.8068 - val_loss: 0.5412 - val_binary_accuracy: 0.7815\n",
      "Epoch 1275/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4743 - binary_accuracy: 0.8068 - val_loss: 0.5411 - val_binary_accuracy: 0.7805\n",
      "Epoch 1276/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4743 - binary_accuracy: 0.8066 - val_loss: 0.5411 - val_binary_accuracy: 0.7805\n",
      "Epoch 1277/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4742 - binary_accuracy: 0.8071 - val_loss: 0.5411 - val_binary_accuracy: 0.7805\n",
      "Epoch 1278/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4742 - binary_accuracy: 0.8070 - val_loss: 0.5411 - val_binary_accuracy: 0.7810\n",
      "Epoch 1279/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4742 - binary_accuracy: 0.8070 - val_loss: 0.5411 - val_binary_accuracy: 0.7810\n",
      "Epoch 1280/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4741 - binary_accuracy: 0.8073 - val_loss: 0.5410 - val_binary_accuracy: 0.7810\n",
      "Epoch 1281/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4741 - binary_accuracy: 0.8071 - val_loss: 0.5410 - val_binary_accuracy: 0.7810\n",
      "Epoch 1282/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4740 - binary_accuracy: 0.8071 - val_loss: 0.5410 - val_binary_accuracy: 0.7815\n",
      "Epoch 1283/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4740 - binary_accuracy: 0.8071 - val_loss: 0.5410 - val_binary_accuracy: 0.7815\n",
      "Epoch 1284/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4739 - binary_accuracy: 0.8070 - val_loss: 0.5409 - val_binary_accuracy: 0.7815\n",
      "Epoch 1285/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4739 - binary_accuracy: 0.8070 - val_loss: 0.5409 - val_binary_accuracy: 0.7815\n",
      "Epoch 1286/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4739 - binary_accuracy: 0.8068 - val_loss: 0.5409 - val_binary_accuracy: 0.7815\n",
      "Epoch 1287/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4738 - binary_accuracy: 0.8071 - val_loss: 0.5409 - val_binary_accuracy: 0.7815\n",
      "Epoch 1288/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4738 - binary_accuracy: 0.8077 - val_loss: 0.5409 - val_binary_accuracy: 0.7810\n",
      "Epoch 1289/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4737 - binary_accuracy: 0.8077 - val_loss: 0.5409 - val_binary_accuracy: 0.7820\n",
      "Epoch 1290/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4737 - binary_accuracy: 0.8078 - val_loss: 0.5409 - val_binary_accuracy: 0.7815\n",
      "Epoch 1291/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4736 - binary_accuracy: 0.8080 - val_loss: 0.5409 - val_binary_accuracy: 0.7815\n",
      "Epoch 1292/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4736 - binary_accuracy: 0.8078 - val_loss: 0.5408 - val_binary_accuracy: 0.7820\n",
      "Epoch 1293/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4736 - binary_accuracy: 0.8075 - val_loss: 0.5408 - val_binary_accuracy: 0.7810\n",
      "Epoch 1294/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4735 - binary_accuracy: 0.8075 - val_loss: 0.5408 - val_binary_accuracy: 0.7805\n",
      "Epoch 1295/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4735 - binary_accuracy: 0.8075 - val_loss: 0.5408 - val_binary_accuracy: 0.7805\n",
      "Epoch 1296/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4734 - binary_accuracy: 0.8077 - val_loss: 0.5407 - val_binary_accuracy: 0.7805\n",
      "Epoch 1297/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4734 - binary_accuracy: 0.8077 - val_loss: 0.5407 - val_binary_accuracy: 0.7810\n",
      "Epoch 1298/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4734 - binary_accuracy: 0.8077 - val_loss: 0.5407 - val_binary_accuracy: 0.7810\n",
      "Epoch 1299/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4733 - binary_accuracy: 0.8080 - val_loss: 0.5407 - val_binary_accuracy: 0.7810\n",
      "Epoch 1300/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4733 - binary_accuracy: 0.8082 - val_loss: 0.5407 - val_binary_accuracy: 0.7815\n",
      "Epoch 1301/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4732 - binary_accuracy: 0.8082 - val_loss: 0.5406 - val_binary_accuracy: 0.7815\n",
      "Epoch 1302/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4732 - binary_accuracy: 0.8080 - val_loss: 0.5406 - val_binary_accuracy: 0.7820\n",
      "Epoch 1303/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4731 - binary_accuracy: 0.8084 - val_loss: 0.5406 - val_binary_accuracy: 0.7841\n",
      "Epoch 1304/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4731 - binary_accuracy: 0.8087 - val_loss: 0.5406 - val_binary_accuracy: 0.7847\n",
      "Epoch 1305/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4731 - binary_accuracy: 0.8089 - val_loss: 0.5406 - val_binary_accuracy: 0.7847\n",
      "Epoch 1306/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4730 - binary_accuracy: 0.8087 - val_loss: 0.5406 - val_binary_accuracy: 0.7847\n",
      "Epoch 1307/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4730 - binary_accuracy: 0.8089 - val_loss: 0.5406 - val_binary_accuracy: 0.7847\n",
      "Epoch 1308/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4729 - binary_accuracy: 0.8089 - val_loss: 0.5406 - val_binary_accuracy: 0.7847\n",
      "Epoch 1309/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4729 - binary_accuracy: 0.8089 - val_loss: 0.5406 - val_binary_accuracy: 0.7847\n",
      "Epoch 1310/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4728 - binary_accuracy: 0.8089 - val_loss: 0.5406 - val_binary_accuracy: 0.7847\n",
      "Epoch 1311/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4728 - binary_accuracy: 0.8089 - val_loss: 0.5406 - val_binary_accuracy: 0.7847\n",
      "Epoch 1312/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4728 - binary_accuracy: 0.8092 - val_loss: 0.5406 - val_binary_accuracy: 0.7852\n",
      "Epoch 1313/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4727 - binary_accuracy: 0.8094 - val_loss: 0.5406 - val_binary_accuracy: 0.7852\n",
      "Epoch 1314/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4727 - binary_accuracy: 0.8094 - val_loss: 0.5405 - val_binary_accuracy: 0.7852\n",
      "Epoch 1315/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4726 - binary_accuracy: 0.8092 - val_loss: 0.5405 - val_binary_accuracy: 0.7847\n",
      "Epoch 1316/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4726 - binary_accuracy: 0.8091 - val_loss: 0.5405 - val_binary_accuracy: 0.7841\n",
      "Epoch 1317/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4725 - binary_accuracy: 0.8091 - val_loss: 0.5405 - val_binary_accuracy: 0.7847\n",
      "Epoch 1318/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4725 - binary_accuracy: 0.8094 - val_loss: 0.5405 - val_binary_accuracy: 0.7847\n",
      "Epoch 1319/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4725 - binary_accuracy: 0.8096 - val_loss: 0.5405 - val_binary_accuracy: 0.7852\n",
      "Epoch 1320/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4724 - binary_accuracy: 0.8092 - val_loss: 0.5404 - val_binary_accuracy: 0.7815\n",
      "Epoch 1321/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4724 - binary_accuracy: 0.8089 - val_loss: 0.5404 - val_binary_accuracy: 0.7815\n",
      "Epoch 1322/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4723 - binary_accuracy: 0.8089 - val_loss: 0.5404 - val_binary_accuracy: 0.7810\n",
      "Epoch 1323/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4723 - binary_accuracy: 0.8089 - val_loss: 0.5404 - val_binary_accuracy: 0.7810\n",
      "Epoch 1324/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4722 - binary_accuracy: 0.8087 - val_loss: 0.5404 - val_binary_accuracy: 0.7815\n",
      "Epoch 1325/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4722 - binary_accuracy: 0.8089 - val_loss: 0.5404 - val_binary_accuracy: 0.7805\n",
      "Epoch 1326/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4722 - binary_accuracy: 0.8091 - val_loss: 0.5403 - val_binary_accuracy: 0.7810\n",
      "Epoch 1327/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4721 - binary_accuracy: 0.8092 - val_loss: 0.5403 - val_binary_accuracy: 0.7810\n",
      "Epoch 1328/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4721 - binary_accuracy: 0.8094 - val_loss: 0.5403 - val_binary_accuracy: 0.7805\n",
      "Epoch 1329/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4720 - binary_accuracy: 0.8092 - val_loss: 0.5403 - val_binary_accuracy: 0.7805\n",
      "Epoch 1330/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4720 - binary_accuracy: 0.8091 - val_loss: 0.5403 - val_binary_accuracy: 0.7805\n",
      "Epoch 1331/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4720 - binary_accuracy: 0.8094 - val_loss: 0.5403 - val_binary_accuracy: 0.7810\n",
      "Epoch 1332/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4719 - binary_accuracy: 0.8094 - val_loss: 0.5403 - val_binary_accuracy: 0.7810\n",
      "Epoch 1333/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4719 - binary_accuracy: 0.8094 - val_loss: 0.5403 - val_binary_accuracy: 0.7810\n",
      "Epoch 1334/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4718 - binary_accuracy: 0.8094 - val_loss: 0.5403 - val_binary_accuracy: 0.7810\n",
      "Epoch 1335/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4718 - binary_accuracy: 0.8096 - val_loss: 0.5403 - val_binary_accuracy: 0.7810\n",
      "Epoch 1336/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4718 - binary_accuracy: 0.8101 - val_loss: 0.5403 - val_binary_accuracy: 0.7836\n",
      "Epoch 1337/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4717 - binary_accuracy: 0.8105 - val_loss: 0.5402 - val_binary_accuracy: 0.7836\n",
      "Epoch 1338/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4717 - binary_accuracy: 0.8103 - val_loss: 0.5402 - val_binary_accuracy: 0.7836\n",
      "Epoch 1339/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4716 - binary_accuracy: 0.8103 - val_loss: 0.5402 - val_binary_accuracy: 0.7831\n",
      "Epoch 1340/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4716 - binary_accuracy: 0.8103 - val_loss: 0.5402 - val_binary_accuracy: 0.7841\n",
      "Epoch 1341/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4715 - binary_accuracy: 0.8106 - val_loss: 0.5402 - val_binary_accuracy: 0.7836\n",
      "Epoch 1342/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4715 - binary_accuracy: 0.8105 - val_loss: 0.5402 - val_binary_accuracy: 0.7836\n",
      "Epoch 1343/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4715 - binary_accuracy: 0.8101 - val_loss: 0.5401 - val_binary_accuracy: 0.7831\n",
      "Epoch 1344/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4714 - binary_accuracy: 0.8101 - val_loss: 0.5401 - val_binary_accuracy: 0.7831\n",
      "Epoch 1345/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4714 - binary_accuracy: 0.8103 - val_loss: 0.5401 - val_binary_accuracy: 0.7831\n",
      "Epoch 1346/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4713 - binary_accuracy: 0.8101 - val_loss: 0.5401 - val_binary_accuracy: 0.7831\n",
      "Epoch 1347/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4713 - binary_accuracy: 0.8101 - val_loss: 0.5401 - val_binary_accuracy: 0.7831\n",
      "Epoch 1348/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4713 - binary_accuracy: 0.8103 - val_loss: 0.5400 - val_binary_accuracy: 0.7831\n",
      "Epoch 1349/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4712 - binary_accuracy: 0.8105 - val_loss: 0.5400 - val_binary_accuracy: 0.7826\n",
      "Epoch 1350/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4712 - binary_accuracy: 0.8105 - val_loss: 0.5400 - val_binary_accuracy: 0.7826\n",
      "Epoch 1351/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4711 - binary_accuracy: 0.8103 - val_loss: 0.5400 - val_binary_accuracy: 0.7826\n",
      "Epoch 1352/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4711 - binary_accuracy: 0.8101 - val_loss: 0.5400 - val_binary_accuracy: 0.7826\n",
      "Epoch 1353/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4710 - binary_accuracy: 0.8101 - val_loss: 0.5400 - val_binary_accuracy: 0.7831\n",
      "Epoch 1354/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4710 - binary_accuracy: 0.8105 - val_loss: 0.5400 - val_binary_accuracy: 0.7836\n",
      "Epoch 1355/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4710 - binary_accuracy: 0.8101 - val_loss: 0.5399 - val_binary_accuracy: 0.7841\n",
      "Epoch 1356/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4709 - binary_accuracy: 0.8103 - val_loss: 0.5399 - val_binary_accuracy: 0.7862\n",
      "Epoch 1357/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4709 - binary_accuracy: 0.8105 - val_loss: 0.5399 - val_binary_accuracy: 0.7868\n",
      "Epoch 1358/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4709 - binary_accuracy: 0.8106 - val_loss: 0.5399 - val_binary_accuracy: 0.7868\n",
      "Epoch 1359/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4708 - binary_accuracy: 0.8105 - val_loss: 0.5398 - val_binary_accuracy: 0.7868\n",
      "Epoch 1360/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4708 - binary_accuracy: 0.8101 - val_loss: 0.5398 - val_binary_accuracy: 0.7862\n",
      "Epoch 1361/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4707 - binary_accuracy: 0.8101 - val_loss: 0.5398 - val_binary_accuracy: 0.7868\n",
      "Epoch 1362/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4707 - binary_accuracy: 0.8098 - val_loss: 0.5398 - val_binary_accuracy: 0.7841\n",
      "Epoch 1363/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4706 - binary_accuracy: 0.8101 - val_loss: 0.5398 - val_binary_accuracy: 0.7857\n",
      "Epoch 1364/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4706 - binary_accuracy: 0.8099 - val_loss: 0.5398 - val_binary_accuracy: 0.7852\n",
      "Epoch 1365/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4706 - binary_accuracy: 0.8099 - val_loss: 0.5397 - val_binary_accuracy: 0.7857\n",
      "Epoch 1366/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4705 - binary_accuracy: 0.8099 - val_loss: 0.5397 - val_binary_accuracy: 0.7847\n",
      "Epoch 1367/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4705 - binary_accuracy: 0.8099 - val_loss: 0.5397 - val_binary_accuracy: 0.7847\n",
      "Epoch 1368/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4705 - binary_accuracy: 0.8099 - val_loss: 0.5397 - val_binary_accuracy: 0.7852\n",
      "Epoch 1369/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4704 - binary_accuracy: 0.8099 - val_loss: 0.5397 - val_binary_accuracy: 0.7852\n",
      "Epoch 1370/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4704 - binary_accuracy: 0.8098 - val_loss: 0.5397 - val_binary_accuracy: 0.7857\n",
      "Epoch 1371/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4703 - binary_accuracy: 0.8096 - val_loss: 0.5396 - val_binary_accuracy: 0.7852\n",
      "Epoch 1372/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4703 - binary_accuracy: 0.8101 - val_loss: 0.5397 - val_binary_accuracy: 0.7857\n",
      "Epoch 1373/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4703 - binary_accuracy: 0.8096 - val_loss: 0.5396 - val_binary_accuracy: 0.7857\n",
      "Epoch 1374/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4702 - binary_accuracy: 0.8096 - val_loss: 0.5396 - val_binary_accuracy: 0.7852\n",
      "Epoch 1375/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4702 - binary_accuracy: 0.8099 - val_loss: 0.5396 - val_binary_accuracy: 0.7847\n",
      "Epoch 1376/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4701 - binary_accuracy: 0.8099 - val_loss: 0.5396 - val_binary_accuracy: 0.7847\n",
      "Epoch 1377/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4701 - binary_accuracy: 0.8099 - val_loss: 0.5396 - val_binary_accuracy: 0.7852\n",
      "Epoch 1378/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4701 - binary_accuracy: 0.8101 - val_loss: 0.5396 - val_binary_accuracy: 0.7852\n",
      "Epoch 1379/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4700 - binary_accuracy: 0.8101 - val_loss: 0.5396 - val_binary_accuracy: 0.7847\n",
      "Epoch 1380/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4700 - binary_accuracy: 0.8099 - val_loss: 0.5396 - val_binary_accuracy: 0.7847\n",
      "Epoch 1381/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4699 - binary_accuracy: 0.8098 - val_loss: 0.5396 - val_binary_accuracy: 0.7847\n",
      "Epoch 1382/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4699 - binary_accuracy: 0.8098 - val_loss: 0.5395 - val_binary_accuracy: 0.7847\n",
      "Epoch 1383/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4699 - binary_accuracy: 0.8094 - val_loss: 0.5395 - val_binary_accuracy: 0.7847\n",
      "Epoch 1384/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4698 - binary_accuracy: 0.8094 - val_loss: 0.5395 - val_binary_accuracy: 0.7847\n",
      "Epoch 1385/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4698 - binary_accuracy: 0.8094 - val_loss: 0.5395 - val_binary_accuracy: 0.7852\n",
      "Epoch 1386/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4697 - binary_accuracy: 0.8094 - val_loss: 0.5394 - val_binary_accuracy: 0.7852\n",
      "Epoch 1387/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4697 - binary_accuracy: 0.8094 - val_loss: 0.5394 - val_binary_accuracy: 0.7852\n",
      "Epoch 1388/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4697 - binary_accuracy: 0.8094 - val_loss: 0.5394 - val_binary_accuracy: 0.7852\n",
      "Epoch 1389/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4696 - binary_accuracy: 0.8098 - val_loss: 0.5394 - val_binary_accuracy: 0.7852\n",
      "Epoch 1390/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4696 - binary_accuracy: 0.8098 - val_loss: 0.5394 - val_binary_accuracy: 0.7852\n",
      "Epoch 1391/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4695 - binary_accuracy: 0.8098 - val_loss: 0.5394 - val_binary_accuracy: 0.7857\n",
      "Epoch 1392/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4695 - binary_accuracy: 0.8098 - val_loss: 0.5394 - val_binary_accuracy: 0.7857\n",
      "Epoch 1393/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4695 - binary_accuracy: 0.8099 - val_loss: 0.5394 - val_binary_accuracy: 0.7857\n",
      "Epoch 1394/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4694 - binary_accuracy: 0.8098 - val_loss: 0.5393 - val_binary_accuracy: 0.7857\n",
      "Epoch 1395/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4694 - binary_accuracy: 0.8098 - val_loss: 0.5393 - val_binary_accuracy: 0.7857\n",
      "Epoch 1396/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4693 - binary_accuracy: 0.8099 - val_loss: 0.5393 - val_binary_accuracy: 0.7852\n",
      "Epoch 1397/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4693 - binary_accuracy: 0.8098 - val_loss: 0.5393 - val_binary_accuracy: 0.7847\n",
      "Epoch 1398/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4693 - binary_accuracy: 0.8098 - val_loss: 0.5393 - val_binary_accuracy: 0.7857\n",
      "Epoch 1399/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4692 - binary_accuracy: 0.8098 - val_loss: 0.5393 - val_binary_accuracy: 0.7852\n",
      "Epoch 1400/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4692 - binary_accuracy: 0.8099 - val_loss: 0.5393 - val_binary_accuracy: 0.7847\n",
      "Epoch 1401/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4692 - binary_accuracy: 0.8101 - val_loss: 0.5393 - val_binary_accuracy: 0.7852\n",
      "Epoch 1402/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4691 - binary_accuracy: 0.8103 - val_loss: 0.5393 - val_binary_accuracy: 0.7857\n",
      "Epoch 1403/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4691 - binary_accuracy: 0.8103 - val_loss: 0.5392 - val_binary_accuracy: 0.7868\n",
      "Epoch 1404/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4690 - binary_accuracy: 0.8105 - val_loss: 0.5392 - val_binary_accuracy: 0.7873\n",
      "Epoch 1405/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4690 - binary_accuracy: 0.8105 - val_loss: 0.5392 - val_binary_accuracy: 0.7862\n",
      "Epoch 1406/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4690 - binary_accuracy: 0.8105 - val_loss: 0.5392 - val_binary_accuracy: 0.7852\n",
      "Epoch 1407/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4689 - binary_accuracy: 0.8101 - val_loss: 0.5392 - val_binary_accuracy: 0.7852\n",
      "Epoch 1408/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4689 - binary_accuracy: 0.8099 - val_loss: 0.5392 - val_binary_accuracy: 0.7847\n",
      "Epoch 1409/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4688 - binary_accuracy: 0.8099 - val_loss: 0.5391 - val_binary_accuracy: 0.7852\n",
      "Epoch 1410/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4688 - binary_accuracy: 0.8103 - val_loss: 0.5391 - val_binary_accuracy: 0.7852\n",
      "Epoch 1411/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4688 - binary_accuracy: 0.8103 - val_loss: 0.5391 - val_binary_accuracy: 0.7847\n",
      "Epoch 1412/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4687 - binary_accuracy: 0.8101 - val_loss: 0.5391 - val_binary_accuracy: 0.7841\n",
      "Epoch 1413/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4687 - binary_accuracy: 0.8101 - val_loss: 0.5391 - val_binary_accuracy: 0.7841\n",
      "Epoch 1414/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4687 - binary_accuracy: 0.8103 - val_loss: 0.5391 - val_binary_accuracy: 0.7841\n",
      "Epoch 1415/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4686 - binary_accuracy: 0.8103 - val_loss: 0.5391 - val_binary_accuracy: 0.7841\n",
      "Epoch 1416/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4686 - binary_accuracy: 0.8103 - val_loss: 0.5391 - val_binary_accuracy: 0.7841\n",
      "Epoch 1417/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4685 - binary_accuracy: 0.8103 - val_loss: 0.5391 - val_binary_accuracy: 0.7841\n",
      "Epoch 1418/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4685 - binary_accuracy: 0.8105 - val_loss: 0.5391 - val_binary_accuracy: 0.7841\n",
      "Epoch 1419/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4685 - binary_accuracy: 0.8106 - val_loss: 0.5391 - val_binary_accuracy: 0.7847\n",
      "Epoch 1420/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4684 - binary_accuracy: 0.8110 - val_loss: 0.5391 - val_binary_accuracy: 0.7847\n",
      "Epoch 1421/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4684 - binary_accuracy: 0.8110 - val_loss: 0.5391 - val_binary_accuracy: 0.7847\n",
      "Epoch 1422/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4683 - binary_accuracy: 0.8112 - val_loss: 0.5391 - val_binary_accuracy: 0.7847\n",
      "Epoch 1423/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4683 - binary_accuracy: 0.8114 - val_loss: 0.5390 - val_binary_accuracy: 0.7873\n",
      "Epoch 1424/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4683 - binary_accuracy: 0.8115 - val_loss: 0.5390 - val_binary_accuracy: 0.7878\n",
      "Epoch 1425/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4682 - binary_accuracy: 0.8115 - val_loss: 0.5390 - val_binary_accuracy: 0.7873\n",
      "Epoch 1426/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4682 - binary_accuracy: 0.8115 - val_loss: 0.5390 - val_binary_accuracy: 0.7873\n",
      "Epoch 1427/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4682 - binary_accuracy: 0.8115 - val_loss: 0.5390 - val_binary_accuracy: 0.7862\n",
      "Epoch 1428/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4681 - binary_accuracy: 0.8115 - val_loss: 0.5390 - val_binary_accuracy: 0.7862\n",
      "Epoch 1429/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4681 - binary_accuracy: 0.8115 - val_loss: 0.5390 - val_binary_accuracy: 0.7857\n",
      "Epoch 1430/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4680 - binary_accuracy: 0.8117 - val_loss: 0.5390 - val_binary_accuracy: 0.7857\n",
      "Epoch 1431/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4680 - binary_accuracy: 0.8117 - val_loss: 0.5390 - val_binary_accuracy: 0.7852\n",
      "Epoch 1432/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4680 - binary_accuracy: 0.8115 - val_loss: 0.5389 - val_binary_accuracy: 0.7857\n",
      "Epoch 1433/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4679 - binary_accuracy: 0.8115 - val_loss: 0.5389 - val_binary_accuracy: 0.7862\n",
      "Epoch 1434/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4679 - binary_accuracy: 0.8117 - val_loss: 0.5389 - val_binary_accuracy: 0.7852\n",
      "Epoch 1435/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4679 - binary_accuracy: 0.8119 - val_loss: 0.5389 - val_binary_accuracy: 0.7852\n",
      "Epoch 1436/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4678 - binary_accuracy: 0.8117 - val_loss: 0.5389 - val_binary_accuracy: 0.7852\n",
      "Epoch 1437/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4678 - binary_accuracy: 0.8115 - val_loss: 0.5389 - val_binary_accuracy: 0.7852\n",
      "Epoch 1438/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4677 - binary_accuracy: 0.8117 - val_loss: 0.5389 - val_binary_accuracy: 0.7852\n",
      "Epoch 1439/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4677 - binary_accuracy: 0.8121 - val_loss: 0.5389 - val_binary_accuracy: 0.7852\n",
      "Epoch 1440/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4677 - binary_accuracy: 0.8121 - val_loss: 0.5389 - val_binary_accuracy: 0.7862\n",
      "Epoch 1441/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4676 - binary_accuracy: 0.8119 - val_loss: 0.5389 - val_binary_accuracy: 0.7868\n",
      "Epoch 1442/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4676 - binary_accuracy: 0.8119 - val_loss: 0.5389 - val_binary_accuracy: 0.7868\n",
      "Epoch 1443/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4676 - binary_accuracy: 0.8119 - val_loss: 0.5389 - val_binary_accuracy: 0.7868\n",
      "Epoch 1444/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4675 - binary_accuracy: 0.8121 - val_loss: 0.5388 - val_binary_accuracy: 0.7868\n",
      "Epoch 1445/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4675 - binary_accuracy: 0.8121 - val_loss: 0.5388 - val_binary_accuracy: 0.7868\n",
      "Epoch 1446/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4674 - binary_accuracy: 0.8122 - val_loss: 0.5388 - val_binary_accuracy: 0.7868\n",
      "Epoch 1447/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4674 - binary_accuracy: 0.8126 - val_loss: 0.5387 - val_binary_accuracy: 0.7868\n",
      "Epoch 1448/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4674 - binary_accuracy: 0.8122 - val_loss: 0.5387 - val_binary_accuracy: 0.7873\n",
      "Epoch 1449/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4673 - binary_accuracy: 0.8119 - val_loss: 0.5387 - val_binary_accuracy: 0.7873\n",
      "Epoch 1450/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4673 - binary_accuracy: 0.8122 - val_loss: 0.5387 - val_binary_accuracy: 0.7873\n",
      "Epoch 1451/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4673 - binary_accuracy: 0.8124 - val_loss: 0.5386 - val_binary_accuracy: 0.7868\n",
      "Epoch 1452/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4672 - binary_accuracy: 0.8124 - val_loss: 0.5387 - val_binary_accuracy: 0.7862\n",
      "Epoch 1453/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4672 - binary_accuracy: 0.8124 - val_loss: 0.5387 - val_binary_accuracy: 0.7868\n",
      "Epoch 1454/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4671 - binary_accuracy: 0.8122 - val_loss: 0.5387 - val_binary_accuracy: 0.7862\n",
      "Epoch 1455/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4671 - binary_accuracy: 0.8122 - val_loss: 0.5387 - val_binary_accuracy: 0.7862\n",
      "Epoch 1456/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4671 - binary_accuracy: 0.8122 - val_loss: 0.5387 - val_binary_accuracy: 0.7868\n",
      "Epoch 1457/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4670 - binary_accuracy: 0.8121 - val_loss: 0.5387 - val_binary_accuracy: 0.7868\n",
      "Epoch 1458/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4670 - binary_accuracy: 0.8124 - val_loss: 0.5387 - val_binary_accuracy: 0.7868\n",
      "Epoch 1459/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4670 - binary_accuracy: 0.8124 - val_loss: 0.5387 - val_binary_accuracy: 0.7868\n",
      "Epoch 1460/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4669 - binary_accuracy: 0.8122 - val_loss: 0.5387 - val_binary_accuracy: 0.7878\n",
      "Epoch 1461/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4669 - binary_accuracy: 0.8124 - val_loss: 0.5387 - val_binary_accuracy: 0.7873\n",
      "Epoch 1462/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4668 - binary_accuracy: 0.8124 - val_loss: 0.5387 - val_binary_accuracy: 0.7878\n",
      "Epoch 1463/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4668 - binary_accuracy: 0.8124 - val_loss: 0.5387 - val_binary_accuracy: 0.7862\n",
      "Epoch 1464/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4668 - binary_accuracy: 0.8124 - val_loss: 0.5387 - val_binary_accuracy: 0.7862\n",
      "Epoch 1465/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4667 - binary_accuracy: 0.8126 - val_loss: 0.5386 - val_binary_accuracy: 0.7868\n",
      "Epoch 1466/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4667 - binary_accuracy: 0.8129 - val_loss: 0.5386 - val_binary_accuracy: 0.7868\n",
      "Epoch 1467/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4667 - binary_accuracy: 0.8129 - val_loss: 0.5386 - val_binary_accuracy: 0.7868\n",
      "Epoch 1468/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4666 - binary_accuracy: 0.8129 - val_loss: 0.5386 - val_binary_accuracy: 0.7878\n",
      "Epoch 1469/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4666 - binary_accuracy: 0.8124 - val_loss: 0.5387 - val_binary_accuracy: 0.7878\n",
      "Epoch 1470/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4666 - binary_accuracy: 0.8124 - val_loss: 0.5387 - val_binary_accuracy: 0.7873\n",
      "Epoch 1471/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4665 - binary_accuracy: 0.8124 - val_loss: 0.5386 - val_binary_accuracy: 0.7873\n",
      "Epoch 1472/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4665 - binary_accuracy: 0.8124 - val_loss: 0.5386 - val_binary_accuracy: 0.7873\n",
      "Epoch 1473/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4665 - binary_accuracy: 0.8128 - val_loss: 0.5386 - val_binary_accuracy: 0.7862\n",
      "Epoch 1474/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4664 - binary_accuracy: 0.8128 - val_loss: 0.5386 - val_binary_accuracy: 0.7862\n",
      "Epoch 1475/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4664 - binary_accuracy: 0.8129 - val_loss: 0.5386 - val_binary_accuracy: 0.7862\n",
      "Epoch 1476/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4663 - binary_accuracy: 0.8128 - val_loss: 0.5386 - val_binary_accuracy: 0.7862\n",
      "Epoch 1477/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4663 - binary_accuracy: 0.8126 - val_loss: 0.5386 - val_binary_accuracy: 0.7868\n",
      "Epoch 1478/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4663 - binary_accuracy: 0.8124 - val_loss: 0.5386 - val_binary_accuracy: 0.7868\n",
      "Epoch 1479/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4662 - binary_accuracy: 0.8128 - val_loss: 0.5386 - val_binary_accuracy: 0.7868\n",
      "Epoch 1480/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4662 - binary_accuracy: 0.8129 - val_loss: 0.5386 - val_binary_accuracy: 0.7868\n",
      "Epoch 1481/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4662 - binary_accuracy: 0.8128 - val_loss: 0.5386 - val_binary_accuracy: 0.7868\n",
      "Epoch 1482/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4661 - binary_accuracy: 0.8128 - val_loss: 0.5386 - val_binary_accuracy: 0.7868\n",
      "Epoch 1483/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4661 - binary_accuracy: 0.8126 - val_loss: 0.5386 - val_binary_accuracy: 0.7868\n",
      "Epoch 1484/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4660 - binary_accuracy: 0.8124 - val_loss: 0.5386 - val_binary_accuracy: 0.7868\n",
      "Epoch 1485/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4660 - binary_accuracy: 0.8126 - val_loss: 0.5386 - val_binary_accuracy: 0.7868\n",
      "Epoch 1486/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4660 - binary_accuracy: 0.8126 - val_loss: 0.5386 - val_binary_accuracy: 0.7868\n",
      "Epoch 1487/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4659 - binary_accuracy: 0.8126 - val_loss: 0.5386 - val_binary_accuracy: 0.7868\n",
      "Epoch 1488/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4659 - binary_accuracy: 0.8128 - val_loss: 0.5386 - val_binary_accuracy: 0.7868\n",
      "Epoch 1489/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4659 - binary_accuracy: 0.8126 - val_loss: 0.5385 - val_binary_accuracy: 0.7873\n",
      "Epoch 1490/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4658 - binary_accuracy: 0.8126 - val_loss: 0.5385 - val_binary_accuracy: 0.7868\n",
      "Epoch 1491/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4658 - binary_accuracy: 0.8129 - val_loss: 0.5385 - val_binary_accuracy: 0.7868\n",
      "Epoch 1492/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4658 - binary_accuracy: 0.8128 - val_loss: 0.5385 - val_binary_accuracy: 0.7868\n",
      "Epoch 1493/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4657 - binary_accuracy: 0.8128 - val_loss: 0.5384 - val_binary_accuracy: 0.7868\n",
      "Epoch 1494/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4657 - binary_accuracy: 0.8129 - val_loss: 0.5384 - val_binary_accuracy: 0.7873\n",
      "Epoch 1495/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4657 - binary_accuracy: 0.8129 - val_loss: 0.5384 - val_binary_accuracy: 0.7873\n",
      "Epoch 1496/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4656 - binary_accuracy: 0.8129 - val_loss: 0.5384 - val_binary_accuracy: 0.7873\n",
      "Epoch 1497/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4656 - binary_accuracy: 0.8129 - val_loss: 0.5384 - val_binary_accuracy: 0.7878\n",
      "Epoch 1498/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4656 - binary_accuracy: 0.8129 - val_loss: 0.5384 - val_binary_accuracy: 0.7883\n",
      "Epoch 1499/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4655 - binary_accuracy: 0.8129 - val_loss: 0.5384 - val_binary_accuracy: 0.7883\n",
      "Epoch 1500/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4655 - binary_accuracy: 0.8129 - val_loss: 0.5384 - val_binary_accuracy: 0.7878\n",
      "Epoch 1501/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4654 - binary_accuracy: 0.8131 - val_loss: 0.5384 - val_binary_accuracy: 0.7878\n",
      "Epoch 1502/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4654 - binary_accuracy: 0.8135 - val_loss: 0.5384 - val_binary_accuracy: 0.7873\n",
      "Epoch 1503/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4654 - binary_accuracy: 0.8136 - val_loss: 0.5384 - val_binary_accuracy: 0.7883\n",
      "Epoch 1504/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4653 - binary_accuracy: 0.8135 - val_loss: 0.5384 - val_binary_accuracy: 0.7883\n",
      "Epoch 1505/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4653 - binary_accuracy: 0.8133 - val_loss: 0.5384 - val_binary_accuracy: 0.7878\n",
      "Epoch 1506/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4653 - binary_accuracy: 0.8135 - val_loss: 0.5384 - val_binary_accuracy: 0.7873\n",
      "Epoch 1507/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4652 - binary_accuracy: 0.8138 - val_loss: 0.5383 - val_binary_accuracy: 0.7873\n",
      "Epoch 1508/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4652 - binary_accuracy: 0.8136 - val_loss: 0.5384 - val_binary_accuracy: 0.7873\n",
      "Epoch 1509/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4652 - binary_accuracy: 0.8133 - val_loss: 0.5383 - val_binary_accuracy: 0.7873\n",
      "Epoch 1510/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4651 - binary_accuracy: 0.8135 - val_loss: 0.5383 - val_binary_accuracy: 0.7883\n",
      "Epoch 1511/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4651 - binary_accuracy: 0.8135 - val_loss: 0.5383 - val_binary_accuracy: 0.7883\n",
      "Epoch 1512/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4651 - binary_accuracy: 0.8136 - val_loss: 0.5383 - val_binary_accuracy: 0.7883\n",
      "Epoch 1513/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4650 - binary_accuracy: 0.8136 - val_loss: 0.5383 - val_binary_accuracy: 0.7883\n",
      "Epoch 1514/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4650 - binary_accuracy: 0.8138 - val_loss: 0.5383 - val_binary_accuracy: 0.7889\n",
      "Epoch 1515/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4650 - binary_accuracy: 0.8143 - val_loss: 0.5383 - val_binary_accuracy: 0.7889\n",
      "Epoch 1516/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4649 - binary_accuracy: 0.8143 - val_loss: 0.5383 - val_binary_accuracy: 0.7889\n",
      "Epoch 1517/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4649 - binary_accuracy: 0.8143 - val_loss: 0.5383 - val_binary_accuracy: 0.7889\n",
      "Epoch 1518/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4649 - binary_accuracy: 0.8142 - val_loss: 0.5383 - val_binary_accuracy: 0.7889\n",
      "Epoch 1519/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4648 - binary_accuracy: 0.8142 - val_loss: 0.5383 - val_binary_accuracy: 0.7883\n",
      "Epoch 1520/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4648 - binary_accuracy: 0.8142 - val_loss: 0.5383 - val_binary_accuracy: 0.7889\n",
      "Epoch 1521/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4648 - binary_accuracy: 0.8138 - val_loss: 0.5383 - val_binary_accuracy: 0.7883\n",
      "Epoch 1522/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4647 - binary_accuracy: 0.8136 - val_loss: 0.5383 - val_binary_accuracy: 0.7878\n",
      "Epoch 1523/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4647 - binary_accuracy: 0.8136 - val_loss: 0.5383 - val_binary_accuracy: 0.7878\n",
      "Epoch 1524/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4646 - binary_accuracy: 0.8138 - val_loss: 0.5383 - val_binary_accuracy: 0.7878\n",
      "Epoch 1525/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4646 - binary_accuracy: 0.8138 - val_loss: 0.5383 - val_binary_accuracy: 0.7878\n",
      "Epoch 1526/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4646 - binary_accuracy: 0.8138 - val_loss: 0.5383 - val_binary_accuracy: 0.7878\n",
      "Epoch 1527/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4645 - binary_accuracy: 0.8140 - val_loss: 0.5383 - val_binary_accuracy: 0.7883\n",
      "Epoch 1528/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4645 - binary_accuracy: 0.8140 - val_loss: 0.5383 - val_binary_accuracy: 0.7883\n",
      "Epoch 1529/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4645 - binary_accuracy: 0.8143 - val_loss: 0.5383 - val_binary_accuracy: 0.7883\n",
      "Epoch 1530/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4644 - binary_accuracy: 0.8142 - val_loss: 0.5382 - val_binary_accuracy: 0.7878\n",
      "Epoch 1531/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4644 - binary_accuracy: 0.8142 - val_loss: 0.5382 - val_binary_accuracy: 0.7878\n",
      "Epoch 1532/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4644 - binary_accuracy: 0.8140 - val_loss: 0.5382 - val_binary_accuracy: 0.7873\n",
      "Epoch 1533/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4643 - binary_accuracy: 0.8138 - val_loss: 0.5382 - val_binary_accuracy: 0.7873\n",
      "Epoch 1534/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4643 - binary_accuracy: 0.8143 - val_loss: 0.5382 - val_binary_accuracy: 0.7878\n",
      "Epoch 1535/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4643 - binary_accuracy: 0.8142 - val_loss: 0.5381 - val_binary_accuracy: 0.7883\n",
      "Epoch 1536/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4642 - binary_accuracy: 0.8142 - val_loss: 0.5381 - val_binary_accuracy: 0.7883\n",
      "Epoch 1537/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4642 - binary_accuracy: 0.8142 - val_loss: 0.5381 - val_binary_accuracy: 0.7883\n",
      "Epoch 1538/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4642 - binary_accuracy: 0.8142 - val_loss: 0.5381 - val_binary_accuracy: 0.7883\n",
      "Epoch 1539/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4641 - binary_accuracy: 0.8142 - val_loss: 0.5381 - val_binary_accuracy: 0.7883\n",
      "Epoch 1540/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4641 - binary_accuracy: 0.8142 - val_loss: 0.5381 - val_binary_accuracy: 0.7883\n",
      "Epoch 1541/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4641 - binary_accuracy: 0.8142 - val_loss: 0.5381 - val_binary_accuracy: 0.7883\n",
      "Epoch 1542/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4640 - binary_accuracy: 0.8143 - val_loss: 0.5381 - val_binary_accuracy: 0.7889\n",
      "Epoch 1543/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4640 - binary_accuracy: 0.8143 - val_loss: 0.5381 - val_binary_accuracy: 0.7878\n",
      "Epoch 1544/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4640 - binary_accuracy: 0.8142 - val_loss: 0.5381 - val_binary_accuracy: 0.7878\n",
      "Epoch 1545/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4639 - binary_accuracy: 0.8142 - val_loss: 0.5381 - val_binary_accuracy: 0.7873\n",
      "Epoch 1546/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4639 - binary_accuracy: 0.8142 - val_loss: 0.5381 - val_binary_accuracy: 0.7878\n",
      "Epoch 1547/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4639 - binary_accuracy: 0.8143 - val_loss: 0.5381 - val_binary_accuracy: 0.7878\n",
      "Epoch 1548/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4638 - binary_accuracy: 0.8145 - val_loss: 0.5381 - val_binary_accuracy: 0.7883\n",
      "Epoch 1549/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4638 - binary_accuracy: 0.8147 - val_loss: 0.5380 - val_binary_accuracy: 0.7883\n",
      "Epoch 1550/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4638 - binary_accuracy: 0.8147 - val_loss: 0.5380 - val_binary_accuracy: 0.7883\n",
      "Epoch 1551/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4637 - binary_accuracy: 0.8150 - val_loss: 0.5380 - val_binary_accuracy: 0.7883\n",
      "Epoch 1552/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4637 - binary_accuracy: 0.8149 - val_loss: 0.5380 - val_binary_accuracy: 0.7883\n",
      "Epoch 1553/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4637 - binary_accuracy: 0.8149 - val_loss: 0.5380 - val_binary_accuracy: 0.7883\n",
      "Epoch 1554/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4636 - binary_accuracy: 0.8147 - val_loss: 0.5380 - val_binary_accuracy: 0.7883\n",
      "Epoch 1555/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4636 - binary_accuracy: 0.8143 - val_loss: 0.5380 - val_binary_accuracy: 0.7883\n",
      "Epoch 1556/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4636 - binary_accuracy: 0.8145 - val_loss: 0.5380 - val_binary_accuracy: 0.7889\n",
      "Epoch 1557/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4635 - binary_accuracy: 0.8147 - val_loss: 0.5380 - val_binary_accuracy: 0.7889\n",
      "Epoch 1558/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4635 - binary_accuracy: 0.8145 - val_loss: 0.5379 - val_binary_accuracy: 0.7889\n",
      "Epoch 1559/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4635 - binary_accuracy: 0.8145 - val_loss: 0.5379 - val_binary_accuracy: 0.7889\n",
      "Epoch 1560/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4634 - binary_accuracy: 0.8147 - val_loss: 0.5379 - val_binary_accuracy: 0.7883\n",
      "Epoch 1561/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4634 - binary_accuracy: 0.8145 - val_loss: 0.5379 - val_binary_accuracy: 0.7889\n",
      "Epoch 1562/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4634 - binary_accuracy: 0.8145 - val_loss: 0.5378 - val_binary_accuracy: 0.7889\n",
      "Epoch 1563/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4633 - binary_accuracy: 0.8143 - val_loss: 0.5378 - val_binary_accuracy: 0.7889\n",
      "Epoch 1564/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4633 - binary_accuracy: 0.8142 - val_loss: 0.5379 - val_binary_accuracy: 0.7883\n",
      "Epoch 1565/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4633 - binary_accuracy: 0.8143 - val_loss: 0.5378 - val_binary_accuracy: 0.7883\n",
      "Epoch 1566/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4632 - binary_accuracy: 0.8149 - val_loss: 0.5378 - val_binary_accuracy: 0.7889\n",
      "Epoch 1567/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4632 - binary_accuracy: 0.8149 - val_loss: 0.5378 - val_binary_accuracy: 0.7894\n",
      "Epoch 1568/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4632 - binary_accuracy: 0.8147 - val_loss: 0.5378 - val_binary_accuracy: 0.7894\n",
      "Epoch 1569/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4631 - binary_accuracy: 0.8147 - val_loss: 0.5378 - val_binary_accuracy: 0.7894\n",
      "Epoch 1570/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4631 - binary_accuracy: 0.8145 - val_loss: 0.5378 - val_binary_accuracy: 0.7894\n",
      "Epoch 1571/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4631 - binary_accuracy: 0.8142 - val_loss: 0.5378 - val_binary_accuracy: 0.7899\n",
      "Epoch 1572/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4630 - binary_accuracy: 0.8145 - val_loss: 0.5378 - val_binary_accuracy: 0.7894\n",
      "Epoch 1573/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4630 - binary_accuracy: 0.8140 - val_loss: 0.5377 - val_binary_accuracy: 0.7889\n",
      "Epoch 1574/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4630 - binary_accuracy: 0.8140 - val_loss: 0.5377 - val_binary_accuracy: 0.7889\n",
      "Epoch 1575/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4629 - binary_accuracy: 0.8142 - val_loss: 0.5377 - val_binary_accuracy: 0.7889\n",
      "Epoch 1576/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4629 - binary_accuracy: 0.8142 - val_loss: 0.5377 - val_binary_accuracy: 0.7889\n",
      "Epoch 1577/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4629 - binary_accuracy: 0.8142 - val_loss: 0.5377 - val_binary_accuracy: 0.7894\n",
      "Epoch 1578/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4628 - binary_accuracy: 0.8142 - val_loss: 0.5377 - val_binary_accuracy: 0.7894\n",
      "Epoch 1579/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4628 - binary_accuracy: 0.8143 - val_loss: 0.5377 - val_binary_accuracy: 0.7894\n",
      "Epoch 1580/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4628 - binary_accuracy: 0.8143 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1581/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4627 - binary_accuracy: 0.8142 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1582/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4627 - binary_accuracy: 0.8143 - val_loss: 0.5377 - val_binary_accuracy: 0.7894\n",
      "Epoch 1583/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4627 - binary_accuracy: 0.8143 - val_loss: 0.5377 - val_binary_accuracy: 0.7894\n",
      "Epoch 1584/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4626 - binary_accuracy: 0.8143 - val_loss: 0.5377 - val_binary_accuracy: 0.7894\n",
      "Epoch 1585/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4626 - binary_accuracy: 0.8143 - val_loss: 0.5377 - val_binary_accuracy: 0.7894\n",
      "Epoch 1586/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4626 - binary_accuracy: 0.8147 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1587/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4625 - binary_accuracy: 0.8145 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1588/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4625 - binary_accuracy: 0.8147 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1589/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4625 - binary_accuracy: 0.8147 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1590/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4624 - binary_accuracy: 0.8145 - val_loss: 0.5377 - val_binary_accuracy: 0.7894\n",
      "Epoch 1591/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4624 - binary_accuracy: 0.8145 - val_loss: 0.5377 - val_binary_accuracy: 0.7894\n",
      "Epoch 1592/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4624 - binary_accuracy: 0.8145 - val_loss: 0.5377 - val_binary_accuracy: 0.7894\n",
      "Epoch 1593/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4623 - binary_accuracy: 0.8140 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1594/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4623 - binary_accuracy: 0.8142 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1595/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4623 - binary_accuracy: 0.8142 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1596/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4622 - binary_accuracy: 0.8142 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1597/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4622 - binary_accuracy: 0.8142 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1598/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4622 - binary_accuracy: 0.8142 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1599/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4621 - binary_accuracy: 0.8143 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1600/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4621 - binary_accuracy: 0.8143 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1601/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4621 - binary_accuracy: 0.8145 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1602/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4620 - binary_accuracy: 0.8150 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1603/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4620 - binary_accuracy: 0.8149 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1604/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4620 - binary_accuracy: 0.8145 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1605/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4619 - binary_accuracy: 0.8147 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1606/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4619 - binary_accuracy: 0.8149 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1607/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4619 - binary_accuracy: 0.8147 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1608/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4619 - binary_accuracy: 0.8147 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1609/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4618 - binary_accuracy: 0.8145 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1610/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4618 - binary_accuracy: 0.8147 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1611/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4618 - binary_accuracy: 0.8149 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1612/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4617 - binary_accuracy: 0.8149 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1613/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4617 - binary_accuracy: 0.8152 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1614/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4617 - binary_accuracy: 0.8152 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1615/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4616 - binary_accuracy: 0.8154 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1616/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4616 - binary_accuracy: 0.8152 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1617/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4616 - binary_accuracy: 0.8150 - val_loss: 0.5376 - val_binary_accuracy: 0.7889\n",
      "Epoch 1618/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4615 - binary_accuracy: 0.8150 - val_loss: 0.5376 - val_binary_accuracy: 0.7894\n",
      "Epoch 1619/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4615 - binary_accuracy: 0.8150 - val_loss: 0.5376 - val_binary_accuracy: 0.7889\n",
      "Epoch 1620/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4615 - binary_accuracy: 0.8150 - val_loss: 0.5375 - val_binary_accuracy: 0.7883\n",
      "Epoch 1621/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4614 - binary_accuracy: 0.8150 - val_loss: 0.5375 - val_binary_accuracy: 0.7883\n",
      "Epoch 1622/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4614 - binary_accuracy: 0.8152 - val_loss: 0.5375 - val_binary_accuracy: 0.7889\n",
      "Epoch 1623/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4614 - binary_accuracy: 0.8152 - val_loss: 0.5375 - val_binary_accuracy: 0.7894\n",
      "Epoch 1624/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4613 - binary_accuracy: 0.8152 - val_loss: 0.5375 - val_binary_accuracy: 0.7878\n",
      "Epoch 1625/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4613 - binary_accuracy: 0.8154 - val_loss: 0.5375 - val_binary_accuracy: 0.7868\n",
      "Epoch 1626/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4613 - binary_accuracy: 0.8156 - val_loss: 0.5374 - val_binary_accuracy: 0.7873\n",
      "Epoch 1627/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4613 - binary_accuracy: 0.8159 - val_loss: 0.5374 - val_binary_accuracy: 0.7873\n",
      "Epoch 1628/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4612 - binary_accuracy: 0.8159 - val_loss: 0.5374 - val_binary_accuracy: 0.7878\n",
      "Epoch 1629/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4612 - binary_accuracy: 0.8163 - val_loss: 0.5374 - val_binary_accuracy: 0.7878\n",
      "Epoch 1630/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4612 - binary_accuracy: 0.8163 - val_loss: 0.5374 - val_binary_accuracy: 0.7878\n",
      "Epoch 1631/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4611 - binary_accuracy: 0.8163 - val_loss: 0.5374 - val_binary_accuracy: 0.7873\n",
      "Epoch 1632/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4611 - binary_accuracy: 0.8157 - val_loss: 0.5374 - val_binary_accuracy: 0.7878\n",
      "Epoch 1633/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4611 - binary_accuracy: 0.8163 - val_loss: 0.5374 - val_binary_accuracy: 0.7878\n",
      "Epoch 1634/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4610 - binary_accuracy: 0.8163 - val_loss: 0.5374 - val_binary_accuracy: 0.7878\n",
      "Epoch 1635/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4610 - binary_accuracy: 0.8170 - val_loss: 0.5374 - val_binary_accuracy: 0.7873\n",
      "Epoch 1636/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4610 - binary_accuracy: 0.8164 - val_loss: 0.5374 - val_binary_accuracy: 0.7873\n",
      "Epoch 1637/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4610 - binary_accuracy: 0.8161 - val_loss: 0.5374 - val_binary_accuracy: 0.7873\n",
      "Epoch 1638/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4609 - binary_accuracy: 0.8163 - val_loss: 0.5374 - val_binary_accuracy: 0.7873\n",
      "Epoch 1639/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4609 - binary_accuracy: 0.8168 - val_loss: 0.5374 - val_binary_accuracy: 0.7868\n",
      "Epoch 1640/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4609 - binary_accuracy: 0.8168 - val_loss: 0.5374 - val_binary_accuracy: 0.7873\n",
      "Epoch 1641/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4608 - binary_accuracy: 0.8171 - val_loss: 0.5374 - val_binary_accuracy: 0.7868\n",
      "Epoch 1642/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4608 - binary_accuracy: 0.8171 - val_loss: 0.5374 - val_binary_accuracy: 0.7868\n",
      "Epoch 1643/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4608 - binary_accuracy: 0.8171 - val_loss: 0.5374 - val_binary_accuracy: 0.7868\n",
      "Epoch 1644/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4607 - binary_accuracy: 0.8173 - val_loss: 0.5374 - val_binary_accuracy: 0.7868\n",
      "Epoch 1645/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4607 - binary_accuracy: 0.8173 - val_loss: 0.5373 - val_binary_accuracy: 0.7868\n",
      "Epoch 1646/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4607 - binary_accuracy: 0.8171 - val_loss: 0.5373 - val_binary_accuracy: 0.7868\n",
      "Epoch 1647/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4606 - binary_accuracy: 0.8173 - val_loss: 0.5373 - val_binary_accuracy: 0.7868\n",
      "Epoch 1648/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4606 - binary_accuracy: 0.8173 - val_loss: 0.5373 - val_binary_accuracy: 0.7868\n",
      "Epoch 1649/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4606 - binary_accuracy: 0.8166 - val_loss: 0.5373 - val_binary_accuracy: 0.7868\n",
      "Epoch 1650/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4606 - binary_accuracy: 0.8166 - val_loss: 0.5373 - val_binary_accuracy: 0.7868\n",
      "Epoch 1651/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4605 - binary_accuracy: 0.8164 - val_loss: 0.5373 - val_binary_accuracy: 0.7873\n",
      "Epoch 1652/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4605 - binary_accuracy: 0.8166 - val_loss: 0.5373 - val_binary_accuracy: 0.7868\n",
      "Epoch 1653/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4605 - binary_accuracy: 0.8171 - val_loss: 0.5373 - val_binary_accuracy: 0.7868\n",
      "Epoch 1654/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4604 - binary_accuracy: 0.8175 - val_loss: 0.5372 - val_binary_accuracy: 0.7868\n",
      "Epoch 1655/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4604 - binary_accuracy: 0.8177 - val_loss: 0.5372 - val_binary_accuracy: 0.7873\n",
      "Epoch 1656/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4604 - binary_accuracy: 0.8177 - val_loss: 0.5373 - val_binary_accuracy: 0.7868\n",
      "Epoch 1657/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4603 - binary_accuracy: 0.8177 - val_loss: 0.5373 - val_binary_accuracy: 0.7868\n",
      "Epoch 1658/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4603 - binary_accuracy: 0.8173 - val_loss: 0.5373 - val_binary_accuracy: 0.7868\n",
      "Epoch 1659/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4603 - binary_accuracy: 0.8177 - val_loss: 0.5372 - val_binary_accuracy: 0.7868\n",
      "Epoch 1660/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4602 - binary_accuracy: 0.8177 - val_loss: 0.5372 - val_binary_accuracy: 0.7868\n",
      "Epoch 1661/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4602 - binary_accuracy: 0.8180 - val_loss: 0.5372 - val_binary_accuracy: 0.7868\n",
      "Epoch 1662/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4602 - binary_accuracy: 0.8175 - val_loss: 0.5372 - val_binary_accuracy: 0.7868\n",
      "Epoch 1663/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4602 - binary_accuracy: 0.8177 - val_loss: 0.5372 - val_binary_accuracy: 0.7873\n",
      "Epoch 1664/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4601 - binary_accuracy: 0.8180 - val_loss: 0.5372 - val_binary_accuracy: 0.7883\n",
      "Epoch 1665/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4601 - binary_accuracy: 0.8180 - val_loss: 0.5372 - val_binary_accuracy: 0.7883\n",
      "Epoch 1666/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4601 - binary_accuracy: 0.8182 - val_loss: 0.5372 - val_binary_accuracy: 0.7878\n",
      "Epoch 1667/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4600 - binary_accuracy: 0.8182 - val_loss: 0.5372 - val_binary_accuracy: 0.7883\n",
      "Epoch 1668/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4600 - binary_accuracy: 0.8184 - val_loss: 0.5372 - val_binary_accuracy: 0.7883\n",
      "Epoch 1669/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4600 - binary_accuracy: 0.8184 - val_loss: 0.5372 - val_binary_accuracy: 0.7883\n",
      "Epoch 1670/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4599 - binary_accuracy: 0.8182 - val_loss: 0.5372 - val_binary_accuracy: 0.7883\n",
      "Epoch 1671/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4599 - binary_accuracy: 0.8185 - val_loss: 0.5372 - val_binary_accuracy: 0.7883\n",
      "Epoch 1672/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4599 - binary_accuracy: 0.8182 - val_loss: 0.5372 - val_binary_accuracy: 0.7883\n",
      "Epoch 1673/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4599 - binary_accuracy: 0.8184 - val_loss: 0.5372 - val_binary_accuracy: 0.7883\n",
      "Epoch 1674/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4598 - binary_accuracy: 0.8182 - val_loss: 0.5372 - val_binary_accuracy: 0.7878\n",
      "Epoch 1675/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4598 - binary_accuracy: 0.8182 - val_loss: 0.5372 - val_binary_accuracy: 0.7873\n",
      "Epoch 1676/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4598 - binary_accuracy: 0.8180 - val_loss: 0.5372 - val_binary_accuracy: 0.7868\n",
      "Epoch 1677/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4597 - binary_accuracy: 0.8182 - val_loss: 0.5372 - val_binary_accuracy: 0.7868\n",
      "Epoch 1678/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4597 - binary_accuracy: 0.8177 - val_loss: 0.5372 - val_binary_accuracy: 0.7868\n",
      "Epoch 1679/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4597 - binary_accuracy: 0.8173 - val_loss: 0.5372 - val_binary_accuracy: 0.7868\n",
      "Epoch 1680/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4596 - binary_accuracy: 0.8173 - val_loss: 0.5372 - val_binary_accuracy: 0.7873\n",
      "Epoch 1681/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4596 - binary_accuracy: 0.8177 - val_loss: 0.5372 - val_binary_accuracy: 0.7878\n",
      "Epoch 1682/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4596 - binary_accuracy: 0.8180 - val_loss: 0.5372 - val_binary_accuracy: 0.7878\n",
      "Epoch 1683/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4596 - binary_accuracy: 0.8180 - val_loss: 0.5372 - val_binary_accuracy: 0.7878\n",
      "Epoch 1684/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4595 - binary_accuracy: 0.8182 - val_loss: 0.5372 - val_binary_accuracy: 0.7878\n",
      "Epoch 1685/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4595 - binary_accuracy: 0.8182 - val_loss: 0.5372 - val_binary_accuracy: 0.7878\n",
      "Epoch 1686/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4595 - binary_accuracy: 0.8182 - val_loss: 0.5372 - val_binary_accuracy: 0.7878\n",
      "Epoch 1687/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4594 - binary_accuracy: 0.8182 - val_loss: 0.5372 - val_binary_accuracy: 0.7878\n",
      "Epoch 1688/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4594 - binary_accuracy: 0.8182 - val_loss: 0.5371 - val_binary_accuracy: 0.7873\n",
      "Epoch 1689/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4594 - binary_accuracy: 0.8182 - val_loss: 0.5371 - val_binary_accuracy: 0.7873\n",
      "Epoch 1690/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4594 - binary_accuracy: 0.8180 - val_loss: 0.5372 - val_binary_accuracy: 0.7878\n",
      "Epoch 1691/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4593 - binary_accuracy: 0.8180 - val_loss: 0.5372 - val_binary_accuracy: 0.7878\n",
      "Epoch 1692/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4593 - binary_accuracy: 0.8180 - val_loss: 0.5371 - val_binary_accuracy: 0.7878\n",
      "Epoch 1693/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4593 - binary_accuracy: 0.8178 - val_loss: 0.5371 - val_binary_accuracy: 0.7878\n",
      "Epoch 1694/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4592 - binary_accuracy: 0.8182 - val_loss: 0.5371 - val_binary_accuracy: 0.7878\n",
      "Epoch 1695/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4592 - binary_accuracy: 0.8180 - val_loss: 0.5371 - val_binary_accuracy: 0.7878\n",
      "Epoch 1696/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4592 - binary_accuracy: 0.8182 - val_loss: 0.5371 - val_binary_accuracy: 0.7878\n",
      "Epoch 1697/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4591 - binary_accuracy: 0.8184 - val_loss: 0.5371 - val_binary_accuracy: 0.7878\n",
      "Epoch 1698/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4591 - binary_accuracy: 0.8187 - val_loss: 0.5371 - val_binary_accuracy: 0.7878\n",
      "Epoch 1699/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4591 - binary_accuracy: 0.8185 - val_loss: 0.5371 - val_binary_accuracy: 0.7878\n",
      "Epoch 1700/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4591 - binary_accuracy: 0.8187 - val_loss: 0.5371 - val_binary_accuracy: 0.7878\n",
      "Epoch 1701/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4590 - binary_accuracy: 0.8189 - val_loss: 0.5371 - val_binary_accuracy: 0.7878\n",
      "Epoch 1702/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4590 - binary_accuracy: 0.8192 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1703/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4590 - binary_accuracy: 0.8191 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1704/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4589 - binary_accuracy: 0.8189 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1705/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4589 - binary_accuracy: 0.8189 - val_loss: 0.5371 - val_binary_accuracy: 0.7878\n",
      "Epoch 1706/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4589 - binary_accuracy: 0.8191 - val_loss: 0.5371 - val_binary_accuracy: 0.7878\n",
      "Epoch 1707/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4589 - binary_accuracy: 0.8187 - val_loss: 0.5371 - val_binary_accuracy: 0.7878\n",
      "Epoch 1708/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4588 - binary_accuracy: 0.8182 - val_loss: 0.5371 - val_binary_accuracy: 0.7878\n",
      "Epoch 1709/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4588 - binary_accuracy: 0.8184 - val_loss: 0.5371 - val_binary_accuracy: 0.7873\n",
      "Epoch 1710/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4588 - binary_accuracy: 0.8177 - val_loss: 0.5371 - val_binary_accuracy: 0.7873\n",
      "Epoch 1711/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4587 - binary_accuracy: 0.8175 - val_loss: 0.5371 - val_binary_accuracy: 0.7873\n",
      "Epoch 1712/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4587 - binary_accuracy: 0.8175 - val_loss: 0.5371 - val_binary_accuracy: 0.7873\n",
      "Epoch 1713/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4587 - binary_accuracy: 0.8180 - val_loss: 0.5371 - val_binary_accuracy: 0.7873\n",
      "Epoch 1714/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4587 - binary_accuracy: 0.8184 - val_loss: 0.5371 - val_binary_accuracy: 0.7878\n",
      "Epoch 1715/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4586 - binary_accuracy: 0.8184 - val_loss: 0.5371 - val_binary_accuracy: 0.7873\n",
      "Epoch 1716/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4586 - binary_accuracy: 0.8180 - val_loss: 0.5371 - val_binary_accuracy: 0.7873\n",
      "Epoch 1717/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4586 - binary_accuracy: 0.8184 - val_loss: 0.5371 - val_binary_accuracy: 0.7878\n",
      "Epoch 1718/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4585 - binary_accuracy: 0.8185 - val_loss: 0.5372 - val_binary_accuracy: 0.7873\n",
      "Epoch 1719/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4585 - binary_accuracy: 0.8182 - val_loss: 0.5372 - val_binary_accuracy: 0.7873\n",
      "Epoch 1720/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4585 - binary_accuracy: 0.8180 - val_loss: 0.5371 - val_binary_accuracy: 0.7873\n",
      "Epoch 1721/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4585 - binary_accuracy: 0.8182 - val_loss: 0.5372 - val_binary_accuracy: 0.7873\n",
      "Epoch 1722/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4584 - binary_accuracy: 0.8182 - val_loss: 0.5372 - val_binary_accuracy: 0.7873\n",
      "Epoch 1723/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4584 - binary_accuracy: 0.8182 - val_loss: 0.5371 - val_binary_accuracy: 0.7873\n",
      "Epoch 1724/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4584 - binary_accuracy: 0.8182 - val_loss: 0.5372 - val_binary_accuracy: 0.7878\n",
      "Epoch 1725/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4583 - binary_accuracy: 0.8184 - val_loss: 0.5372 - val_binary_accuracy: 0.7883\n",
      "Epoch 1726/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4583 - binary_accuracy: 0.8184 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1727/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4583 - binary_accuracy: 0.8185 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1728/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4583 - binary_accuracy: 0.8187 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1729/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4582 - binary_accuracy: 0.8189 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1730/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4582 - binary_accuracy: 0.8184 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1731/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4582 - binary_accuracy: 0.8185 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1732/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4582 - binary_accuracy: 0.8182 - val_loss: 0.5371 - val_binary_accuracy: 0.7878\n",
      "Epoch 1733/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4581 - binary_accuracy: 0.8184 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1734/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4581 - binary_accuracy: 0.8189 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1735/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4581 - binary_accuracy: 0.8192 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1736/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4580 - binary_accuracy: 0.8192 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1737/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4580 - binary_accuracy: 0.8199 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1738/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4580 - binary_accuracy: 0.8198 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1739/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4580 - binary_accuracy: 0.8198 - val_loss: 0.5370 - val_binary_accuracy: 0.7883\n",
      "Epoch 1740/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4579 - binary_accuracy: 0.8198 - val_loss: 0.5370 - val_binary_accuracy: 0.7883\n",
      "Epoch 1741/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4579 - binary_accuracy: 0.8199 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1742/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4579 - binary_accuracy: 0.8198 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1743/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4578 - binary_accuracy: 0.8198 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1744/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4578 - binary_accuracy: 0.8198 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1745/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4578 - binary_accuracy: 0.8198 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1746/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4578 - binary_accuracy: 0.8198 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1747/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4577 - binary_accuracy: 0.8199 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1748/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4577 - binary_accuracy: 0.8199 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1749/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4577 - binary_accuracy: 0.8198 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1750/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4577 - binary_accuracy: 0.8196 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1751/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4576 - binary_accuracy: 0.8194 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1752/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4576 - binary_accuracy: 0.8196 - val_loss: 0.5372 - val_binary_accuracy: 0.7883\n",
      "Epoch 1753/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4576 - binary_accuracy: 0.8198 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1754/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4575 - binary_accuracy: 0.8198 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1755/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4575 - binary_accuracy: 0.8198 - val_loss: 0.5372 - val_binary_accuracy: 0.7883\n",
      "Epoch 1756/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4575 - binary_accuracy: 0.8201 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1757/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4575 - binary_accuracy: 0.8203 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1758/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4574 - binary_accuracy: 0.8203 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1759/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4574 - binary_accuracy: 0.8205 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1760/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4574 - binary_accuracy: 0.8203 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1761/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4574 - binary_accuracy: 0.8203 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1762/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4573 - binary_accuracy: 0.8203 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1763/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4573 - binary_accuracy: 0.8201 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1764/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4573 - binary_accuracy: 0.8198 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1765/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4572 - binary_accuracy: 0.8199 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1766/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4572 - binary_accuracy: 0.8199 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1767/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4572 - binary_accuracy: 0.8198 - val_loss: 0.5372 - val_binary_accuracy: 0.7883\n",
      "Epoch 1768/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4572 - binary_accuracy: 0.8198 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1769/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4571 - binary_accuracy: 0.8198 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1770/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4571 - binary_accuracy: 0.8198 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1771/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4571 - binary_accuracy: 0.8198 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1772/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4571 - binary_accuracy: 0.8198 - val_loss: 0.5371 - val_binary_accuracy: 0.7889\n",
      "Epoch 1773/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4570 - binary_accuracy: 0.8194 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1774/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4570 - binary_accuracy: 0.8192 - val_loss: 0.5371 - val_binary_accuracy: 0.7883\n",
      "Epoch 1775/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4570 - binary_accuracy: 0.8192 - val_loss: 0.5372 - val_binary_accuracy: 0.7883\n",
      "Epoch 1776/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4569 - binary_accuracy: 0.8196 - val_loss: 0.5371 - val_binary_accuracy: 0.7889\n",
      "Epoch 1777/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4569 - binary_accuracy: 0.8198 - val_loss: 0.5371 - val_binary_accuracy: 0.7889\n",
      "Epoch 1778/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4569 - binary_accuracy: 0.8199 - val_loss: 0.5371 - val_binary_accuracy: 0.7889\n",
      "Epoch 1779/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4569 - binary_accuracy: 0.8198 - val_loss: 0.5371 - val_binary_accuracy: 0.7889\n",
      "Epoch 1780/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4568 - binary_accuracy: 0.8198 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1781/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4568 - binary_accuracy: 0.8198 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1782/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4568 - binary_accuracy: 0.8198 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1783/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4568 - binary_accuracy: 0.8201 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1784/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4567 - binary_accuracy: 0.8203 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1785/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4567 - binary_accuracy: 0.8203 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1786/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4567 - binary_accuracy: 0.8206 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1787/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4567 - binary_accuracy: 0.8206 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1788/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4566 - binary_accuracy: 0.8206 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1789/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4566 - binary_accuracy: 0.8205 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1790/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4566 - binary_accuracy: 0.8203 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1791/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4565 - binary_accuracy: 0.8199 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1792/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4565 - binary_accuracy: 0.8198 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1793/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4565 - binary_accuracy: 0.8199 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1794/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4565 - binary_accuracy: 0.8199 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1795/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4564 - binary_accuracy: 0.8203 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1796/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4564 - binary_accuracy: 0.8205 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1797/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4564 - binary_accuracy: 0.8203 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1798/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4564 - binary_accuracy: 0.8199 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1799/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4563 - binary_accuracy: 0.8201 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1800/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4563 - binary_accuracy: 0.8203 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1801/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4563 - binary_accuracy: 0.8205 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1802/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4563 - binary_accuracy: 0.8212 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1803/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4562 - binary_accuracy: 0.8220 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1804/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4562 - binary_accuracy: 0.8219 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1805/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4562 - binary_accuracy: 0.8219 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1806/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4562 - binary_accuracy: 0.8215 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1807/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4561 - binary_accuracy: 0.8217 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1808/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4561 - binary_accuracy: 0.8219 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1809/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4561 - binary_accuracy: 0.8219 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1810/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4561 - binary_accuracy: 0.8215 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1811/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4560 - binary_accuracy: 0.8213 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1812/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4560 - binary_accuracy: 0.8212 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1813/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4560 - binary_accuracy: 0.8212 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1814/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4559 - binary_accuracy: 0.8212 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1815/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4559 - binary_accuracy: 0.8212 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1816/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4559 - binary_accuracy: 0.8210 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1817/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4559 - binary_accuracy: 0.8210 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1818/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4558 - binary_accuracy: 0.8210 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1819/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4558 - binary_accuracy: 0.8210 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1820/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4558 - binary_accuracy: 0.8210 - val_loss: 0.5373 - val_binary_accuracy: 0.7894\n",
      "Epoch 1821/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4558 - binary_accuracy: 0.8210 - val_loss: 0.5373 - val_binary_accuracy: 0.7894\n",
      "Epoch 1822/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4557 - binary_accuracy: 0.8210 - val_loss: 0.5373 - val_binary_accuracy: 0.7894\n",
      "Epoch 1823/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4557 - binary_accuracy: 0.8212 - val_loss: 0.5373 - val_binary_accuracy: 0.7894\n",
      "Epoch 1824/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4557 - binary_accuracy: 0.8212 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1825/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4557 - binary_accuracy: 0.8205 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1826/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4556 - binary_accuracy: 0.8203 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1827/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4556 - binary_accuracy: 0.8203 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1828/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4556 - binary_accuracy: 0.8205 - val_loss: 0.5373 - val_binary_accuracy: 0.7894\n",
      "Epoch 1829/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4556 - binary_accuracy: 0.8206 - val_loss: 0.5373 - val_binary_accuracy: 0.7894\n",
      "Epoch 1830/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4555 - binary_accuracy: 0.8208 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1831/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4555 - binary_accuracy: 0.8206 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1832/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4555 - binary_accuracy: 0.8205 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1833/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4555 - binary_accuracy: 0.8208 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1834/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4554 - binary_accuracy: 0.8208 - val_loss: 0.5373 - val_binary_accuracy: 0.7894\n",
      "Epoch 1835/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4554 - binary_accuracy: 0.8206 - val_loss: 0.5373 - val_binary_accuracy: 0.7889\n",
      "Epoch 1836/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4554 - binary_accuracy: 0.8206 - val_loss: 0.5373 - val_binary_accuracy: 0.7889\n",
      "Epoch 1837/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4554 - binary_accuracy: 0.8210 - val_loss: 0.5373 - val_binary_accuracy: 0.7889\n",
      "Epoch 1838/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4553 - binary_accuracy: 0.8208 - val_loss: 0.5373 - val_binary_accuracy: 0.7889\n",
      "Epoch 1839/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4553 - binary_accuracy: 0.8210 - val_loss: 0.5373 - val_binary_accuracy: 0.7889\n",
      "Epoch 1840/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4553 - binary_accuracy: 0.8212 - val_loss: 0.5373 - val_binary_accuracy: 0.7889\n",
      "Epoch 1841/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4553 - binary_accuracy: 0.8212 - val_loss: 0.5373 - val_binary_accuracy: 0.7889\n",
      "Epoch 1842/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4552 - binary_accuracy: 0.8215 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1843/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4552 - binary_accuracy: 0.8217 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1844/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4552 - binary_accuracy: 0.8220 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1845/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4552 - binary_accuracy: 0.8220 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1846/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4551 - binary_accuracy: 0.8219 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1847/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4551 - binary_accuracy: 0.8217 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1848/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4551 - binary_accuracy: 0.8215 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1849/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4551 - binary_accuracy: 0.8215 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1850/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4550 - binary_accuracy: 0.8213 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1851/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4550 - binary_accuracy: 0.8215 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1852/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4550 - binary_accuracy: 0.8217 - val_loss: 0.5371 - val_binary_accuracy: 0.7889\n",
      "Epoch 1853/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4550 - binary_accuracy: 0.8217 - val_loss: 0.5371 - val_binary_accuracy: 0.7889\n",
      "Epoch 1854/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4549 - binary_accuracy: 0.8217 - val_loss: 0.5371 - val_binary_accuracy: 0.7889\n",
      "Epoch 1855/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4549 - binary_accuracy: 0.8217 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1856/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4549 - binary_accuracy: 0.8217 - val_loss: 0.5372 - val_binary_accuracy: 0.7894\n",
      "Epoch 1857/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4549 - binary_accuracy: 0.8217 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1858/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4548 - binary_accuracy: 0.8215 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1859/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4548 - binary_accuracy: 0.8213 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1860/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4548 - binary_accuracy: 0.8213 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1861/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4548 - binary_accuracy: 0.8215 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1862/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4548 - binary_accuracy: 0.8213 - val_loss: 0.5373 - val_binary_accuracy: 0.7889\n",
      "Epoch 1863/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4547 - binary_accuracy: 0.8213 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1864/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4547 - binary_accuracy: 0.8213 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1865/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4547 - binary_accuracy: 0.8217 - val_loss: 0.5372 - val_binary_accuracy: 0.7889\n",
      "Epoch 1866/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4546 - binary_accuracy: 0.8217 - val_loss: 0.5373 - val_binary_accuracy: 0.7889\n",
      "Epoch 1867/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4546 - binary_accuracy: 0.8213 - val_loss: 0.5373 - val_binary_accuracy: 0.7889\n",
      "Epoch 1868/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4546 - binary_accuracy: 0.8213 - val_loss: 0.5373 - val_binary_accuracy: 0.7894\n",
      "Epoch 1869/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4546 - binary_accuracy: 0.8213 - val_loss: 0.5373 - val_binary_accuracy: 0.7894\n",
      "Epoch 1870/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4546 - binary_accuracy: 0.8215 - val_loss: 0.5373 - val_binary_accuracy: 0.7894\n",
      "Epoch 1871/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4545 - binary_accuracy: 0.8215 - val_loss: 0.5373 - val_binary_accuracy: 0.7894\n",
      "Epoch 1872/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4545 - binary_accuracy: 0.8217 - val_loss: 0.5373 - val_binary_accuracy: 0.7894\n",
      "Epoch 1873/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4545 - binary_accuracy: 0.8215 - val_loss: 0.5373 - val_binary_accuracy: 0.7899\n",
      "Epoch 1874/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4545 - binary_accuracy: 0.8217 - val_loss: 0.5373 - val_binary_accuracy: 0.7904\n",
      "Epoch 1875/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4544 - binary_accuracy: 0.8219 - val_loss: 0.5373 - val_binary_accuracy: 0.7904\n",
      "Epoch 1876/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4544 - binary_accuracy: 0.8220 - val_loss: 0.5374 - val_binary_accuracy: 0.7899\n",
      "Epoch 1877/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4544 - binary_accuracy: 0.8220 - val_loss: 0.5374 - val_binary_accuracy: 0.7910\n",
      "Epoch 1878/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4544 - binary_accuracy: 0.8220 - val_loss: 0.5374 - val_binary_accuracy: 0.7904\n",
      "Epoch 1879/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4543 - binary_accuracy: 0.8224 - val_loss: 0.5374 - val_binary_accuracy: 0.7910\n",
      "Epoch 1880/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4543 - binary_accuracy: 0.8220 - val_loss: 0.5374 - val_binary_accuracy: 0.7910\n",
      "Epoch 1881/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4543 - binary_accuracy: 0.8220 - val_loss: 0.5374 - val_binary_accuracy: 0.7904\n",
      "Epoch 1882/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4543 - binary_accuracy: 0.8220 - val_loss: 0.5374 - val_binary_accuracy: 0.7904\n",
      "Epoch 1883/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4543 - binary_accuracy: 0.8224 - val_loss: 0.5374 - val_binary_accuracy: 0.7899\n",
      "Epoch 1884/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4542 - binary_accuracy: 0.8224 - val_loss: 0.5374 - val_binary_accuracy: 0.7899\n",
      "Epoch 1885/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4542 - binary_accuracy: 0.8220 - val_loss: 0.5374 - val_binary_accuracy: 0.7899\n",
      "Epoch 1886/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4542 - binary_accuracy: 0.8220 - val_loss: 0.5374 - val_binary_accuracy: 0.7910\n",
      "Epoch 1887/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4542 - binary_accuracy: 0.8220 - val_loss: 0.5374 - val_binary_accuracy: 0.7910\n",
      "Epoch 1888/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4541 - binary_accuracy: 0.8222 - val_loss: 0.5374 - val_binary_accuracy: 0.7904\n",
      "Epoch 1889/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4541 - binary_accuracy: 0.8226 - val_loss: 0.5374 - val_binary_accuracy: 0.7899\n",
      "Epoch 1890/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4541 - binary_accuracy: 0.8226 - val_loss: 0.5374 - val_binary_accuracy: 0.7899\n",
      "Epoch 1891/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4541 - binary_accuracy: 0.8226 - val_loss: 0.5374 - val_binary_accuracy: 0.7904\n",
      "Epoch 1892/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4540 - binary_accuracy: 0.8227 - val_loss: 0.5374 - val_binary_accuracy: 0.7899\n",
      "Epoch 1893/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4540 - binary_accuracy: 0.8231 - val_loss: 0.5375 - val_binary_accuracy: 0.7899\n",
      "Epoch 1894/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4540 - binary_accuracy: 0.8233 - val_loss: 0.5375 - val_binary_accuracy: 0.7899\n",
      "Epoch 1895/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4540 - binary_accuracy: 0.8229 - val_loss: 0.5375 - val_binary_accuracy: 0.7899\n",
      "Epoch 1896/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4539 - binary_accuracy: 0.8224 - val_loss: 0.5375 - val_binary_accuracy: 0.7910\n",
      "Epoch 1897/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4539 - binary_accuracy: 0.8220 - val_loss: 0.5375 - val_binary_accuracy: 0.7904\n",
      "Epoch 1898/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4539 - binary_accuracy: 0.8220 - val_loss: 0.5375 - val_binary_accuracy: 0.7904\n",
      "Epoch 1899/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4539 - binary_accuracy: 0.8222 - val_loss: 0.5374 - val_binary_accuracy: 0.7904\n",
      "Epoch 1900/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4538 - binary_accuracy: 0.8222 - val_loss: 0.5374 - val_binary_accuracy: 0.7904\n",
      "Epoch 1901/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4538 - binary_accuracy: 0.8222 - val_loss: 0.5374 - val_binary_accuracy: 0.7904\n",
      "Epoch 1902/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4538 - binary_accuracy: 0.8222 - val_loss: 0.5374 - val_binary_accuracy: 0.7904\n",
      "Epoch 1903/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4538 - binary_accuracy: 0.8226 - val_loss: 0.5374 - val_binary_accuracy: 0.7904\n",
      "Epoch 1904/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4538 - binary_accuracy: 0.8227 - val_loss: 0.5374 - val_binary_accuracy: 0.7904\n",
      "Epoch 1905/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4537 - binary_accuracy: 0.8227 - val_loss: 0.5374 - val_binary_accuracy: 0.7904\n",
      "Epoch 1906/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4537 - binary_accuracy: 0.8227 - val_loss: 0.5374 - val_binary_accuracy: 0.7904\n",
      "Epoch 1907/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4537 - binary_accuracy: 0.8227 - val_loss: 0.5374 - val_binary_accuracy: 0.7904\n",
      "Epoch 1908/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4537 - binary_accuracy: 0.8229 - val_loss: 0.5374 - val_binary_accuracy: 0.7904\n",
      "Epoch 1909/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4536 - binary_accuracy: 0.8229 - val_loss: 0.5374 - val_binary_accuracy: 0.7910\n",
      "Epoch 1910/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4536 - binary_accuracy: 0.8227 - val_loss: 0.5374 - val_binary_accuracy: 0.7910\n",
      "Epoch 1911/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4536 - binary_accuracy: 0.8227 - val_loss: 0.5375 - val_binary_accuracy: 0.7910\n",
      "Epoch 1912/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4536 - binary_accuracy: 0.8227 - val_loss: 0.5374 - val_binary_accuracy: 0.7910\n",
      "Epoch 1913/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4535 - binary_accuracy: 0.8229 - val_loss: 0.5374 - val_binary_accuracy: 0.7910\n",
      "Epoch 1914/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4535 - binary_accuracy: 0.8227 - val_loss: 0.5375 - val_binary_accuracy: 0.7910\n",
      "Epoch 1915/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4535 - binary_accuracy: 0.8229 - val_loss: 0.5375 - val_binary_accuracy: 0.7910\n",
      "Epoch 1916/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4535 - binary_accuracy: 0.8227 - val_loss: 0.5375 - val_binary_accuracy: 0.7910\n",
      "Epoch 1917/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4534 - binary_accuracy: 0.8227 - val_loss: 0.5374 - val_binary_accuracy: 0.7904\n",
      "Epoch 1918/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4534 - binary_accuracy: 0.8227 - val_loss: 0.5374 - val_binary_accuracy: 0.7904\n",
      "Epoch 1919/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4534 - binary_accuracy: 0.8229 - val_loss: 0.5374 - val_binary_accuracy: 0.7904\n",
      "Epoch 1920/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4534 - binary_accuracy: 0.8227 - val_loss: 0.5374 - val_binary_accuracy: 0.7904\n",
      "Epoch 1921/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4534 - binary_accuracy: 0.8229 - val_loss: 0.5374 - val_binary_accuracy: 0.7899\n",
      "Epoch 1922/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4533 - binary_accuracy: 0.8229 - val_loss: 0.5374 - val_binary_accuracy: 0.7899\n",
      "Epoch 1923/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4533 - binary_accuracy: 0.8229 - val_loss: 0.5374 - val_binary_accuracy: 0.7904\n",
      "Epoch 1924/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4533 - binary_accuracy: 0.8231 - val_loss: 0.5374 - val_binary_accuracy: 0.7904\n",
      "Epoch 1925/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4533 - binary_accuracy: 0.8231 - val_loss: 0.5374 - val_binary_accuracy: 0.7904\n",
      "Epoch 1926/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4532 - binary_accuracy: 0.8231 - val_loss: 0.5374 - val_binary_accuracy: 0.7910\n",
      "Epoch 1927/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4532 - binary_accuracy: 0.8231 - val_loss: 0.5374 - val_binary_accuracy: 0.7910\n",
      "Epoch 1928/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4532 - binary_accuracy: 0.8234 - val_loss: 0.5374 - val_binary_accuracy: 0.7910\n",
      "Epoch 1929/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4532 - binary_accuracy: 0.8238 - val_loss: 0.5374 - val_binary_accuracy: 0.7910\n",
      "Epoch 1930/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4531 - binary_accuracy: 0.8243 - val_loss: 0.5374 - val_binary_accuracy: 0.7910\n",
      "Epoch 1931/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4531 - binary_accuracy: 0.8241 - val_loss: 0.5374 - val_binary_accuracy: 0.7910\n",
      "Epoch 1932/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4531 - binary_accuracy: 0.8245 - val_loss: 0.5374 - val_binary_accuracy: 0.7910\n",
      "Epoch 1933/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4531 - binary_accuracy: 0.8245 - val_loss: 0.5374 - val_binary_accuracy: 0.7910\n",
      "Epoch 1934/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4531 - binary_accuracy: 0.8245 - val_loss: 0.5374 - val_binary_accuracy: 0.7910\n",
      "Epoch 1935/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4530 - binary_accuracy: 0.8241 - val_loss: 0.5373 - val_binary_accuracy: 0.7910\n",
      "Epoch 1936/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4530 - binary_accuracy: 0.8238 - val_loss: 0.5373 - val_binary_accuracy: 0.7904\n",
      "Epoch 1937/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4530 - binary_accuracy: 0.8240 - val_loss: 0.5374 - val_binary_accuracy: 0.7904\n",
      "Epoch 1938/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4530 - binary_accuracy: 0.8240 - val_loss: 0.5373 - val_binary_accuracy: 0.7904\n",
      "Epoch 1939/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4530 - binary_accuracy: 0.8236 - val_loss: 0.5373 - val_binary_accuracy: 0.7904\n",
      "Epoch 1940/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4529 - binary_accuracy: 0.8236 - val_loss: 0.5373 - val_binary_accuracy: 0.7904\n",
      "Epoch 1941/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4529 - binary_accuracy: 0.8238 - val_loss: 0.5373 - val_binary_accuracy: 0.7910\n",
      "Epoch 1942/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4529 - binary_accuracy: 0.8238 - val_loss: 0.5373 - val_binary_accuracy: 0.7910\n",
      "Epoch 1943/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4529 - binary_accuracy: 0.8236 - val_loss: 0.5373 - val_binary_accuracy: 0.7910\n",
      "Epoch 1944/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4528 - binary_accuracy: 0.8238 - val_loss: 0.5373 - val_binary_accuracy: 0.7910\n",
      "Epoch 1945/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4528 - binary_accuracy: 0.8241 - val_loss: 0.5373 - val_binary_accuracy: 0.7910\n",
      "Epoch 1946/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4528 - binary_accuracy: 0.8243 - val_loss: 0.5373 - val_binary_accuracy: 0.7910\n",
      "Epoch 1947/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4528 - binary_accuracy: 0.8248 - val_loss: 0.5373 - val_binary_accuracy: 0.7910\n",
      "Epoch 1948/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4527 - binary_accuracy: 0.8247 - val_loss: 0.5373 - val_binary_accuracy: 0.7910\n",
      "Epoch 1949/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4527 - binary_accuracy: 0.8243 - val_loss: 0.5373 - val_binary_accuracy: 0.7910\n",
      "Epoch 1950/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4527 - binary_accuracy: 0.8240 - val_loss: 0.5373 - val_binary_accuracy: 0.7910\n",
      "Epoch 1951/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4527 - binary_accuracy: 0.8240 - val_loss: 0.5373 - val_binary_accuracy: 0.7910\n",
      "Epoch 1952/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4527 - binary_accuracy: 0.8240 - val_loss: 0.5373 - val_binary_accuracy: 0.7910\n",
      "Epoch 1953/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4526 - binary_accuracy: 0.8240 - val_loss: 0.5373 - val_binary_accuracy: 0.7910\n",
      "Epoch 1954/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4526 - binary_accuracy: 0.8241 - val_loss: 0.5374 - val_binary_accuracy: 0.7910\n",
      "Epoch 1955/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4526 - binary_accuracy: 0.8241 - val_loss: 0.5373 - val_binary_accuracy: 0.7910\n",
      "Epoch 1956/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4526 - binary_accuracy: 0.8245 - val_loss: 0.5374 - val_binary_accuracy: 0.7910\n",
      "Epoch 1957/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4525 - binary_accuracy: 0.8247 - val_loss: 0.5374 - val_binary_accuracy: 0.7910\n",
      "Epoch 1958/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4525 - binary_accuracy: 0.8245 - val_loss: 0.5374 - val_binary_accuracy: 0.7910\n",
      "Epoch 1959/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4525 - binary_accuracy: 0.8243 - val_loss: 0.5374 - val_binary_accuracy: 0.7910\n",
      "Epoch 1960/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4525 - binary_accuracy: 0.8248 - val_loss: 0.5374 - val_binary_accuracy: 0.7910\n",
      "Epoch 1961/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4525 - binary_accuracy: 0.8248 - val_loss: 0.5374 - val_binary_accuracy: 0.7910\n",
      "Epoch 1962/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4524 - binary_accuracy: 0.8248 - val_loss: 0.5374 - val_binary_accuracy: 0.7910\n",
      "Epoch 1963/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4524 - binary_accuracy: 0.8247 - val_loss: 0.5375 - val_binary_accuracy: 0.7910\n",
      "Epoch 1964/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4524 - binary_accuracy: 0.8247 - val_loss: 0.5375 - val_binary_accuracy: 0.7910\n",
      "Epoch 1965/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4524 - binary_accuracy: 0.8248 - val_loss: 0.5375 - val_binary_accuracy: 0.7910\n",
      "Epoch 1966/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4524 - binary_accuracy: 0.8250 - val_loss: 0.5375 - val_binary_accuracy: 0.7910\n",
      "Epoch 1967/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4523 - binary_accuracy: 0.8247 - val_loss: 0.5375 - val_binary_accuracy: 0.7910\n",
      "Epoch 1968/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4523 - binary_accuracy: 0.8247 - val_loss: 0.5375 - val_binary_accuracy: 0.7910\n",
      "Epoch 1969/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4523 - binary_accuracy: 0.8247 - val_loss: 0.5375 - val_binary_accuracy: 0.7904\n",
      "Epoch 1970/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4523 - binary_accuracy: 0.8245 - val_loss: 0.5376 - val_binary_accuracy: 0.7904\n",
      "Epoch 1971/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4522 - binary_accuracy: 0.8247 - val_loss: 0.5375 - val_binary_accuracy: 0.7910\n",
      "Epoch 1972/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4522 - binary_accuracy: 0.8247 - val_loss: 0.5375 - val_binary_accuracy: 0.7910\n",
      "Epoch 1973/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4522 - binary_accuracy: 0.8247 - val_loss: 0.5375 - val_binary_accuracy: 0.7910\n",
      "Epoch 1974/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4522 - binary_accuracy: 0.8245 - val_loss: 0.5375 - val_binary_accuracy: 0.7910\n",
      "Epoch 1975/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4522 - binary_accuracy: 0.8245 - val_loss: 0.5375 - val_binary_accuracy: 0.7904\n",
      "Epoch 1976/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4521 - binary_accuracy: 0.8248 - val_loss: 0.5375 - val_binary_accuracy: 0.7910\n",
      "Epoch 1977/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4521 - binary_accuracy: 0.8247 - val_loss: 0.5375 - val_binary_accuracy: 0.7915\n",
      "Epoch 1978/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4521 - binary_accuracy: 0.8247 - val_loss: 0.5375 - val_binary_accuracy: 0.7915\n",
      "Epoch 1979/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4521 - binary_accuracy: 0.8248 - val_loss: 0.5374 - val_binary_accuracy: 0.7915\n",
      "Epoch 1980/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4521 - binary_accuracy: 0.8247 - val_loss: 0.5374 - val_binary_accuracy: 0.7915\n",
      "Epoch 1981/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4520 - binary_accuracy: 0.8250 - val_loss: 0.5375 - val_binary_accuracy: 0.7910\n",
      "Epoch 1982/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4520 - binary_accuracy: 0.8252 - val_loss: 0.5375 - val_binary_accuracy: 0.7904\n",
      "Epoch 1983/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4520 - binary_accuracy: 0.8250 - val_loss: 0.5375 - val_binary_accuracy: 0.7904\n",
      "Epoch 1984/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4520 - binary_accuracy: 0.8250 - val_loss: 0.5376 - val_binary_accuracy: 0.7904\n",
      "Epoch 1985/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4520 - binary_accuracy: 0.8254 - val_loss: 0.5375 - val_binary_accuracy: 0.7904\n",
      "Epoch 1986/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4519 - binary_accuracy: 0.8254 - val_loss: 0.5375 - val_binary_accuracy: 0.7904\n",
      "Epoch 1987/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4519 - binary_accuracy: 0.8252 - val_loss: 0.5375 - val_binary_accuracy: 0.7904\n",
      "Epoch 1988/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4519 - binary_accuracy: 0.8245 - val_loss: 0.5375 - val_binary_accuracy: 0.7904\n",
      "Epoch 1989/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4519 - binary_accuracy: 0.8248 - val_loss: 0.5375 - val_binary_accuracy: 0.7904\n",
      "Epoch 1990/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4518 - binary_accuracy: 0.8250 - val_loss: 0.5375 - val_binary_accuracy: 0.7904\n",
      "Epoch 1991/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4518 - binary_accuracy: 0.8247 - val_loss: 0.5375 - val_binary_accuracy: 0.7904\n",
      "Epoch 1992/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4518 - binary_accuracy: 0.8245 - val_loss: 0.5375 - val_binary_accuracy: 0.7910\n",
      "Epoch 1993/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4518 - binary_accuracy: 0.8245 - val_loss: 0.5375 - val_binary_accuracy: 0.7904\n",
      "Epoch 1994/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4518 - binary_accuracy: 0.8247 - val_loss: 0.5376 - val_binary_accuracy: 0.7904\n",
      "Epoch 1995/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4517 - binary_accuracy: 0.8248 - val_loss: 0.5376 - val_binary_accuracy: 0.7904\n",
      "Epoch 1996/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4517 - binary_accuracy: 0.8248 - val_loss: 0.5376 - val_binary_accuracy: 0.7904\n",
      "Epoch 1997/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4517 - binary_accuracy: 0.8248 - val_loss: 0.5376 - val_binary_accuracy: 0.7904\n",
      "Epoch 1998/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4517 - binary_accuracy: 0.8248 - val_loss: 0.5376 - val_binary_accuracy: 0.7904\n",
      "Epoch 1999/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4517 - binary_accuracy: 0.8248 - val_loss: 0.5375 - val_binary_accuracy: 0.7904\n",
      "Epoch 2000/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4516 - binary_accuracy: 0.8250 - val_loss: 0.5375 - val_binary_accuracy: 0.7904\n",
      "Epoch 2001/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4516 - binary_accuracy: 0.8255 - val_loss: 0.5375 - val_binary_accuracy: 0.7904\n",
      "Epoch 2002/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4516 - binary_accuracy: 0.8250 - val_loss: 0.5375 - val_binary_accuracy: 0.7904\n",
      "Epoch 2003/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4516 - binary_accuracy: 0.8252 - val_loss: 0.5375 - val_binary_accuracy: 0.7904\n",
      "Epoch 2004/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4516 - binary_accuracy: 0.8248 - val_loss: 0.5376 - val_binary_accuracy: 0.7904\n",
      "Epoch 2005/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4515 - binary_accuracy: 0.8252 - val_loss: 0.5375 - val_binary_accuracy: 0.7904\n",
      "Epoch 2006/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4515 - binary_accuracy: 0.8254 - val_loss: 0.5376 - val_binary_accuracy: 0.7904\n",
      "Epoch 2007/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4515 - binary_accuracy: 0.8252 - val_loss: 0.5376 - val_binary_accuracy: 0.7904\n",
      "Epoch 2008/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4515 - binary_accuracy: 0.8255 - val_loss: 0.5375 - val_binary_accuracy: 0.7904\n",
      "Epoch 2009/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4514 - binary_accuracy: 0.8250 - val_loss: 0.5375 - val_binary_accuracy: 0.7904\n",
      "Epoch 2010/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4514 - binary_accuracy: 0.8250 - val_loss: 0.5375 - val_binary_accuracy: 0.7904\n",
      "Epoch 2011/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4514 - binary_accuracy: 0.8250 - val_loss: 0.5375 - val_binary_accuracy: 0.7899\n",
      "Epoch 2012/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4514 - binary_accuracy: 0.8248 - val_loss: 0.5376 - val_binary_accuracy: 0.7899\n",
      "Epoch 2013/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4514 - binary_accuracy: 0.8250 - val_loss: 0.5376 - val_binary_accuracy: 0.7904\n",
      "Epoch 2014/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4513 - binary_accuracy: 0.8250 - val_loss: 0.5376 - val_binary_accuracy: 0.7899\n",
      "Epoch 2015/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4513 - binary_accuracy: 0.8250 - val_loss: 0.5376 - val_binary_accuracy: 0.7899\n",
      "Epoch 2016/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4513 - binary_accuracy: 0.8250 - val_loss: 0.5376 - val_binary_accuracy: 0.7904\n",
      "Epoch 2017/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4513 - binary_accuracy: 0.8252 - val_loss: 0.5376 - val_binary_accuracy: 0.7904\n",
      "Epoch 2018/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4513 - binary_accuracy: 0.8250 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2019/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4512 - binary_accuracy: 0.8250 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2020/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4512 - binary_accuracy: 0.8255 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2021/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4512 - binary_accuracy: 0.8259 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2022/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4512 - binary_accuracy: 0.8255 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2023/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4512 - binary_accuracy: 0.8254 - val_loss: 0.5376 - val_binary_accuracy: 0.7899\n",
      "Epoch 2024/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4511 - binary_accuracy: 0.8255 - val_loss: 0.5377 - val_binary_accuracy: 0.7899\n",
      "Epoch 2025/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4511 - binary_accuracy: 0.8255 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2026/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4511 - binary_accuracy: 0.8257 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2027/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4511 - binary_accuracy: 0.8259 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2028/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4511 - binary_accuracy: 0.8261 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2029/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4510 - binary_accuracy: 0.8261 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2030/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4510 - binary_accuracy: 0.8259 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2031/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4510 - binary_accuracy: 0.8261 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2032/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4510 - binary_accuracy: 0.8264 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2033/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4510 - binary_accuracy: 0.8262 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2034/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4509 - binary_accuracy: 0.8259 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2035/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4509 - binary_accuracy: 0.8259 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2036/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4509 - binary_accuracy: 0.8259 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2037/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4509 - binary_accuracy: 0.8261 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2038/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4509 - binary_accuracy: 0.8259 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2039/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4508 - binary_accuracy: 0.8259 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2040/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4508 - binary_accuracy: 0.8261 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2041/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4508 - binary_accuracy: 0.8262 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2042/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4508 - binary_accuracy: 0.8266 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2043/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4508 - binary_accuracy: 0.8262 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2044/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4507 - binary_accuracy: 0.8262 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2045/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4507 - binary_accuracy: 0.8262 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2046/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4507 - binary_accuracy: 0.8262 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2047/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4507 - binary_accuracy: 0.8262 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2048/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4507 - binary_accuracy: 0.8257 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2049/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4506 - binary_accuracy: 0.8264 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2050/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4506 - binary_accuracy: 0.8264 - val_loss: 0.5378 - val_binary_accuracy: 0.7904\n",
      "Epoch 2051/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4506 - binary_accuracy: 0.8266 - val_loss: 0.5378 - val_binary_accuracy: 0.7904\n",
      "Epoch 2052/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4506 - binary_accuracy: 0.8266 - val_loss: 0.5378 - val_binary_accuracy: 0.7904\n",
      "Epoch 2053/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4506 - binary_accuracy: 0.8268 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2054/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4505 - binary_accuracy: 0.8268 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2055/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4505 - binary_accuracy: 0.8268 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2056/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4505 - binary_accuracy: 0.8264 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2057/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4505 - binary_accuracy: 0.8261 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2058/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4505 - binary_accuracy: 0.8261 - val_loss: 0.5377 - val_binary_accuracy: 0.7904\n",
      "Epoch 2059/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4504 - binary_accuracy: 0.8261 - val_loss: 0.5377 - val_binary_accuracy: 0.7899\n",
      "Epoch 2060/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4504 - binary_accuracy: 0.8264 - val_loss: 0.5377 - val_binary_accuracy: 0.7899\n",
      "Epoch 2061/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4504 - binary_accuracy: 0.8262 - val_loss: 0.5377 - val_binary_accuracy: 0.7894\n",
      "Epoch 2062/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4504 - binary_accuracy: 0.8262 - val_loss: 0.5377 - val_binary_accuracy: 0.7894\n",
      "Epoch 2063/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4504 - binary_accuracy: 0.8264 - val_loss: 0.5377 - val_binary_accuracy: 0.7894\n",
      "Epoch 2064/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4503 - binary_accuracy: 0.8268 - val_loss: 0.5377 - val_binary_accuracy: 0.7894\n",
      "Epoch 2065/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4503 - binary_accuracy: 0.8268 - val_loss: 0.5378 - val_binary_accuracy: 0.7899\n",
      "Epoch 2066/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4503 - binary_accuracy: 0.8264 - val_loss: 0.5378 - val_binary_accuracy: 0.7899\n",
      "Epoch 2067/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4503 - binary_accuracy: 0.8268 - val_loss: 0.5378 - val_binary_accuracy: 0.7904\n",
      "Epoch 2068/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4503 - binary_accuracy: 0.8266 - val_loss: 0.5378 - val_binary_accuracy: 0.7904\n",
      "Epoch 2069/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4503 - binary_accuracy: 0.8266 - val_loss: 0.5378 - val_binary_accuracy: 0.7904\n",
      "Epoch 2070/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4502 - binary_accuracy: 0.8268 - val_loss: 0.5378 - val_binary_accuracy: 0.7910\n",
      "Epoch 2071/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4502 - binary_accuracy: 0.8269 - val_loss: 0.5378 - val_binary_accuracy: 0.7904\n",
      "Epoch 2072/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4502 - binary_accuracy: 0.8266 - val_loss: 0.5378 - val_binary_accuracy: 0.7910\n",
      "Epoch 2073/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4502 - binary_accuracy: 0.8269 - val_loss: 0.5378 - val_binary_accuracy: 0.7910\n",
      "Epoch 2074/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4502 - binary_accuracy: 0.8271 - val_loss: 0.5378 - val_binary_accuracy: 0.7910\n",
      "Epoch 2075/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4501 - binary_accuracy: 0.8269 - val_loss: 0.5378 - val_binary_accuracy: 0.7910\n",
      "Epoch 2076/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4501 - binary_accuracy: 0.8269 - val_loss: 0.5378 - val_binary_accuracy: 0.7910\n",
      "Epoch 2077/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4501 - binary_accuracy: 0.8273 - val_loss: 0.5379 - val_binary_accuracy: 0.7915\n",
      "Epoch 2078/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4501 - binary_accuracy: 0.8268 - val_loss: 0.5378 - val_binary_accuracy: 0.7910\n",
      "Epoch 2079/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4501 - binary_accuracy: 0.8268 - val_loss: 0.5378 - val_binary_accuracy: 0.7910\n",
      "Epoch 2080/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4500 - binary_accuracy: 0.8268 - val_loss: 0.5378 - val_binary_accuracy: 0.7910\n",
      "Epoch 2081/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4500 - binary_accuracy: 0.8269 - val_loss: 0.5379 - val_binary_accuracy: 0.7910\n",
      "Epoch 2082/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4500 - binary_accuracy: 0.8269 - val_loss: 0.5379 - val_binary_accuracy: 0.7910\n",
      "Epoch 2083/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4500 - binary_accuracy: 0.8268 - val_loss: 0.5379 - val_binary_accuracy: 0.7910\n",
      "Epoch 2084/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4500 - binary_accuracy: 0.8269 - val_loss: 0.5379 - val_binary_accuracy: 0.7910\n",
      "Epoch 2085/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4500 - binary_accuracy: 0.8271 - val_loss: 0.5379 - val_binary_accuracy: 0.7910\n",
      "Epoch 2086/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4499 - binary_accuracy: 0.8271 - val_loss: 0.5379 - val_binary_accuracy: 0.7910\n",
      "Epoch 2087/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4499 - binary_accuracy: 0.8269 - val_loss: 0.5379 - val_binary_accuracy: 0.7915\n",
      "Epoch 2088/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4499 - binary_accuracy: 0.8275 - val_loss: 0.5379 - val_binary_accuracy: 0.7915\n",
      "Epoch 2089/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4499 - binary_accuracy: 0.8273 - val_loss: 0.5379 - val_binary_accuracy: 0.7915\n",
      "Epoch 2090/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4499 - binary_accuracy: 0.8273 - val_loss: 0.5379 - val_binary_accuracy: 0.7915\n",
      "Epoch 2091/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4498 - binary_accuracy: 0.8275 - val_loss: 0.5379 - val_binary_accuracy: 0.7915\n",
      "Epoch 2092/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4498 - binary_accuracy: 0.8275 - val_loss: 0.5379 - val_binary_accuracy: 0.7920\n",
      "Epoch 2093/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4498 - binary_accuracy: 0.8276 - val_loss: 0.5379 - val_binary_accuracy: 0.7925\n",
      "Epoch 2094/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4498 - binary_accuracy: 0.8275 - val_loss: 0.5379 - val_binary_accuracy: 0.7925\n",
      "Epoch 2095/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4498 - binary_accuracy: 0.8275 - val_loss: 0.5378 - val_binary_accuracy: 0.7915\n",
      "Epoch 2096/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4497 - binary_accuracy: 0.8276 - val_loss: 0.5378 - val_binary_accuracy: 0.7915\n",
      "Epoch 2097/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4497 - binary_accuracy: 0.8275 - val_loss: 0.5378 - val_binary_accuracy: 0.7915\n",
      "Epoch 2098/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4497 - binary_accuracy: 0.8276 - val_loss: 0.5379 - val_binary_accuracy: 0.7915\n",
      "Epoch 2099/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4497 - binary_accuracy: 0.8276 - val_loss: 0.5379 - val_binary_accuracy: 0.7915\n",
      "Epoch 2100/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4497 - binary_accuracy: 0.8276 - val_loss: 0.5379 - val_binary_accuracy: 0.7920\n",
      "Epoch 2101/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4497 - binary_accuracy: 0.8276 - val_loss: 0.5379 - val_binary_accuracy: 0.7920\n",
      "Epoch 2102/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4496 - binary_accuracy: 0.8276 - val_loss: 0.5379 - val_binary_accuracy: 0.7915\n",
      "Epoch 2103/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4496 - binary_accuracy: 0.8275 - val_loss: 0.5379 - val_binary_accuracy: 0.7915\n",
      "Epoch 2104/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4496 - binary_accuracy: 0.8271 - val_loss: 0.5379 - val_binary_accuracy: 0.7915\n",
      "Epoch 2105/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4496 - binary_accuracy: 0.8271 - val_loss: 0.5379 - val_binary_accuracy: 0.7910\n",
      "Epoch 2106/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4496 - binary_accuracy: 0.8268 - val_loss: 0.5379 - val_binary_accuracy: 0.7915\n",
      "Epoch 2107/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4496 - binary_accuracy: 0.8268 - val_loss: 0.5379 - val_binary_accuracy: 0.7910\n",
      "Epoch 2108/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4495 - binary_accuracy: 0.8269 - val_loss: 0.5380 - val_binary_accuracy: 0.7915\n",
      "Epoch 2109/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4495 - binary_accuracy: 0.8269 - val_loss: 0.5380 - val_binary_accuracy: 0.7920\n",
      "Epoch 2110/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4495 - binary_accuracy: 0.8268 - val_loss: 0.5380 - val_binary_accuracy: 0.7915\n",
      "Epoch 2111/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4495 - binary_accuracy: 0.8269 - val_loss: 0.5380 - val_binary_accuracy: 0.7920\n",
      "Epoch 2112/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4495 - binary_accuracy: 0.8269 - val_loss: 0.5380 - val_binary_accuracy: 0.7915\n",
      "Epoch 2113/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4494 - binary_accuracy: 0.8271 - val_loss: 0.5379 - val_binary_accuracy: 0.7915\n",
      "Epoch 2114/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4494 - binary_accuracy: 0.8275 - val_loss: 0.5380 - val_binary_accuracy: 0.7915\n",
      "Epoch 2115/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4494 - binary_accuracy: 0.8275 - val_loss: 0.5380 - val_binary_accuracy: 0.7915\n",
      "Epoch 2116/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4494 - binary_accuracy: 0.8273 - val_loss: 0.5380 - val_binary_accuracy: 0.7910\n",
      "Epoch 2117/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4494 - binary_accuracy: 0.8273 - val_loss: 0.5380 - val_binary_accuracy: 0.7910\n",
      "Epoch 2118/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4494 - binary_accuracy: 0.8271 - val_loss: 0.5380 - val_binary_accuracy: 0.7920\n",
      "Epoch 2119/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4493 - binary_accuracy: 0.8271 - val_loss: 0.5380 - val_binary_accuracy: 0.7920\n",
      "Epoch 2120/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4493 - binary_accuracy: 0.8271 - val_loss: 0.5380 - val_binary_accuracy: 0.7920\n",
      "Epoch 2121/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4493 - binary_accuracy: 0.8273 - val_loss: 0.5380 - val_binary_accuracy: 0.7925\n",
      "Epoch 2122/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4493 - binary_accuracy: 0.8273 - val_loss: 0.5380 - val_binary_accuracy: 0.7925\n",
      "Epoch 2123/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4493 - binary_accuracy: 0.8276 - val_loss: 0.5380 - val_binary_accuracy: 0.7925\n",
      "Epoch 2124/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4492 - binary_accuracy: 0.8278 - val_loss: 0.5380 - val_binary_accuracy: 0.7925\n",
      "Epoch 2125/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4492 - binary_accuracy: 0.8280 - val_loss: 0.5381 - val_binary_accuracy: 0.7925\n",
      "Epoch 2126/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4492 - binary_accuracy: 0.8276 - val_loss: 0.5381 - val_binary_accuracy: 0.7925\n",
      "Epoch 2127/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4492 - binary_accuracy: 0.8278 - val_loss: 0.5381 - val_binary_accuracy: 0.7925\n",
      "Epoch 2128/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4492 - binary_accuracy: 0.8275 - val_loss: 0.5380 - val_binary_accuracy: 0.7925\n",
      "Epoch 2129/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4492 - binary_accuracy: 0.8273 - val_loss: 0.5381 - val_binary_accuracy: 0.7920\n",
      "Epoch 2130/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4491 - binary_accuracy: 0.8275 - val_loss: 0.5381 - val_binary_accuracy: 0.7925\n",
      "Epoch 2131/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4491 - binary_accuracy: 0.8276 - val_loss: 0.5381 - val_binary_accuracy: 0.7920\n",
      "Epoch 2132/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4491 - binary_accuracy: 0.8278 - val_loss: 0.5381 - val_binary_accuracy: 0.7920\n",
      "Epoch 2133/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4491 - binary_accuracy: 0.8282 - val_loss: 0.5381 - val_binary_accuracy: 0.7925\n",
      "Epoch 2134/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4491 - binary_accuracy: 0.8282 - val_loss: 0.5381 - val_binary_accuracy: 0.7920\n",
      "Epoch 2135/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4491 - binary_accuracy: 0.8282 - val_loss: 0.5381 - val_binary_accuracy: 0.7920\n",
      "Epoch 2136/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4490 - binary_accuracy: 0.8278 - val_loss: 0.5381 - val_binary_accuracy: 0.7920\n",
      "Epoch 2137/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4490 - binary_accuracy: 0.8276 - val_loss: 0.5381 - val_binary_accuracy: 0.7920\n",
      "Epoch 2138/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4490 - binary_accuracy: 0.8273 - val_loss: 0.5381 - val_binary_accuracy: 0.7920\n",
      "Epoch 2139/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4490 - binary_accuracy: 0.8275 - val_loss: 0.5381 - val_binary_accuracy: 0.7915\n",
      "Epoch 2140/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4490 - binary_accuracy: 0.8276 - val_loss: 0.5381 - val_binary_accuracy: 0.7915\n",
      "Epoch 2141/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4489 - binary_accuracy: 0.8275 - val_loss: 0.5381 - val_binary_accuracy: 0.7920\n",
      "Epoch 2142/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4489 - binary_accuracy: 0.8276 - val_loss: 0.5381 - val_binary_accuracy: 0.7920\n",
      "Epoch 2143/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4489 - binary_accuracy: 0.8276 - val_loss: 0.5381 - val_binary_accuracy: 0.7915\n",
      "Epoch 2144/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4489 - binary_accuracy: 0.8276 - val_loss: 0.5381 - val_binary_accuracy: 0.7915\n",
      "Epoch 2145/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4489 - binary_accuracy: 0.8278 - val_loss: 0.5381 - val_binary_accuracy: 0.7915\n",
      "Epoch 2146/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4489 - binary_accuracy: 0.8278 - val_loss: 0.5381 - val_binary_accuracy: 0.7925\n",
      "Epoch 2147/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4488 - binary_accuracy: 0.8280 - val_loss: 0.5381 - val_binary_accuracy: 0.7925\n",
      "Epoch 2148/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4488 - binary_accuracy: 0.8282 - val_loss: 0.5381 - val_binary_accuracy: 0.7925\n",
      "Epoch 2149/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4488 - binary_accuracy: 0.8278 - val_loss: 0.5381 - val_binary_accuracy: 0.7915\n",
      "Epoch 2150/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4488 - binary_accuracy: 0.8282 - val_loss: 0.5381 - val_binary_accuracy: 0.7920\n",
      "Epoch 2151/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4488 - binary_accuracy: 0.8278 - val_loss: 0.5380 - val_binary_accuracy: 0.7920\n",
      "Epoch 2152/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4488 - binary_accuracy: 0.8278 - val_loss: 0.5381 - val_binary_accuracy: 0.7915\n",
      "Epoch 2153/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4487 - binary_accuracy: 0.8280 - val_loss: 0.5381 - val_binary_accuracy: 0.7920\n",
      "Epoch 2154/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4487 - binary_accuracy: 0.8280 - val_loss: 0.5381 - val_binary_accuracy: 0.7920\n",
      "Epoch 2155/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4487 - binary_accuracy: 0.8280 - val_loss: 0.5381 - val_binary_accuracy: 0.7925\n",
      "Epoch 2156/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4487 - binary_accuracy: 0.8280 - val_loss: 0.5382 - val_binary_accuracy: 0.7925\n",
      "Epoch 2157/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4487 - binary_accuracy: 0.8282 - val_loss: 0.5382 - val_binary_accuracy: 0.7915\n",
      "Epoch 2158/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4487 - binary_accuracy: 0.8280 - val_loss: 0.5382 - val_binary_accuracy: 0.7920\n",
      "Epoch 2159/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4486 - binary_accuracy: 0.8282 - val_loss: 0.5382 - val_binary_accuracy: 0.7920\n",
      "Epoch 2160/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4486 - binary_accuracy: 0.8280 - val_loss: 0.5382 - val_binary_accuracy: 0.7920\n",
      "Epoch 2161/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4486 - binary_accuracy: 0.8280 - val_loss: 0.5382 - val_binary_accuracy: 0.7920\n",
      "Epoch 2162/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4486 - binary_accuracy: 0.8280 - val_loss: 0.5382 - val_binary_accuracy: 0.7920\n",
      "Epoch 2163/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4486 - binary_accuracy: 0.8282 - val_loss: 0.5382 - val_binary_accuracy: 0.7920\n",
      "Epoch 2164/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4486 - binary_accuracy: 0.8282 - val_loss: 0.5382 - val_binary_accuracy: 0.7920\n",
      "Epoch 2165/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4485 - binary_accuracy: 0.8282 - val_loss: 0.5382 - val_binary_accuracy: 0.7920\n",
      "Epoch 2166/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4485 - binary_accuracy: 0.8282 - val_loss: 0.5382 - val_binary_accuracy: 0.7920\n",
      "Epoch 2167/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4485 - binary_accuracy: 0.8280 - val_loss: 0.5382 - val_binary_accuracy: 0.7920\n",
      "Epoch 2168/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4485 - binary_accuracy: 0.8280 - val_loss: 0.5382 - val_binary_accuracy: 0.7920\n",
      "Epoch 2169/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4485 - binary_accuracy: 0.8280 - val_loss: 0.5382 - val_binary_accuracy: 0.7920\n",
      "Epoch 2170/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4484 - binary_accuracy: 0.8280 - val_loss: 0.5383 - val_binary_accuracy: 0.7920\n",
      "Epoch 2171/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4484 - binary_accuracy: 0.8282 - val_loss: 0.5383 - val_binary_accuracy: 0.7920\n",
      "Epoch 2172/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4484 - binary_accuracy: 0.8282 - val_loss: 0.5383 - val_binary_accuracy: 0.7920\n",
      "Epoch 2173/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4484 - binary_accuracy: 0.8287 - val_loss: 0.5383 - val_binary_accuracy: 0.7920\n",
      "Epoch 2174/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4484 - binary_accuracy: 0.8287 - val_loss: 0.5383 - val_binary_accuracy: 0.7920\n",
      "Epoch 2175/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4484 - binary_accuracy: 0.8285 - val_loss: 0.5383 - val_binary_accuracy: 0.7920\n",
      "Epoch 2176/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4483 - binary_accuracy: 0.8287 - val_loss: 0.5383 - val_binary_accuracy: 0.7920\n",
      "Epoch 2177/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4483 - binary_accuracy: 0.8285 - val_loss: 0.5383 - val_binary_accuracy: 0.7920\n",
      "Epoch 2178/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4483 - binary_accuracy: 0.8285 - val_loss: 0.5383 - val_binary_accuracy: 0.7920\n",
      "Epoch 2179/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4483 - binary_accuracy: 0.8285 - val_loss: 0.5383 - val_binary_accuracy: 0.7920\n",
      "Epoch 2180/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4483 - binary_accuracy: 0.8285 - val_loss: 0.5383 - val_binary_accuracy: 0.7920\n",
      "Epoch 2181/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4483 - binary_accuracy: 0.8285 - val_loss: 0.5384 - val_binary_accuracy: 0.7920\n",
      "Epoch 2182/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4483 - binary_accuracy: 0.8285 - val_loss: 0.5384 - val_binary_accuracy: 0.7925\n",
      "Epoch 2183/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4482 - binary_accuracy: 0.8287 - val_loss: 0.5383 - val_binary_accuracy: 0.7925\n",
      "Epoch 2184/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4482 - binary_accuracy: 0.8287 - val_loss: 0.5384 - val_binary_accuracy: 0.7925\n",
      "Epoch 2185/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4482 - binary_accuracy: 0.8287 - val_loss: 0.5384 - val_binary_accuracy: 0.7925\n",
      "Epoch 2186/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4482 - binary_accuracy: 0.8283 - val_loss: 0.5384 - val_binary_accuracy: 0.7920\n",
      "Epoch 2187/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4482 - binary_accuracy: 0.8285 - val_loss: 0.5384 - val_binary_accuracy: 0.7925\n",
      "Epoch 2188/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4482 - binary_accuracy: 0.8285 - val_loss: 0.5385 - val_binary_accuracy: 0.7920\n",
      "Epoch 2189/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4481 - binary_accuracy: 0.8283 - val_loss: 0.5385 - val_binary_accuracy: 0.7920\n",
      "Epoch 2190/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4481 - binary_accuracy: 0.8283 - val_loss: 0.5385 - val_binary_accuracy: 0.7920\n",
      "Epoch 2191/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4481 - binary_accuracy: 0.8283 - val_loss: 0.5385 - val_binary_accuracy: 0.7920\n",
      "Epoch 2192/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4481 - binary_accuracy: 0.8282 - val_loss: 0.5385 - val_binary_accuracy: 0.7920\n",
      "Epoch 2193/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4481 - binary_accuracy: 0.8283 - val_loss: 0.5386 - val_binary_accuracy: 0.7915\n",
      "Epoch 2194/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4481 - binary_accuracy: 0.8287 - val_loss: 0.5386 - val_binary_accuracy: 0.7915\n",
      "Epoch 2195/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4480 - binary_accuracy: 0.8289 - val_loss: 0.5386 - val_binary_accuracy: 0.7915\n",
      "Epoch 2196/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4480 - binary_accuracy: 0.8290 - val_loss: 0.5385 - val_binary_accuracy: 0.7915\n",
      "Epoch 2197/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4480 - binary_accuracy: 0.8287 - val_loss: 0.5385 - val_binary_accuracy: 0.7915\n",
      "Epoch 2198/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4480 - binary_accuracy: 0.8289 - val_loss: 0.5385 - val_binary_accuracy: 0.7915\n",
      "Epoch 2199/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4480 - binary_accuracy: 0.8285 - val_loss: 0.5385 - val_binary_accuracy: 0.7915\n",
      "Epoch 2200/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4480 - binary_accuracy: 0.8287 - val_loss: 0.5385 - val_binary_accuracy: 0.7915\n",
      "Epoch 2201/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4479 - binary_accuracy: 0.8287 - val_loss: 0.5385 - val_binary_accuracy: 0.7915\n",
      "Epoch 2202/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4479 - binary_accuracy: 0.8287 - val_loss: 0.5385 - val_binary_accuracy: 0.7915\n",
      "Epoch 2203/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4479 - binary_accuracy: 0.8285 - val_loss: 0.5386 - val_binary_accuracy: 0.7915\n",
      "Epoch 2204/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4479 - binary_accuracy: 0.8287 - val_loss: 0.5386 - val_binary_accuracy: 0.7915\n",
      "Epoch 2205/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4479 - binary_accuracy: 0.8292 - val_loss: 0.5386 - val_binary_accuracy: 0.7915\n",
      "Epoch 2206/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4479 - binary_accuracy: 0.8292 - val_loss: 0.5386 - val_binary_accuracy: 0.7915\n",
      "Epoch 2207/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4478 - binary_accuracy: 0.8292 - val_loss: 0.5386 - val_binary_accuracy: 0.7915\n",
      "Epoch 2208/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4478 - binary_accuracy: 0.8294 - val_loss: 0.5387 - val_binary_accuracy: 0.7920\n",
      "Epoch 2209/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4478 - binary_accuracy: 0.8294 - val_loss: 0.5387 - val_binary_accuracy: 0.7915\n",
      "Epoch 2210/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4478 - binary_accuracy: 0.8296 - val_loss: 0.5387 - val_binary_accuracy: 0.7920\n",
      "Epoch 2211/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4478 - binary_accuracy: 0.8294 - val_loss: 0.5387 - val_binary_accuracy: 0.7920\n",
      "Epoch 2212/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4478 - binary_accuracy: 0.8292 - val_loss: 0.5387 - val_binary_accuracy: 0.7920\n",
      "Epoch 2213/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4477 - binary_accuracy: 0.8289 - val_loss: 0.5386 - val_binary_accuracy: 0.7915\n",
      "Epoch 2214/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4477 - binary_accuracy: 0.8289 - val_loss: 0.5387 - val_binary_accuracy: 0.7920\n",
      "Epoch 2215/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4477 - binary_accuracy: 0.8289 - val_loss: 0.5387 - val_binary_accuracy: 0.7920\n",
      "Epoch 2216/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4477 - binary_accuracy: 0.8287 - val_loss: 0.5387 - val_binary_accuracy: 0.7920\n",
      "Epoch 2217/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4477 - binary_accuracy: 0.8287 - val_loss: 0.5387 - val_binary_accuracy: 0.7915\n",
      "Epoch 2218/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4477 - binary_accuracy: 0.8290 - val_loss: 0.5387 - val_binary_accuracy: 0.7915\n",
      "Epoch 2219/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4477 - binary_accuracy: 0.8292 - val_loss: 0.5387 - val_binary_accuracy: 0.7920\n",
      "Epoch 2220/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4476 - binary_accuracy: 0.8290 - val_loss: 0.5387 - val_binary_accuracy: 0.7920\n",
      "Epoch 2221/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4476 - binary_accuracy: 0.8289 - val_loss: 0.5387 - val_binary_accuracy: 0.7920\n",
      "Epoch 2222/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4476 - binary_accuracy: 0.8290 - val_loss: 0.5387 - val_binary_accuracy: 0.7920\n",
      "Epoch 2223/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4476 - binary_accuracy: 0.8292 - val_loss: 0.5387 - val_binary_accuracy: 0.7920\n",
      "Epoch 2224/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4476 - binary_accuracy: 0.8292 - val_loss: 0.5387 - val_binary_accuracy: 0.7920\n",
      "Epoch 2225/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4476 - binary_accuracy: 0.8292 - val_loss: 0.5387 - val_binary_accuracy: 0.7920\n",
      "Epoch 2226/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4475 - binary_accuracy: 0.8290 - val_loss: 0.5387 - val_binary_accuracy: 0.7920\n",
      "Epoch 2227/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4475 - binary_accuracy: 0.8290 - val_loss: 0.5388 - val_binary_accuracy: 0.7920\n",
      "Epoch 2228/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4475 - binary_accuracy: 0.8290 - val_loss: 0.5388 - val_binary_accuracy: 0.7920\n",
      "Epoch 2229/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4475 - binary_accuracy: 0.8290 - val_loss: 0.5388 - val_binary_accuracy: 0.7920\n",
      "Epoch 2230/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4475 - binary_accuracy: 0.8289 - val_loss: 0.5388 - val_binary_accuracy: 0.7920\n",
      "Epoch 2231/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4475 - binary_accuracy: 0.8289 - val_loss: 0.5388 - val_binary_accuracy: 0.7920\n",
      "Epoch 2232/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4475 - binary_accuracy: 0.8290 - val_loss: 0.5388 - val_binary_accuracy: 0.7920\n",
      "Epoch 2233/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4474 - binary_accuracy: 0.8290 - val_loss: 0.5388 - val_binary_accuracy: 0.7920\n",
      "Epoch 2234/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4474 - binary_accuracy: 0.8290 - val_loss: 0.5388 - val_binary_accuracy: 0.7920\n",
      "Epoch 2235/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4474 - binary_accuracy: 0.8289 - val_loss: 0.5388 - val_binary_accuracy: 0.7915\n",
      "Epoch 2236/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4474 - binary_accuracy: 0.8289 - val_loss: 0.5388 - val_binary_accuracy: 0.7920\n",
      "Epoch 2237/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4474 - binary_accuracy: 0.8290 - val_loss: 0.5388 - val_binary_accuracy: 0.7920\n",
      "Epoch 2238/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4474 - binary_accuracy: 0.8292 - val_loss: 0.5388 - val_binary_accuracy: 0.7915\n",
      "Epoch 2239/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4473 - binary_accuracy: 0.8292 - val_loss: 0.5388 - val_binary_accuracy: 0.7915\n",
      "Epoch 2240/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4473 - binary_accuracy: 0.8290 - val_loss: 0.5388 - val_binary_accuracy: 0.7910\n",
      "Epoch 2241/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4473 - binary_accuracy: 0.8290 - val_loss: 0.5388 - val_binary_accuracy: 0.7910\n",
      "Epoch 2242/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4473 - binary_accuracy: 0.8292 - val_loss: 0.5388 - val_binary_accuracy: 0.7910\n",
      "Epoch 2243/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4473 - binary_accuracy: 0.8292 - val_loss: 0.5389 - val_binary_accuracy: 0.7904\n",
      "Epoch 2244/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4473 - binary_accuracy: 0.8290 - val_loss: 0.5389 - val_binary_accuracy: 0.7904\n",
      "Epoch 2245/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4473 - binary_accuracy: 0.8290 - val_loss: 0.5389 - val_binary_accuracy: 0.7910\n",
      "Epoch 2246/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4472 - binary_accuracy: 0.8292 - val_loss: 0.5389 - val_binary_accuracy: 0.7910\n",
      "Epoch 2247/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4472 - binary_accuracy: 0.8292 - val_loss: 0.5389 - val_binary_accuracy: 0.7915\n",
      "Epoch 2248/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4472 - binary_accuracy: 0.8292 - val_loss: 0.5389 - val_binary_accuracy: 0.7910\n",
      "Epoch 2249/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4472 - binary_accuracy: 0.8294 - val_loss: 0.5389 - val_binary_accuracy: 0.7910\n",
      "Epoch 2250/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4472 - binary_accuracy: 0.8290 - val_loss: 0.5389 - val_binary_accuracy: 0.7910\n",
      "Epoch 2251/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4472 - binary_accuracy: 0.8292 - val_loss: 0.5389 - val_binary_accuracy: 0.7910\n",
      "Epoch 2252/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4471 - binary_accuracy: 0.8294 - val_loss: 0.5389 - val_binary_accuracy: 0.7910\n",
      "Epoch 2253/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4471 - binary_accuracy: 0.8294 - val_loss: 0.5389 - val_binary_accuracy: 0.7910\n",
      "Epoch 2254/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4471 - binary_accuracy: 0.8292 - val_loss: 0.5389 - val_binary_accuracy: 0.7915\n",
      "Epoch 2255/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4471 - binary_accuracy: 0.8292 - val_loss: 0.5389 - val_binary_accuracy: 0.7910\n",
      "Epoch 2256/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4471 - binary_accuracy: 0.8292 - val_loss: 0.5389 - val_binary_accuracy: 0.7920\n",
      "Epoch 2257/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4471 - binary_accuracy: 0.8294 - val_loss: 0.5390 - val_binary_accuracy: 0.7910\n",
      "Epoch 2258/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4470 - binary_accuracy: 0.8296 - val_loss: 0.5390 - val_binary_accuracy: 0.7910\n",
      "Epoch 2259/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4470 - binary_accuracy: 0.8299 - val_loss: 0.5390 - val_binary_accuracy: 0.7915\n",
      "Epoch 2260/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4470 - binary_accuracy: 0.8299 - val_loss: 0.5391 - val_binary_accuracy: 0.7920\n",
      "Epoch 2261/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4470 - binary_accuracy: 0.8301 - val_loss: 0.5391 - val_binary_accuracy: 0.7920\n",
      "Epoch 2262/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4470 - binary_accuracy: 0.8304 - val_loss: 0.5391 - val_binary_accuracy: 0.7920\n",
      "Epoch 2263/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4470 - binary_accuracy: 0.8304 - val_loss: 0.5391 - val_binary_accuracy: 0.7925\n",
      "Epoch 2264/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4470 - binary_accuracy: 0.8303 - val_loss: 0.5391 - val_binary_accuracy: 0.7925\n",
      "Epoch 2265/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4470 - binary_accuracy: 0.8301 - val_loss: 0.5391 - val_binary_accuracy: 0.7925\n",
      "Epoch 2266/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4470 - binary_accuracy: 0.8301 - val_loss: 0.5391 - val_binary_accuracy: 0.7925\n",
      "Epoch 2267/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4469 - binary_accuracy: 0.8303 - val_loss: 0.5390 - val_binary_accuracy: 0.7925\n",
      "Epoch 2268/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4469 - binary_accuracy: 0.8301 - val_loss: 0.5390 - val_binary_accuracy: 0.7925\n",
      "Epoch 2269/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4469 - binary_accuracy: 0.8301 - val_loss: 0.5390 - val_binary_accuracy: 0.7925\n",
      "Epoch 2270/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4469 - binary_accuracy: 0.8299 - val_loss: 0.5390 - val_binary_accuracy: 0.7925\n",
      "Epoch 2271/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4469 - binary_accuracy: 0.8297 - val_loss: 0.5390 - val_binary_accuracy: 0.7925\n",
      "Epoch 2272/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4469 - binary_accuracy: 0.8299 - val_loss: 0.5391 - val_binary_accuracy: 0.7925\n",
      "Epoch 2273/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4468 - binary_accuracy: 0.8301 - val_loss: 0.5390 - val_binary_accuracy: 0.7925\n",
      "Epoch 2274/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4468 - binary_accuracy: 0.8299 - val_loss: 0.5391 - val_binary_accuracy: 0.7931\n",
      "Epoch 2275/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4468 - binary_accuracy: 0.8299 - val_loss: 0.5391 - val_binary_accuracy: 0.7931\n",
      "Epoch 2276/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4468 - binary_accuracy: 0.8299 - val_loss: 0.5391 - val_binary_accuracy: 0.7931\n",
      "Epoch 2277/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4468 - binary_accuracy: 0.8296 - val_loss: 0.5391 - val_binary_accuracy: 0.7931\n",
      "Epoch 2278/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4468 - binary_accuracy: 0.8296 - val_loss: 0.5392 - val_binary_accuracy: 0.7936\n",
      "Epoch 2279/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4468 - binary_accuracy: 0.8296 - val_loss: 0.5392 - val_binary_accuracy: 0.7931\n",
      "Epoch 2280/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4467 - binary_accuracy: 0.8294 - val_loss: 0.5392 - val_binary_accuracy: 0.7931\n",
      "Epoch 2281/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4467 - binary_accuracy: 0.8292 - val_loss: 0.5392 - val_binary_accuracy: 0.7931\n",
      "Epoch 2282/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4467 - binary_accuracy: 0.8289 - val_loss: 0.5392 - val_binary_accuracy: 0.7920\n",
      "Epoch 2283/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4467 - binary_accuracy: 0.8290 - val_loss: 0.5392 - val_binary_accuracy: 0.7920\n",
      "Epoch 2284/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4467 - binary_accuracy: 0.8292 - val_loss: 0.5392 - val_binary_accuracy: 0.7920\n",
      "Epoch 2285/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4467 - binary_accuracy: 0.8292 - val_loss: 0.5392 - val_binary_accuracy: 0.7920\n",
      "Epoch 2286/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4467 - binary_accuracy: 0.8294 - val_loss: 0.5392 - val_binary_accuracy: 0.7920\n",
      "Epoch 2287/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4467 - binary_accuracy: 0.8290 - val_loss: 0.5392 - val_binary_accuracy: 0.7920\n",
      "Epoch 2288/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4466 - binary_accuracy: 0.8294 - val_loss: 0.5392 - val_binary_accuracy: 0.7920\n",
      "Epoch 2289/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4466 - binary_accuracy: 0.8292 - val_loss: 0.5392 - val_binary_accuracy: 0.7920\n",
      "Epoch 2290/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4466 - binary_accuracy: 0.8292 - val_loss: 0.5393 - val_binary_accuracy: 0.7925\n",
      "Epoch 2291/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4466 - binary_accuracy: 0.8290 - val_loss: 0.5393 - val_binary_accuracy: 0.7925\n",
      "Epoch 2292/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4466 - binary_accuracy: 0.8290 - val_loss: 0.5393 - val_binary_accuracy: 0.7925\n",
      "Epoch 2293/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4466 - binary_accuracy: 0.8292 - val_loss: 0.5393 - val_binary_accuracy: 0.7931\n",
      "Epoch 2294/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4465 - binary_accuracy: 0.8290 - val_loss: 0.5393 - val_binary_accuracy: 0.7925\n",
      "Epoch 2295/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4465 - binary_accuracy: 0.8290 - val_loss: 0.5393 - val_binary_accuracy: 0.7925\n",
      "Epoch 2296/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4465 - binary_accuracy: 0.8290 - val_loss: 0.5393 - val_binary_accuracy: 0.7920\n",
      "Epoch 2297/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4465 - binary_accuracy: 0.8292 - val_loss: 0.5394 - val_binary_accuracy: 0.7920\n",
      "Epoch 2298/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4465 - binary_accuracy: 0.8290 - val_loss: 0.5394 - val_binary_accuracy: 0.7925\n",
      "Epoch 2299/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4465 - binary_accuracy: 0.8290 - val_loss: 0.5394 - val_binary_accuracy: 0.7925\n",
      "Epoch 2300/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4465 - binary_accuracy: 0.8292 - val_loss: 0.5394 - val_binary_accuracy: 0.7925\n",
      "Epoch 2301/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4464 - binary_accuracy: 0.8292 - val_loss: 0.5394 - val_binary_accuracy: 0.7925\n",
      "Epoch 2302/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4464 - binary_accuracy: 0.8292 - val_loss: 0.5393 - val_binary_accuracy: 0.7931\n",
      "Epoch 2303/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4464 - binary_accuracy: 0.8292 - val_loss: 0.5393 - val_binary_accuracy: 0.7931\n",
      "Epoch 2304/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4464 - binary_accuracy: 0.8294 - val_loss: 0.5393 - val_binary_accuracy: 0.7936\n",
      "Epoch 2305/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4464 - binary_accuracy: 0.8296 - val_loss: 0.5394 - val_binary_accuracy: 0.7931\n",
      "Epoch 2306/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4464 - binary_accuracy: 0.8297 - val_loss: 0.5394 - val_binary_accuracy: 0.7925\n",
      "Epoch 2307/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4464 - binary_accuracy: 0.8294 - val_loss: 0.5393 - val_binary_accuracy: 0.7925\n",
      "Epoch 2308/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4464 - binary_accuracy: 0.8290 - val_loss: 0.5393 - val_binary_accuracy: 0.7925\n",
      "Epoch 2309/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4463 - binary_accuracy: 0.8290 - val_loss: 0.5394 - val_binary_accuracy: 0.7925\n",
      "Epoch 2310/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4463 - binary_accuracy: 0.8290 - val_loss: 0.5394 - val_binary_accuracy: 0.7925\n",
      "Epoch 2311/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4463 - binary_accuracy: 0.8292 - val_loss: 0.5393 - val_binary_accuracy: 0.7925\n",
      "Epoch 2312/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4463 - binary_accuracy: 0.8290 - val_loss: 0.5393 - val_binary_accuracy: 0.7925\n",
      "Epoch 2313/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4463 - binary_accuracy: 0.8290 - val_loss: 0.5393 - val_binary_accuracy: 0.7925\n",
      "Epoch 2314/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4463 - binary_accuracy: 0.8290 - val_loss: 0.5393 - val_binary_accuracy: 0.7925\n",
      "Epoch 2315/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4463 - binary_accuracy: 0.8294 - val_loss: 0.5393 - val_binary_accuracy: 0.7925\n",
      "Epoch 2316/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4462 - binary_accuracy: 0.8294 - val_loss: 0.5394 - val_binary_accuracy: 0.7920\n",
      "Epoch 2317/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4462 - binary_accuracy: 0.8292 - val_loss: 0.5394 - val_binary_accuracy: 0.7920\n",
      "Epoch 2318/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4462 - binary_accuracy: 0.8292 - val_loss: 0.5395 - val_binary_accuracy: 0.7920\n",
      "Epoch 2319/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4462 - binary_accuracy: 0.8294 - val_loss: 0.5395 - val_binary_accuracy: 0.7920\n",
      "Epoch 2320/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4462 - binary_accuracy: 0.8296 - val_loss: 0.5395 - val_binary_accuracy: 0.7925\n",
      "Epoch 2321/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4462 - binary_accuracy: 0.8299 - val_loss: 0.5395 - val_binary_accuracy: 0.7925\n",
      "Epoch 2322/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4462 - binary_accuracy: 0.8301 - val_loss: 0.5395 - val_binary_accuracy: 0.7925\n",
      "Epoch 2323/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4461 - binary_accuracy: 0.8301 - val_loss: 0.5395 - val_binary_accuracy: 0.7925\n",
      "Epoch 2324/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4461 - binary_accuracy: 0.8306 - val_loss: 0.5396 - val_binary_accuracy: 0.7931\n",
      "Epoch 2325/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4461 - binary_accuracy: 0.8306 - val_loss: 0.5396 - val_binary_accuracy: 0.7925\n",
      "Epoch 2326/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4461 - binary_accuracy: 0.8304 - val_loss: 0.5396 - val_binary_accuracy: 0.7925\n",
      "Epoch 2327/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4461 - binary_accuracy: 0.8310 - val_loss: 0.5396 - val_binary_accuracy: 0.7931\n",
      "Epoch 2328/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4461 - binary_accuracy: 0.8310 - val_loss: 0.5397 - val_binary_accuracy: 0.7925\n",
      "Epoch 2329/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4461 - binary_accuracy: 0.8308 - val_loss: 0.5397 - val_binary_accuracy: 0.7925\n",
      "Epoch 2330/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4461 - binary_accuracy: 0.8301 - val_loss: 0.5397 - val_binary_accuracy: 0.7925\n",
      "Epoch 2331/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4460 - binary_accuracy: 0.8308 - val_loss: 0.5397 - val_binary_accuracy: 0.7925\n",
      "Epoch 2332/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4460 - binary_accuracy: 0.8308 - val_loss: 0.5397 - val_binary_accuracy: 0.7925\n",
      "Epoch 2333/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4460 - binary_accuracy: 0.8303 - val_loss: 0.5397 - val_binary_accuracy: 0.7925\n",
      "Epoch 2334/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4460 - binary_accuracy: 0.8304 - val_loss: 0.5397 - val_binary_accuracy: 0.7920\n",
      "Epoch 2335/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4460 - binary_accuracy: 0.8303 - val_loss: 0.5397 - val_binary_accuracy: 0.7925\n",
      "Epoch 2336/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4460 - binary_accuracy: 0.8299 - val_loss: 0.5397 - val_binary_accuracy: 0.7920\n",
      "Epoch 2337/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4460 - binary_accuracy: 0.8299 - val_loss: 0.5397 - val_binary_accuracy: 0.7920\n",
      "Epoch 2338/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4459 - binary_accuracy: 0.8304 - val_loss: 0.5397 - val_binary_accuracy: 0.7920\n",
      "Epoch 2339/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4459 - binary_accuracy: 0.8299 - val_loss: 0.5397 - val_binary_accuracy: 0.7920\n",
      "Epoch 2340/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4459 - binary_accuracy: 0.8299 - val_loss: 0.5397 - val_binary_accuracy: 0.7920\n",
      "Epoch 2341/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4459 - binary_accuracy: 0.8299 - val_loss: 0.5397 - val_binary_accuracy: 0.7920\n",
      "Epoch 2342/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4459 - binary_accuracy: 0.8297 - val_loss: 0.5397 - val_binary_accuracy: 0.7920\n",
      "Epoch 2343/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4459 - binary_accuracy: 0.8297 - val_loss: 0.5398 - val_binary_accuracy: 0.7920\n",
      "Epoch 2344/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4459 - binary_accuracy: 0.8304 - val_loss: 0.5398 - val_binary_accuracy: 0.7915\n",
      "Epoch 2345/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4459 - binary_accuracy: 0.8311 - val_loss: 0.5398 - val_binary_accuracy: 0.7915\n",
      "Epoch 2346/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4458 - binary_accuracy: 0.8308 - val_loss: 0.5399 - val_binary_accuracy: 0.7920\n",
      "Epoch 2347/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4458 - binary_accuracy: 0.8308 - val_loss: 0.5399 - val_binary_accuracy: 0.7920\n",
      "Epoch 2348/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4458 - binary_accuracy: 0.8308 - val_loss: 0.5399 - val_binary_accuracy: 0.7915\n",
      "Epoch 2349/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4458 - binary_accuracy: 0.8308 - val_loss: 0.5399 - val_binary_accuracy: 0.7910\n",
      "Epoch 2350/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4458 - binary_accuracy: 0.8304 - val_loss: 0.5400 - val_binary_accuracy: 0.7904\n",
      "Epoch 2351/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4458 - binary_accuracy: 0.8306 - val_loss: 0.5401 - val_binary_accuracy: 0.7910\n",
      "Epoch 2352/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4458 - binary_accuracy: 0.8310 - val_loss: 0.5401 - val_binary_accuracy: 0.7904\n",
      "Epoch 2353/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4458 - binary_accuracy: 0.8311 - val_loss: 0.5401 - val_binary_accuracy: 0.7904\n",
      "Epoch 2354/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4457 - binary_accuracy: 0.8310 - val_loss: 0.5401 - val_binary_accuracy: 0.7899\n",
      "Epoch 2355/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4457 - binary_accuracy: 0.8313 - val_loss: 0.5402 - val_binary_accuracy: 0.7894\n",
      "Epoch 2356/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4457 - binary_accuracy: 0.8315 - val_loss: 0.5402 - val_binary_accuracy: 0.7894\n",
      "Epoch 2357/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4457 - binary_accuracy: 0.8315 - val_loss: 0.5402 - val_binary_accuracy: 0.7894\n",
      "Epoch 2358/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4457 - binary_accuracy: 0.8313 - val_loss: 0.5402 - val_binary_accuracy: 0.7899\n",
      "Epoch 2359/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4457 - binary_accuracy: 0.8313 - val_loss: 0.5402 - val_binary_accuracy: 0.7899\n",
      "Epoch 2360/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4457 - binary_accuracy: 0.8313 - val_loss: 0.5402 - val_binary_accuracy: 0.7899\n",
      "Epoch 2361/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4457 - binary_accuracy: 0.8320 - val_loss: 0.5403 - val_binary_accuracy: 0.7899\n",
      "Epoch 2362/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4456 - binary_accuracy: 0.8320 - val_loss: 0.5403 - val_binary_accuracy: 0.7899\n",
      "Epoch 2363/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4456 - binary_accuracy: 0.8324 - val_loss: 0.5403 - val_binary_accuracy: 0.7899\n",
      "Epoch 2364/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4456 - binary_accuracy: 0.8318 - val_loss: 0.5403 - val_binary_accuracy: 0.7899\n",
      "Epoch 2365/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4456 - binary_accuracy: 0.8320 - val_loss: 0.5403 - val_binary_accuracy: 0.7899\n",
      "Epoch 2366/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4456 - binary_accuracy: 0.8320 - val_loss: 0.5404 - val_binary_accuracy: 0.7899\n",
      "Epoch 2367/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4456 - binary_accuracy: 0.8322 - val_loss: 0.5404 - val_binary_accuracy: 0.7899\n",
      "Epoch 2368/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4456 - binary_accuracy: 0.8324 - val_loss: 0.5404 - val_binary_accuracy: 0.7899\n",
      "Epoch 2369/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4456 - binary_accuracy: 0.8325 - val_loss: 0.5404 - val_binary_accuracy: 0.7899\n",
      "Epoch 2370/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4455 - binary_accuracy: 0.8322 - val_loss: 0.5404 - val_binary_accuracy: 0.7899\n",
      "Epoch 2371/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4455 - binary_accuracy: 0.8324 - val_loss: 0.5404 - val_binary_accuracy: 0.7904\n",
      "Epoch 2372/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4455 - binary_accuracy: 0.8320 - val_loss: 0.5404 - val_binary_accuracy: 0.7904\n",
      "Epoch 2373/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4455 - binary_accuracy: 0.8318 - val_loss: 0.5404 - val_binary_accuracy: 0.7899\n",
      "Epoch 2374/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4455 - binary_accuracy: 0.8318 - val_loss: 0.5404 - val_binary_accuracy: 0.7894\n",
      "Epoch 2375/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4455 - binary_accuracy: 0.8317 - val_loss: 0.5404 - val_binary_accuracy: 0.7894\n",
      "Epoch 2376/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4455 - binary_accuracy: 0.8320 - val_loss: 0.5404 - val_binary_accuracy: 0.7899\n",
      "Epoch 2377/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4454 - binary_accuracy: 0.8320 - val_loss: 0.5404 - val_binary_accuracy: 0.7899\n",
      "Epoch 2378/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4454 - binary_accuracy: 0.8320 - val_loss: 0.5404 - val_binary_accuracy: 0.7899\n",
      "Epoch 2379/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4454 - binary_accuracy: 0.8320 - val_loss: 0.5404 - val_binary_accuracy: 0.7899\n",
      "Epoch 2380/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4454 - binary_accuracy: 0.8318 - val_loss: 0.5404 - val_binary_accuracy: 0.7899\n",
      "Epoch 2381/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4454 - binary_accuracy: 0.8318 - val_loss: 0.5404 - val_binary_accuracy: 0.7899\n",
      "Epoch 2382/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4454 - binary_accuracy: 0.8318 - val_loss: 0.5404 - val_binary_accuracy: 0.7899\n",
      "Epoch 2383/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4454 - binary_accuracy: 0.8315 - val_loss: 0.5404 - val_binary_accuracy: 0.7899\n",
      "Epoch 2384/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4454 - binary_accuracy: 0.8318 - val_loss: 0.5404 - val_binary_accuracy: 0.7899\n",
      "Epoch 2385/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4454 - binary_accuracy: 0.8317 - val_loss: 0.5404 - val_binary_accuracy: 0.7899\n",
      "Epoch 2386/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4453 - binary_accuracy: 0.8317 - val_loss: 0.5404 - val_binary_accuracy: 0.7899\n",
      "Epoch 2387/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4453 - binary_accuracy: 0.8317 - val_loss: 0.5404 - val_binary_accuracy: 0.7899\n",
      "Epoch 2388/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4453 - binary_accuracy: 0.8317 - val_loss: 0.5404 - val_binary_accuracy: 0.7899\n",
      "Epoch 2389/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4453 - binary_accuracy: 0.8317 - val_loss: 0.5404 - val_binary_accuracy: 0.7889\n",
      "Epoch 2390/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4453 - binary_accuracy: 0.8318 - val_loss: 0.5404 - val_binary_accuracy: 0.7899\n",
      "Epoch 2391/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4453 - binary_accuracy: 0.8317 - val_loss: 0.5404 - val_binary_accuracy: 0.7899\n",
      "Epoch 2392/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4453 - binary_accuracy: 0.8317 - val_loss: 0.5405 - val_binary_accuracy: 0.7894\n",
      "Epoch 2393/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4452 - binary_accuracy: 0.8317 - val_loss: 0.5404 - val_binary_accuracy: 0.7894\n",
      "Epoch 2394/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4453 - binary_accuracy: 0.8317 - val_loss: 0.5404 - val_binary_accuracy: 0.7899\n",
      "Epoch 2395/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4452 - binary_accuracy: 0.8317 - val_loss: 0.5404 - val_binary_accuracy: 0.7899\n",
      "Epoch 2396/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4452 - binary_accuracy: 0.8317 - val_loss: 0.5404 - val_binary_accuracy: 0.7894\n",
      "Epoch 2397/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4452 - binary_accuracy: 0.8318 - val_loss: 0.5404 - val_binary_accuracy: 0.7894\n",
      "Epoch 2398/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4452 - binary_accuracy: 0.8320 - val_loss: 0.5404 - val_binary_accuracy: 0.7894\n",
      "Epoch 2399/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4452 - binary_accuracy: 0.8322 - val_loss: 0.5405 - val_binary_accuracy: 0.7894\n",
      "Epoch 2400/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4452 - binary_accuracy: 0.8320 - val_loss: 0.5405 - val_binary_accuracy: 0.7894\n",
      "Epoch 2401/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4452 - binary_accuracy: 0.8317 - val_loss: 0.5405 - val_binary_accuracy: 0.7894\n",
      "Epoch 2402/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4452 - binary_accuracy: 0.8315 - val_loss: 0.5405 - val_binary_accuracy: 0.7894\n",
      "Epoch 2403/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4451 - binary_accuracy: 0.8320 - val_loss: 0.5405 - val_binary_accuracy: 0.7894\n",
      "Epoch 2404/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4451 - binary_accuracy: 0.8313 - val_loss: 0.5405 - val_binary_accuracy: 0.7894\n",
      "Epoch 2405/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4451 - binary_accuracy: 0.8313 - val_loss: 0.5405 - val_binary_accuracy: 0.7894\n",
      "Epoch 2406/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4451 - binary_accuracy: 0.8317 - val_loss: 0.5405 - val_binary_accuracy: 0.7894\n",
      "Epoch 2407/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4451 - binary_accuracy: 0.8317 - val_loss: 0.5406 - val_binary_accuracy: 0.7899\n",
      "Epoch 2408/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4451 - binary_accuracy: 0.8317 - val_loss: 0.5405 - val_binary_accuracy: 0.7904\n",
      "Epoch 2409/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4451 - binary_accuracy: 0.8317 - val_loss: 0.5406 - val_binary_accuracy: 0.7904\n",
      "Epoch 2410/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4451 - binary_accuracy: 0.8317 - val_loss: 0.5406 - val_binary_accuracy: 0.7899\n",
      "Epoch 2411/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4450 - binary_accuracy: 0.8320 - val_loss: 0.5406 - val_binary_accuracy: 0.7894\n",
      "Epoch 2412/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4450 - binary_accuracy: 0.8320 - val_loss: 0.5406 - val_binary_accuracy: 0.7894\n",
      "Epoch 2413/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4450 - binary_accuracy: 0.8320 - val_loss: 0.5406 - val_binary_accuracy: 0.7894\n",
      "Epoch 2414/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4450 - binary_accuracy: 0.8318 - val_loss: 0.5406 - val_binary_accuracy: 0.7894\n",
      "Epoch 2415/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4450 - binary_accuracy: 0.8318 - val_loss: 0.5406 - val_binary_accuracy: 0.7899\n",
      "Epoch 2416/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4450 - binary_accuracy: 0.8318 - val_loss: 0.5406 - val_binary_accuracy: 0.7899\n",
      "Epoch 2417/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4450 - binary_accuracy: 0.8318 - val_loss: 0.5407 - val_binary_accuracy: 0.7904\n",
      "Epoch 2418/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4450 - binary_accuracy: 0.8318 - val_loss: 0.5406 - val_binary_accuracy: 0.7899\n",
      "Epoch 2419/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4449 - binary_accuracy: 0.8320 - val_loss: 0.5406 - val_binary_accuracy: 0.7904\n",
      "Epoch 2420/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4449 - binary_accuracy: 0.8320 - val_loss: 0.5406 - val_binary_accuracy: 0.7925\n",
      "Epoch 2421/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4449 - binary_accuracy: 0.8324 - val_loss: 0.5406 - val_binary_accuracy: 0.7915\n",
      "Epoch 2422/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4449 - binary_accuracy: 0.8322 - val_loss: 0.5407 - val_binary_accuracy: 0.7915\n",
      "Epoch 2423/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4449 - binary_accuracy: 0.8324 - val_loss: 0.5407 - val_binary_accuracy: 0.7920\n",
      "Epoch 2424/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4449 - binary_accuracy: 0.8320 - val_loss: 0.5407 - val_binary_accuracy: 0.7920\n",
      "Epoch 2425/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4449 - binary_accuracy: 0.8320 - val_loss: 0.5407 - val_binary_accuracy: 0.7910\n",
      "Epoch 2426/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4449 - binary_accuracy: 0.8317 - val_loss: 0.5407 - val_binary_accuracy: 0.7894\n",
      "Epoch 2427/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4449 - binary_accuracy: 0.8315 - val_loss: 0.5407 - val_binary_accuracy: 0.7904\n",
      "Epoch 2428/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4448 - binary_accuracy: 0.8315 - val_loss: 0.5407 - val_binary_accuracy: 0.7904\n",
      "Epoch 2429/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4448 - binary_accuracy: 0.8315 - val_loss: 0.5407 - val_binary_accuracy: 0.7920\n",
      "Epoch 2430/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4448 - binary_accuracy: 0.8315 - val_loss: 0.5407 - val_binary_accuracy: 0.7920\n",
      "Epoch 2431/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4448 - binary_accuracy: 0.8315 - val_loss: 0.5406 - val_binary_accuracy: 0.7915\n",
      "Epoch 2432/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4448 - binary_accuracy: 0.8315 - val_loss: 0.5407 - val_binary_accuracy: 0.7910\n",
      "Epoch 2433/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4448 - binary_accuracy: 0.8313 - val_loss: 0.5407 - val_binary_accuracy: 0.7915\n",
      "Epoch 2434/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4448 - binary_accuracy: 0.8313 - val_loss: 0.5407 - val_binary_accuracy: 0.7910\n",
      "Epoch 2435/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4448 - binary_accuracy: 0.8311 - val_loss: 0.5407 - val_binary_accuracy: 0.7915\n",
      "Epoch 2436/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4448 - binary_accuracy: 0.8311 - val_loss: 0.5407 - val_binary_accuracy: 0.7915\n",
      "Epoch 2437/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4447 - binary_accuracy: 0.8311 - val_loss: 0.5407 - val_binary_accuracy: 0.7915\n",
      "Epoch 2438/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4447 - binary_accuracy: 0.8313 - val_loss: 0.5407 - val_binary_accuracy: 0.7920\n",
      "Epoch 2439/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4447 - binary_accuracy: 0.8313 - val_loss: 0.5407 - val_binary_accuracy: 0.7915\n",
      "Epoch 2440/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4447 - binary_accuracy: 0.8310 - val_loss: 0.5407 - val_binary_accuracy: 0.7915\n",
      "Epoch 2441/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4447 - binary_accuracy: 0.8311 - val_loss: 0.5407 - val_binary_accuracy: 0.7920\n",
      "Epoch 2442/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4447 - binary_accuracy: 0.8315 - val_loss: 0.5407 - val_binary_accuracy: 0.7920\n",
      "Epoch 2443/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4447 - binary_accuracy: 0.8315 - val_loss: 0.5407 - val_binary_accuracy: 0.7920\n",
      "Epoch 2444/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4447 - binary_accuracy: 0.8320 - val_loss: 0.5408 - val_binary_accuracy: 0.7915\n",
      "Epoch 2445/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4447 - binary_accuracy: 0.8315 - val_loss: 0.5408 - val_binary_accuracy: 0.7915\n",
      "Epoch 2446/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4446 - binary_accuracy: 0.8315 - val_loss: 0.5408 - val_binary_accuracy: 0.7915\n",
      "Epoch 2447/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4446 - binary_accuracy: 0.8317 - val_loss: 0.5408 - val_binary_accuracy: 0.7920\n",
      "Epoch 2448/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4446 - binary_accuracy: 0.8320 - val_loss: 0.5409 - val_binary_accuracy: 0.7920\n",
      "Epoch 2449/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4446 - binary_accuracy: 0.8320 - val_loss: 0.5409 - val_binary_accuracy: 0.7920\n",
      "Epoch 2450/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4446 - binary_accuracy: 0.8320 - val_loss: 0.5409 - val_binary_accuracy: 0.7915\n",
      "Epoch 2451/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4446 - binary_accuracy: 0.8318 - val_loss: 0.5409 - val_binary_accuracy: 0.7915\n",
      "Epoch 2452/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4446 - binary_accuracy: 0.8320 - val_loss: 0.5410 - val_binary_accuracy: 0.7920\n",
      "Epoch 2453/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4446 - binary_accuracy: 0.8322 - val_loss: 0.5410 - val_binary_accuracy: 0.7920\n",
      "Epoch 2454/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4446 - binary_accuracy: 0.8327 - val_loss: 0.5410 - val_binary_accuracy: 0.7920\n",
      "Epoch 2455/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4445 - binary_accuracy: 0.8324 - val_loss: 0.5410 - val_binary_accuracy: 0.7925\n",
      "Epoch 2456/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4445 - binary_accuracy: 0.8320 - val_loss: 0.5410 - val_binary_accuracy: 0.7915\n",
      "Epoch 2457/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4445 - binary_accuracy: 0.8318 - val_loss: 0.5410 - val_binary_accuracy: 0.7915\n",
      "Epoch 2458/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4445 - binary_accuracy: 0.8318 - val_loss: 0.5410 - val_binary_accuracy: 0.7915\n",
      "Epoch 2459/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4445 - binary_accuracy: 0.8322 - val_loss: 0.5410 - val_binary_accuracy: 0.7920\n",
      "Epoch 2460/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4445 - binary_accuracy: 0.8324 - val_loss: 0.5411 - val_binary_accuracy: 0.7920\n",
      "Epoch 2461/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4445 - binary_accuracy: 0.8324 - val_loss: 0.5411 - val_binary_accuracy: 0.7920\n",
      "Epoch 2462/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4445 - binary_accuracy: 0.8322 - val_loss: 0.5411 - val_binary_accuracy: 0.7920\n",
      "Epoch 2463/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4445 - binary_accuracy: 0.8320 - val_loss: 0.5411 - val_binary_accuracy: 0.7920\n",
      "Epoch 2464/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4444 - binary_accuracy: 0.8320 - val_loss: 0.5411 - val_binary_accuracy: 0.7915\n",
      "Epoch 2465/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4444 - binary_accuracy: 0.8320 - val_loss: 0.5411 - val_binary_accuracy: 0.7920\n",
      "Epoch 2466/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4444 - binary_accuracy: 0.8318 - val_loss: 0.5411 - val_binary_accuracy: 0.7920\n",
      "Epoch 2467/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4444 - binary_accuracy: 0.8313 - val_loss: 0.5411 - val_binary_accuracy: 0.7915\n",
      "Epoch 2468/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4444 - binary_accuracy: 0.8315 - val_loss: 0.5412 - val_binary_accuracy: 0.7920\n",
      "Epoch 2469/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4444 - binary_accuracy: 0.8315 - val_loss: 0.5412 - val_binary_accuracy: 0.7920\n",
      "Epoch 2470/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4444 - binary_accuracy: 0.8320 - val_loss: 0.5412 - val_binary_accuracy: 0.7920\n",
      "Epoch 2471/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4444 - binary_accuracy: 0.8322 - val_loss: 0.5412 - val_binary_accuracy: 0.7920\n",
      "Epoch 2472/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4444 - binary_accuracy: 0.8325 - val_loss: 0.5412 - val_binary_accuracy: 0.7920\n",
      "Epoch 2473/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4444 - binary_accuracy: 0.8327 - val_loss: 0.5412 - val_binary_accuracy: 0.7920\n",
      "Epoch 2474/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4443 - binary_accuracy: 0.8325 - val_loss: 0.5412 - val_binary_accuracy: 0.7920\n",
      "Epoch 2475/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4443 - binary_accuracy: 0.8325 - val_loss: 0.5412 - val_binary_accuracy: 0.7920\n",
      "Epoch 2476/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4443 - binary_accuracy: 0.8327 - val_loss: 0.5412 - val_binary_accuracy: 0.7920\n",
      "Epoch 2477/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4443 - binary_accuracy: 0.8329 - val_loss: 0.5412 - val_binary_accuracy: 0.7920\n",
      "Epoch 2478/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4443 - binary_accuracy: 0.8327 - val_loss: 0.5412 - val_binary_accuracy: 0.7915\n",
      "Epoch 2479/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4443 - binary_accuracy: 0.8329 - val_loss: 0.5412 - val_binary_accuracy: 0.7920\n",
      "Epoch 2480/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4443 - binary_accuracy: 0.8325 - val_loss: 0.5412 - val_binary_accuracy: 0.7920\n",
      "Epoch 2481/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4443 - binary_accuracy: 0.8329 - val_loss: 0.5412 - val_binary_accuracy: 0.7920\n",
      "Epoch 2482/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4442 - binary_accuracy: 0.8332 - val_loss: 0.5412 - val_binary_accuracy: 0.7920\n",
      "Epoch 2483/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4442 - binary_accuracy: 0.8329 - val_loss: 0.5412 - val_binary_accuracy: 0.7920\n",
      "Epoch 2484/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4442 - binary_accuracy: 0.8331 - val_loss: 0.5412 - val_binary_accuracy: 0.7920\n",
      "Epoch 2485/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4442 - binary_accuracy: 0.8331 - val_loss: 0.5412 - val_binary_accuracy: 0.7920\n",
      "Epoch 2486/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4442 - binary_accuracy: 0.8329 - val_loss: 0.5412 - val_binary_accuracy: 0.7920\n",
      "Epoch 2487/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4442 - binary_accuracy: 0.8329 - val_loss: 0.5413 - val_binary_accuracy: 0.7920\n",
      "Epoch 2488/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4442 - binary_accuracy: 0.8327 - val_loss: 0.5413 - val_binary_accuracy: 0.7920\n",
      "Epoch 2489/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4442 - binary_accuracy: 0.8327 - val_loss: 0.5413 - val_binary_accuracy: 0.7920\n",
      "Epoch 2490/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4442 - binary_accuracy: 0.8327 - val_loss: 0.5413 - val_binary_accuracy: 0.7920\n",
      "Epoch 2491/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4442 - binary_accuracy: 0.8331 - val_loss: 0.5413 - val_binary_accuracy: 0.7920\n",
      "Epoch 2492/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4441 - binary_accuracy: 0.8324 - val_loss: 0.5413 - val_binary_accuracy: 0.7920\n",
      "Epoch 2493/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4441 - binary_accuracy: 0.8327 - val_loss: 0.5412 - val_binary_accuracy: 0.7920\n",
      "Epoch 2494/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4441 - binary_accuracy: 0.8329 - val_loss: 0.5413 - val_binary_accuracy: 0.7920\n",
      "Epoch 2495/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4441 - binary_accuracy: 0.8329 - val_loss: 0.5413 - val_binary_accuracy: 0.7920\n",
      "Epoch 2496/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4441 - binary_accuracy: 0.8332 - val_loss: 0.5414 - val_binary_accuracy: 0.7920\n",
      "Epoch 2497/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4441 - binary_accuracy: 0.8331 - val_loss: 0.5414 - val_binary_accuracy: 0.7915\n",
      "Epoch 2498/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4441 - binary_accuracy: 0.8329 - val_loss: 0.5414 - val_binary_accuracy: 0.7915\n",
      "Epoch 2499/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4441 - binary_accuracy: 0.8331 - val_loss: 0.5414 - val_binary_accuracy: 0.7915\n",
      "Epoch 2500/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4441 - binary_accuracy: 0.8327 - val_loss: 0.5415 - val_binary_accuracy: 0.7915\n",
      "Epoch 2501/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4441 - binary_accuracy: 0.8332 - val_loss: 0.5415 - val_binary_accuracy: 0.7915\n",
      "Epoch 2502/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4441 - binary_accuracy: 0.8331 - val_loss: 0.5414 - val_binary_accuracy: 0.7915\n",
      "Epoch 2503/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4440 - binary_accuracy: 0.8329 - val_loss: 0.5415 - val_binary_accuracy: 0.7915\n",
      "Epoch 2504/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4440 - binary_accuracy: 0.8332 - val_loss: 0.5415 - val_binary_accuracy: 0.7915\n",
      "Epoch 2505/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4440 - binary_accuracy: 0.8331 - val_loss: 0.5415 - val_binary_accuracy: 0.7915\n",
      "Epoch 2506/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4440 - binary_accuracy: 0.8325 - val_loss: 0.5415 - val_binary_accuracy: 0.7915\n",
      "Epoch 2507/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4440 - binary_accuracy: 0.8329 - val_loss: 0.5416 - val_binary_accuracy: 0.7920\n",
      "Epoch 2508/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4440 - binary_accuracy: 0.8329 - val_loss: 0.5416 - val_binary_accuracy: 0.7920\n",
      "Epoch 2509/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4440 - binary_accuracy: 0.8329 - val_loss: 0.5417 - val_binary_accuracy: 0.7920\n",
      "Epoch 2510/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4440 - binary_accuracy: 0.8329 - val_loss: 0.5417 - val_binary_accuracy: 0.7931\n",
      "Epoch 2511/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4440 - binary_accuracy: 0.8331 - val_loss: 0.5417 - val_binary_accuracy: 0.7931\n",
      "Epoch 2512/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4440 - binary_accuracy: 0.8331 - val_loss: 0.5418 - val_binary_accuracy: 0.7931\n",
      "Epoch 2513/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4439 - binary_accuracy: 0.8331 - val_loss: 0.5418 - val_binary_accuracy: 0.7931\n",
      "Epoch 2514/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4439 - binary_accuracy: 0.8334 - val_loss: 0.5418 - val_binary_accuracy: 0.7931\n",
      "Epoch 2515/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4439 - binary_accuracy: 0.8336 - val_loss: 0.5418 - val_binary_accuracy: 0.7931\n",
      "Epoch 2516/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4439 - binary_accuracy: 0.8334 - val_loss: 0.5418 - val_binary_accuracy: 0.7931\n",
      "Epoch 2517/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4439 - binary_accuracy: 0.8334 - val_loss: 0.5418 - val_binary_accuracy: 0.7931\n",
      "Epoch 2518/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4439 - binary_accuracy: 0.8336 - val_loss: 0.5418 - val_binary_accuracy: 0.7925\n",
      "Epoch 2519/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4439 - binary_accuracy: 0.8332 - val_loss: 0.5417 - val_binary_accuracy: 0.7931\n",
      "Epoch 2520/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4439 - binary_accuracy: 0.8331 - val_loss: 0.5417 - val_binary_accuracy: 0.7925\n",
      "Epoch 2521/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4439 - binary_accuracy: 0.8331 - val_loss: 0.5417 - val_binary_accuracy: 0.7925\n",
      "Epoch 2522/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4439 - binary_accuracy: 0.8329 - val_loss: 0.5417 - val_binary_accuracy: 0.7931\n",
      "Epoch 2523/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4439 - binary_accuracy: 0.8334 - val_loss: 0.5417 - val_binary_accuracy: 0.7931\n",
      "Epoch 2524/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4438 - binary_accuracy: 0.8336 - val_loss: 0.5416 - val_binary_accuracy: 0.7931\n",
      "Epoch 2525/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4438 - binary_accuracy: 0.8336 - val_loss: 0.5417 - val_binary_accuracy: 0.7920\n",
      "Epoch 2526/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4438 - binary_accuracy: 0.8334 - val_loss: 0.5416 - val_binary_accuracy: 0.7920\n",
      "Epoch 2527/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4438 - binary_accuracy: 0.8331 - val_loss: 0.5416 - val_binary_accuracy: 0.7920\n",
      "Epoch 2528/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4438 - binary_accuracy: 0.8332 - val_loss: 0.5417 - val_binary_accuracy: 0.7920\n",
      "Epoch 2529/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4438 - binary_accuracy: 0.8332 - val_loss: 0.5417 - val_binary_accuracy: 0.7920\n",
      "Epoch 2530/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4438 - binary_accuracy: 0.8334 - val_loss: 0.5417 - val_binary_accuracy: 0.7920\n",
      "Epoch 2531/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4438 - binary_accuracy: 0.8334 - val_loss: 0.5417 - val_binary_accuracy: 0.7920\n",
      "Epoch 2532/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4438 - binary_accuracy: 0.8332 - val_loss: 0.5417 - val_binary_accuracy: 0.7920\n",
      "Epoch 2533/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4438 - binary_accuracy: 0.8334 - val_loss: 0.5417 - val_binary_accuracy: 0.7925\n",
      "Epoch 2534/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4437 - binary_accuracy: 0.8332 - val_loss: 0.5417 - val_binary_accuracy: 0.7920\n",
      "Epoch 2535/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4437 - binary_accuracy: 0.8332 - val_loss: 0.5417 - val_binary_accuracy: 0.7925\n",
      "Epoch 2536/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4437 - binary_accuracy: 0.8331 - val_loss: 0.5417 - val_binary_accuracy: 0.7920\n",
      "Epoch 2537/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4437 - binary_accuracy: 0.8331 - val_loss: 0.5417 - val_binary_accuracy: 0.7920\n",
      "Epoch 2538/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4437 - binary_accuracy: 0.8332 - val_loss: 0.5418 - val_binary_accuracy: 0.7920\n",
      "Epoch 2539/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4437 - binary_accuracy: 0.8332 - val_loss: 0.5418 - val_binary_accuracy: 0.7920\n",
      "Epoch 2540/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4437 - binary_accuracy: 0.8332 - val_loss: 0.5419 - val_binary_accuracy: 0.7925\n",
      "Epoch 2541/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4437 - binary_accuracy: 0.8332 - val_loss: 0.5419 - val_binary_accuracy: 0.7925\n",
      "Epoch 2542/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4437 - binary_accuracy: 0.8334 - val_loss: 0.5419 - val_binary_accuracy: 0.7925\n",
      "Epoch 2543/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4437 - binary_accuracy: 0.8329 - val_loss: 0.5419 - val_binary_accuracy: 0.7920\n",
      "Epoch 2544/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4437 - binary_accuracy: 0.8331 - val_loss: 0.5419 - val_binary_accuracy: 0.7920\n",
      "Epoch 2545/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4436 - binary_accuracy: 0.8331 - val_loss: 0.5419 - val_binary_accuracy: 0.7925\n",
      "Epoch 2546/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4436 - binary_accuracy: 0.8331 - val_loss: 0.5419 - val_binary_accuracy: 0.7920\n",
      "Epoch 2547/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4436 - binary_accuracy: 0.8329 - val_loss: 0.5419 - val_binary_accuracy: 0.7920\n",
      "Epoch 2548/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4436 - binary_accuracy: 0.8329 - val_loss: 0.5419 - val_binary_accuracy: 0.7925\n",
      "Epoch 2549/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4436 - binary_accuracy: 0.8329 - val_loss: 0.5419 - val_binary_accuracy: 0.7925\n",
      "Epoch 2550/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4436 - binary_accuracy: 0.8331 - val_loss: 0.5420 - val_binary_accuracy: 0.7925\n",
      "Epoch 2551/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4436 - binary_accuracy: 0.8331 - val_loss: 0.5420 - val_binary_accuracy: 0.7920\n",
      "Epoch 2552/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4436 - binary_accuracy: 0.8332 - val_loss: 0.5420 - val_binary_accuracy: 0.7920\n",
      "Epoch 2553/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4436 - binary_accuracy: 0.8332 - val_loss: 0.5420 - val_binary_accuracy: 0.7920\n",
      "Epoch 2554/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4436 - binary_accuracy: 0.8332 - val_loss: 0.5420 - val_binary_accuracy: 0.7920\n",
      "Epoch 2555/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4436 - binary_accuracy: 0.8329 - val_loss: 0.5419 - val_binary_accuracy: 0.7915\n",
      "Epoch 2556/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4435 - binary_accuracy: 0.8327 - val_loss: 0.5419 - val_binary_accuracy: 0.7915\n",
      "Epoch 2557/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4435 - binary_accuracy: 0.8322 - val_loss: 0.5419 - val_binary_accuracy: 0.7915\n",
      "Epoch 2558/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4435 - binary_accuracy: 0.8320 - val_loss: 0.5419 - val_binary_accuracy: 0.7920\n",
      "Epoch 2559/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4435 - binary_accuracy: 0.8322 - val_loss: 0.5419 - val_binary_accuracy: 0.7920\n",
      "Epoch 2560/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4435 - binary_accuracy: 0.8324 - val_loss: 0.5420 - val_binary_accuracy: 0.7920\n",
      "Epoch 2561/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4435 - binary_accuracy: 0.8325 - val_loss: 0.5420 - val_binary_accuracy: 0.7920\n",
      "Epoch 2562/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4435 - binary_accuracy: 0.8327 - val_loss: 0.5420 - val_binary_accuracy: 0.7920\n",
      "Epoch 2563/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4435 - binary_accuracy: 0.8325 - val_loss: 0.5421 - val_binary_accuracy: 0.7920\n",
      "Epoch 2564/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4435 - binary_accuracy: 0.8327 - val_loss: 0.5421 - val_binary_accuracy: 0.7920\n",
      "Epoch 2565/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4435 - binary_accuracy: 0.8327 - val_loss: 0.5421 - val_binary_accuracy: 0.7920\n",
      "Epoch 2566/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4435 - binary_accuracy: 0.8327 - val_loss: 0.5422 - val_binary_accuracy: 0.7920\n",
      "Epoch 2567/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4435 - binary_accuracy: 0.8331 - val_loss: 0.5422 - val_binary_accuracy: 0.7920\n",
      "Epoch 2568/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4434 - binary_accuracy: 0.8334 - val_loss: 0.5422 - val_binary_accuracy: 0.7920\n",
      "Epoch 2569/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4434 - binary_accuracy: 0.8331 - val_loss: 0.5422 - val_binary_accuracy: 0.7920\n",
      "Epoch 2570/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4434 - binary_accuracy: 0.8331 - val_loss: 0.5422 - val_binary_accuracy: 0.7920\n",
      "Epoch 2571/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4434 - binary_accuracy: 0.8331 - val_loss: 0.5423 - val_binary_accuracy: 0.7920\n",
      "Epoch 2572/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4434 - binary_accuracy: 0.8329 - val_loss: 0.5423 - val_binary_accuracy: 0.7920\n",
      "Epoch 2573/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4434 - binary_accuracy: 0.8327 - val_loss: 0.5424 - val_binary_accuracy: 0.7920\n",
      "Epoch 2574/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4434 - binary_accuracy: 0.8332 - val_loss: 0.5424 - val_binary_accuracy: 0.7920\n",
      "Epoch 2575/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4434 - binary_accuracy: 0.8334 - val_loss: 0.5425 - val_binary_accuracy: 0.7920\n",
      "Epoch 2576/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4434 - binary_accuracy: 0.8334 - val_loss: 0.5424 - val_binary_accuracy: 0.7920\n",
      "Epoch 2577/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4434 - binary_accuracy: 0.8332 - val_loss: 0.5424 - val_binary_accuracy: 0.7920\n",
      "Epoch 2578/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4433 - binary_accuracy: 0.8329 - val_loss: 0.5424 - val_binary_accuracy: 0.7920\n",
      "Epoch 2579/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4433 - binary_accuracy: 0.8331 - val_loss: 0.5424 - val_binary_accuracy: 0.7920\n",
      "Epoch 2580/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4433 - binary_accuracy: 0.8329 - val_loss: 0.5425 - val_binary_accuracy: 0.7920\n",
      "Epoch 2581/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4433 - binary_accuracy: 0.8332 - val_loss: 0.5425 - val_binary_accuracy: 0.7920\n",
      "Epoch 2582/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4433 - binary_accuracy: 0.8331 - val_loss: 0.5425 - val_binary_accuracy: 0.7920\n",
      "Epoch 2583/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4433 - binary_accuracy: 0.8331 - val_loss: 0.5426 - val_binary_accuracy: 0.7920\n",
      "Epoch 2584/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4433 - binary_accuracy: 0.8334 - val_loss: 0.5426 - val_binary_accuracy: 0.7920\n",
      "Epoch 2585/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4433 - binary_accuracy: 0.8334 - val_loss: 0.5426 - val_binary_accuracy: 0.7920\n",
      "Epoch 2586/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4433 - binary_accuracy: 0.8334 - val_loss: 0.5426 - val_binary_accuracy: 0.7920\n",
      "Epoch 2587/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4433 - binary_accuracy: 0.8334 - val_loss: 0.5426 - val_binary_accuracy: 0.7920\n",
      "Epoch 2588/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4433 - binary_accuracy: 0.8331 - val_loss: 0.5426 - val_binary_accuracy: 0.7920\n",
      "Epoch 2589/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4433 - binary_accuracy: 0.8331 - val_loss: 0.5426 - val_binary_accuracy: 0.7920\n",
      "Epoch 2590/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4433 - binary_accuracy: 0.8331 - val_loss: 0.5426 - val_binary_accuracy: 0.7915\n",
      "Epoch 2591/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4432 - binary_accuracy: 0.8332 - val_loss: 0.5426 - val_binary_accuracy: 0.7920\n",
      "Epoch 2592/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4432 - binary_accuracy: 0.8331 - val_loss: 0.5427 - val_binary_accuracy: 0.7915\n",
      "Epoch 2593/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4432 - binary_accuracy: 0.8331 - val_loss: 0.5427 - val_binary_accuracy: 0.7915\n",
      "Epoch 2594/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4432 - binary_accuracy: 0.8331 - val_loss: 0.5427 - val_binary_accuracy: 0.7910\n",
      "Epoch 2595/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4432 - binary_accuracy: 0.8331 - val_loss: 0.5427 - val_binary_accuracy: 0.7910\n",
      "Epoch 2596/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4432 - binary_accuracy: 0.8329 - val_loss: 0.5427 - val_binary_accuracy: 0.7910\n",
      "Epoch 2597/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4432 - binary_accuracy: 0.8329 - val_loss: 0.5427 - val_binary_accuracy: 0.7910\n",
      "Epoch 2598/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4432 - binary_accuracy: 0.8332 - val_loss: 0.5428 - val_binary_accuracy: 0.7910\n",
      "Epoch 2599/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4432 - binary_accuracy: 0.8334 - val_loss: 0.5428 - val_binary_accuracy: 0.7915\n",
      "Epoch 2600/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4432 - binary_accuracy: 0.8336 - val_loss: 0.5428 - val_binary_accuracy: 0.7915\n",
      "Epoch 2601/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4432 - binary_accuracy: 0.8338 - val_loss: 0.5428 - val_binary_accuracy: 0.7915\n",
      "Epoch 2602/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4432 - binary_accuracy: 0.8343 - val_loss: 0.5428 - val_binary_accuracy: 0.7915\n",
      "Epoch 2603/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4432 - binary_accuracy: 0.8341 - val_loss: 0.5428 - val_binary_accuracy: 0.7915\n",
      "Epoch 2604/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4431 - binary_accuracy: 0.8339 - val_loss: 0.5428 - val_binary_accuracy: 0.7910\n",
      "Epoch 2605/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4431 - binary_accuracy: 0.8334 - val_loss: 0.5428 - val_binary_accuracy: 0.7910\n",
      "Epoch 2606/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4431 - binary_accuracy: 0.8331 - val_loss: 0.5428 - val_binary_accuracy: 0.7910\n",
      "Epoch 2607/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4431 - binary_accuracy: 0.8331 - val_loss: 0.5428 - val_binary_accuracy: 0.7910\n",
      "Epoch 2608/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4431 - binary_accuracy: 0.8329 - val_loss: 0.5428 - val_binary_accuracy: 0.7910\n",
      "Epoch 2609/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4431 - binary_accuracy: 0.8331 - val_loss: 0.5428 - val_binary_accuracy: 0.7910\n",
      "Epoch 2610/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4431 - binary_accuracy: 0.8329 - val_loss: 0.5428 - val_binary_accuracy: 0.7910\n",
      "Epoch 2611/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4431 - binary_accuracy: 0.8329 - val_loss: 0.5428 - val_binary_accuracy: 0.7910\n",
      "Epoch 2612/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4431 - binary_accuracy: 0.8331 - val_loss: 0.5428 - val_binary_accuracy: 0.7910\n",
      "Epoch 2613/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4431 - binary_accuracy: 0.8334 - val_loss: 0.5429 - val_binary_accuracy: 0.7915\n",
      "Epoch 2614/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4431 - binary_accuracy: 0.8332 - val_loss: 0.5429 - val_binary_accuracy: 0.7915\n",
      "Epoch 2615/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4431 - binary_accuracy: 0.8331 - val_loss: 0.5429 - val_binary_accuracy: 0.7920\n",
      "Epoch 2616/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4430 - binary_accuracy: 0.8329 - val_loss: 0.5429 - val_binary_accuracy: 0.7910\n",
      "Epoch 2617/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4430 - binary_accuracy: 0.8334 - val_loss: 0.5429 - val_binary_accuracy: 0.7915\n",
      "Epoch 2618/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4430 - binary_accuracy: 0.8339 - val_loss: 0.5429 - val_binary_accuracy: 0.7915\n",
      "Epoch 2619/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4430 - binary_accuracy: 0.8341 - val_loss: 0.5429 - val_binary_accuracy: 0.7915\n",
      "Epoch 2620/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4430 - binary_accuracy: 0.8341 - val_loss: 0.5429 - val_binary_accuracy: 0.7915\n",
      "Epoch 2621/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4430 - binary_accuracy: 0.8341 - val_loss: 0.5430 - val_binary_accuracy: 0.7920\n",
      "Epoch 2622/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4430 - binary_accuracy: 0.8338 - val_loss: 0.5430 - val_binary_accuracy: 0.7915\n",
      "Epoch 2623/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4430 - binary_accuracy: 0.8338 - val_loss: 0.5429 - val_binary_accuracy: 0.7915\n",
      "Epoch 2624/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4430 - binary_accuracy: 0.8334 - val_loss: 0.5429 - val_binary_accuracy: 0.7915\n",
      "Epoch 2625/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4430 - binary_accuracy: 0.8334 - val_loss: 0.5430 - val_binary_accuracy: 0.7915\n",
      "Epoch 2626/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4430 - binary_accuracy: 0.8336 - val_loss: 0.5430 - val_binary_accuracy: 0.7915\n",
      "Epoch 2627/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4430 - binary_accuracy: 0.8339 - val_loss: 0.5431 - val_binary_accuracy: 0.7915\n",
      "Epoch 2628/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4429 - binary_accuracy: 0.8338 - val_loss: 0.5431 - val_binary_accuracy: 0.7915\n",
      "Epoch 2629/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4429 - binary_accuracy: 0.8334 - val_loss: 0.5431 - val_binary_accuracy: 0.7915\n",
      "Epoch 2630/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4429 - binary_accuracy: 0.8334 - val_loss: 0.5432 - val_binary_accuracy: 0.7915\n",
      "Epoch 2631/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4429 - binary_accuracy: 0.8336 - val_loss: 0.5432 - val_binary_accuracy: 0.7915\n",
      "Epoch 2632/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4429 - binary_accuracy: 0.8336 - val_loss: 0.5432 - val_binary_accuracy: 0.7915\n",
      "Epoch 2633/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4429 - binary_accuracy: 0.8336 - val_loss: 0.5432 - val_binary_accuracy: 0.7915\n",
      "Epoch 2634/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4429 - binary_accuracy: 0.8339 - val_loss: 0.5432 - val_binary_accuracy: 0.7915\n",
      "Epoch 2635/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4429 - binary_accuracy: 0.8339 - val_loss: 0.5432 - val_binary_accuracy: 0.7920\n",
      "Epoch 2636/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4429 - binary_accuracy: 0.8341 - val_loss: 0.5432 - val_binary_accuracy: 0.7920\n",
      "Epoch 2637/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4429 - binary_accuracy: 0.8343 - val_loss: 0.5432 - val_binary_accuracy: 0.7920\n",
      "Epoch 2638/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4429 - binary_accuracy: 0.8341 - val_loss: 0.5432 - val_binary_accuracy: 0.7915\n",
      "Epoch 2639/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4429 - binary_accuracy: 0.8341 - val_loss: 0.5432 - val_binary_accuracy: 0.7920\n",
      "Epoch 2640/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4429 - binary_accuracy: 0.8341 - val_loss: 0.5432 - val_binary_accuracy: 0.7915\n",
      "Epoch 2641/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4429 - binary_accuracy: 0.8345 - val_loss: 0.5432 - val_binary_accuracy: 0.7915\n",
      "Epoch 2642/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4428 - binary_accuracy: 0.8341 - val_loss: 0.5432 - val_binary_accuracy: 0.7915\n",
      "Epoch 2643/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4428 - binary_accuracy: 0.8339 - val_loss: 0.5432 - val_binary_accuracy: 0.7915\n",
      "Epoch 2644/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4428 - binary_accuracy: 0.8341 - val_loss: 0.5432 - val_binary_accuracy: 0.7915\n",
      "Epoch 2645/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4428 - binary_accuracy: 0.8341 - val_loss: 0.5432 - val_binary_accuracy: 0.7915\n",
      "Epoch 2646/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4428 - binary_accuracy: 0.8339 - val_loss: 0.5432 - val_binary_accuracy: 0.7915\n",
      "Epoch 2647/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4428 - binary_accuracy: 0.8336 - val_loss: 0.5432 - val_binary_accuracy: 0.7915\n",
      "Epoch 2648/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4428 - binary_accuracy: 0.8336 - val_loss: 0.5432 - val_binary_accuracy: 0.7915\n",
      "Epoch 2649/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4428 - binary_accuracy: 0.8336 - val_loss: 0.5433 - val_binary_accuracy: 0.7915\n",
      "Epoch 2650/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4428 - binary_accuracy: 0.8332 - val_loss: 0.5433 - val_binary_accuracy: 0.7915\n",
      "Epoch 2651/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4428 - binary_accuracy: 0.8336 - val_loss: 0.5433 - val_binary_accuracy: 0.7915\n",
      "Epoch 2652/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4428 - binary_accuracy: 0.8338 - val_loss: 0.5433 - val_binary_accuracy: 0.7915\n",
      "Epoch 2653/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4428 - binary_accuracy: 0.8338 - val_loss: 0.5433 - val_binary_accuracy: 0.7915\n",
      "Epoch 2654/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4427 - binary_accuracy: 0.8338 - val_loss: 0.5433 - val_binary_accuracy: 0.7915\n",
      "Epoch 2655/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4427 - binary_accuracy: 0.8339 - val_loss: 0.5433 - val_binary_accuracy: 0.7915\n",
      "Epoch 2656/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4427 - binary_accuracy: 0.8338 - val_loss: 0.5433 - val_binary_accuracy: 0.7915\n",
      "Epoch 2657/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4427 - binary_accuracy: 0.8339 - val_loss: 0.5434 - val_binary_accuracy: 0.7915\n",
      "Epoch 2658/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4427 - binary_accuracy: 0.8336 - val_loss: 0.5434 - val_binary_accuracy: 0.7915\n",
      "Epoch 2659/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4427 - binary_accuracy: 0.8331 - val_loss: 0.5434 - val_binary_accuracy: 0.7915\n",
      "Epoch 2660/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4427 - binary_accuracy: 0.8332 - val_loss: 0.5434 - val_binary_accuracy: 0.7915\n",
      "Epoch 2661/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4427 - binary_accuracy: 0.8334 - val_loss: 0.5434 - val_binary_accuracy: 0.7915\n",
      "Epoch 2662/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4427 - binary_accuracy: 0.8334 - val_loss: 0.5435 - val_binary_accuracy: 0.7920\n",
      "Epoch 2663/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4427 - binary_accuracy: 0.8334 - val_loss: 0.5435 - val_binary_accuracy: 0.7915\n",
      "Epoch 2664/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4427 - binary_accuracy: 0.8332 - val_loss: 0.5435 - val_binary_accuracy: 0.7915\n",
      "Epoch 2665/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4427 - binary_accuracy: 0.8334 - val_loss: 0.5435 - val_binary_accuracy: 0.7915\n",
      "Epoch 2666/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4427 - binary_accuracy: 0.8334 - val_loss: 0.5436 - val_binary_accuracy: 0.7915\n",
      "Epoch 2667/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4427 - binary_accuracy: 0.8336 - val_loss: 0.5436 - val_binary_accuracy: 0.7920\n",
      "Epoch 2668/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4427 - binary_accuracy: 0.8334 - val_loss: 0.5436 - val_binary_accuracy: 0.7920\n",
      "Epoch 2669/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4426 - binary_accuracy: 0.8336 - val_loss: 0.5436 - val_binary_accuracy: 0.7920\n",
      "Epoch 2670/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4426 - binary_accuracy: 0.8339 - val_loss: 0.5436 - val_binary_accuracy: 0.7920\n",
      "Epoch 2671/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4426 - binary_accuracy: 0.8341 - val_loss: 0.5436 - val_binary_accuracy: 0.7920\n",
      "Epoch 2672/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4426 - binary_accuracy: 0.8341 - val_loss: 0.5436 - val_binary_accuracy: 0.7920\n",
      "Epoch 2673/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4426 - binary_accuracy: 0.8341 - val_loss: 0.5436 - val_binary_accuracy: 0.7920\n",
      "Epoch 2674/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4426 - binary_accuracy: 0.8343 - val_loss: 0.5436 - val_binary_accuracy: 0.7915\n",
      "Epoch 2675/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4426 - binary_accuracy: 0.8343 - val_loss: 0.5436 - val_binary_accuracy: 0.7920\n",
      "Epoch 2676/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4426 - binary_accuracy: 0.8343 - val_loss: 0.5436 - val_binary_accuracy: 0.7915\n",
      "Epoch 2677/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4426 - binary_accuracy: 0.8339 - val_loss: 0.5436 - val_binary_accuracy: 0.7915\n",
      "Epoch 2678/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4426 - binary_accuracy: 0.8339 - val_loss: 0.5436 - val_binary_accuracy: 0.7915\n",
      "Epoch 2679/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4426 - binary_accuracy: 0.8339 - val_loss: 0.5437 - val_binary_accuracy: 0.7915\n",
      "Epoch 2680/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4426 - binary_accuracy: 0.8338 - val_loss: 0.5436 - val_binary_accuracy: 0.7915\n",
      "Epoch 2681/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4426 - binary_accuracy: 0.8339 - val_loss: 0.5437 - val_binary_accuracy: 0.7915\n",
      "Epoch 2682/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4426 - binary_accuracy: 0.8343 - val_loss: 0.5437 - val_binary_accuracy: 0.7915\n",
      "Epoch 2683/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4426 - binary_accuracy: 0.8341 - val_loss: 0.5437 - val_binary_accuracy: 0.7915\n",
      "Epoch 2684/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4425 - binary_accuracy: 0.8339 - val_loss: 0.5437 - val_binary_accuracy: 0.7915\n",
      "Epoch 2685/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4425 - binary_accuracy: 0.8341 - val_loss: 0.5437 - val_binary_accuracy: 0.7915\n",
      "Epoch 2686/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4425 - binary_accuracy: 0.8346 - val_loss: 0.5437 - val_binary_accuracy: 0.7915\n",
      "Epoch 2687/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4425 - binary_accuracy: 0.8346 - val_loss: 0.5437 - val_binary_accuracy: 0.7915\n",
      "Epoch 2688/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4425 - binary_accuracy: 0.8345 - val_loss: 0.5438 - val_binary_accuracy: 0.7915\n",
      "Epoch 2689/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4425 - binary_accuracy: 0.8346 - val_loss: 0.5438 - val_binary_accuracy: 0.7915\n",
      "Epoch 2690/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4425 - binary_accuracy: 0.8346 - val_loss: 0.5438 - val_binary_accuracy: 0.7915\n",
      "Epoch 2691/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4425 - binary_accuracy: 0.8346 - val_loss: 0.5438 - val_binary_accuracy: 0.7915\n",
      "Epoch 2692/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4425 - binary_accuracy: 0.8346 - val_loss: 0.5438 - val_binary_accuracy: 0.7920\n",
      "Epoch 2693/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4425 - binary_accuracy: 0.8345 - val_loss: 0.5439 - val_binary_accuracy: 0.7920\n",
      "Epoch 2694/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4425 - binary_accuracy: 0.8346 - val_loss: 0.5439 - val_binary_accuracy: 0.7920\n",
      "Epoch 2695/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4425 - binary_accuracy: 0.8348 - val_loss: 0.5439 - val_binary_accuracy: 0.7920\n",
      "Epoch 2696/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4425 - binary_accuracy: 0.8350 - val_loss: 0.5439 - val_binary_accuracy: 0.7920\n",
      "Epoch 2697/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4425 - binary_accuracy: 0.8352 - val_loss: 0.5439 - val_binary_accuracy: 0.7925\n",
      "Epoch 2698/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4425 - binary_accuracy: 0.8352 - val_loss: 0.5439 - val_binary_accuracy: 0.7925\n",
      "Epoch 2699/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4424 - binary_accuracy: 0.8352 - val_loss: 0.5439 - val_binary_accuracy: 0.7925\n",
      "Epoch 2700/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4424 - binary_accuracy: 0.8352 - val_loss: 0.5439 - val_binary_accuracy: 0.7920\n",
      "Epoch 2701/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4424 - binary_accuracy: 0.8352 - val_loss: 0.5440 - val_binary_accuracy: 0.7925\n",
      "Epoch 2702/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4424 - binary_accuracy: 0.8352 - val_loss: 0.5440 - val_binary_accuracy: 0.7925\n",
      "Epoch 2703/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4424 - binary_accuracy: 0.8352 - val_loss: 0.5440 - val_binary_accuracy: 0.7925\n",
      "Epoch 2704/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4424 - binary_accuracy: 0.8353 - val_loss: 0.5440 - val_binary_accuracy: 0.7925\n",
      "Epoch 2705/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4424 - binary_accuracy: 0.8353 - val_loss: 0.5440 - val_binary_accuracy: 0.7925\n",
      "Epoch 2706/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4424 - binary_accuracy: 0.8352 - val_loss: 0.5440 - val_binary_accuracy: 0.7925\n",
      "Epoch 2707/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4424 - binary_accuracy: 0.8352 - val_loss: 0.5440 - val_binary_accuracy: 0.7925\n",
      "Epoch 2708/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4424 - binary_accuracy: 0.8350 - val_loss: 0.5440 - val_binary_accuracy: 0.7925\n",
      "Epoch 2709/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4424 - binary_accuracy: 0.8350 - val_loss: 0.5440 - val_binary_accuracy: 0.7925\n",
      "Epoch 2710/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4424 - binary_accuracy: 0.8350 - val_loss: 0.5440 - val_binary_accuracy: 0.7931\n",
      "Epoch 2711/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4424 - binary_accuracy: 0.8352 - val_loss: 0.5440 - val_binary_accuracy: 0.7931\n",
      "Epoch 2712/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4424 - binary_accuracy: 0.8353 - val_loss: 0.5440 - val_binary_accuracy: 0.7931\n",
      "Epoch 2713/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4424 - binary_accuracy: 0.8353 - val_loss: 0.5440 - val_binary_accuracy: 0.7931\n",
      "Epoch 2714/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4423 - binary_accuracy: 0.8352 - val_loss: 0.5440 - val_binary_accuracy: 0.7931\n",
      "Epoch 2715/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4423 - binary_accuracy: 0.8352 - val_loss: 0.5440 - val_binary_accuracy: 0.7931\n",
      "Epoch 2716/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4423 - binary_accuracy: 0.8352 - val_loss: 0.5440 - val_binary_accuracy: 0.7931\n",
      "Epoch 2717/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4423 - binary_accuracy: 0.8353 - val_loss: 0.5440 - val_binary_accuracy: 0.7931\n",
      "Epoch 2718/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4423 - binary_accuracy: 0.8353 - val_loss: 0.5441 - val_binary_accuracy: 0.7931\n",
      "Epoch 2719/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4423 - binary_accuracy: 0.8352 - val_loss: 0.5441 - val_binary_accuracy: 0.7925\n",
      "Epoch 2720/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4423 - binary_accuracy: 0.8352 - val_loss: 0.5441 - val_binary_accuracy: 0.7931\n",
      "Epoch 2721/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4423 - binary_accuracy: 0.8353 - val_loss: 0.5441 - val_binary_accuracy: 0.7931\n",
      "Epoch 2722/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4423 - binary_accuracy: 0.8355 - val_loss: 0.5442 - val_binary_accuracy: 0.7931\n",
      "Epoch 2723/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4423 - binary_accuracy: 0.8352 - val_loss: 0.5442 - val_binary_accuracy: 0.7931\n",
      "Epoch 2724/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4423 - binary_accuracy: 0.8352 - val_loss: 0.5442 - val_binary_accuracy: 0.7931\n",
      "Epoch 2725/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4423 - binary_accuracy: 0.8352 - val_loss: 0.5442 - val_binary_accuracy: 0.7931\n",
      "Epoch 2726/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4423 - binary_accuracy: 0.8353 - val_loss: 0.5442 - val_binary_accuracy: 0.7931\n",
      "Epoch 2727/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4423 - binary_accuracy: 0.8355 - val_loss: 0.5442 - val_binary_accuracy: 0.7931\n",
      "Epoch 2728/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4423 - binary_accuracy: 0.8355 - val_loss: 0.5442 - val_binary_accuracy: 0.7925\n",
      "Epoch 2729/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4422 - binary_accuracy: 0.8359 - val_loss: 0.5443 - val_binary_accuracy: 0.7931\n",
      "Epoch 2730/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4423 - binary_accuracy: 0.8357 - val_loss: 0.5443 - val_binary_accuracy: 0.7936\n",
      "Epoch 2731/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4422 - binary_accuracy: 0.8359 - val_loss: 0.5443 - val_binary_accuracy: 0.7936\n",
      "Epoch 2732/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4422 - binary_accuracy: 0.8359 - val_loss: 0.5443 - val_binary_accuracy: 0.7931\n",
      "Epoch 2733/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4422 - binary_accuracy: 0.8360 - val_loss: 0.5443 - val_binary_accuracy: 0.7931\n",
      "Epoch 2734/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4422 - binary_accuracy: 0.8360 - val_loss: 0.5442 - val_binary_accuracy: 0.7931\n",
      "Epoch 2735/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4422 - binary_accuracy: 0.8360 - val_loss: 0.5442 - val_binary_accuracy: 0.7931\n",
      "Epoch 2736/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4422 - binary_accuracy: 0.8360 - val_loss: 0.5443 - val_binary_accuracy: 0.7936\n",
      "Epoch 2737/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4422 - binary_accuracy: 0.8360 - val_loss: 0.5443 - val_binary_accuracy: 0.7936\n",
      "Epoch 2738/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4422 - binary_accuracy: 0.8360 - val_loss: 0.5442 - val_binary_accuracy: 0.7936\n",
      "Epoch 2739/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4422 - binary_accuracy: 0.8360 - val_loss: 0.5442 - val_binary_accuracy: 0.7941\n",
      "Epoch 2740/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4422 - binary_accuracy: 0.8360 - val_loss: 0.5442 - val_binary_accuracy: 0.7941\n",
      "Epoch 2741/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4422 - binary_accuracy: 0.8357 - val_loss: 0.5442 - val_binary_accuracy: 0.7941\n",
      "Epoch 2742/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4422 - binary_accuracy: 0.8355 - val_loss: 0.5442 - val_binary_accuracy: 0.7941\n",
      "Epoch 2743/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4422 - binary_accuracy: 0.8353 - val_loss: 0.5442 - val_binary_accuracy: 0.7941\n",
      "Epoch 2744/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4422 - binary_accuracy: 0.8352 - val_loss: 0.5442 - val_binary_accuracy: 0.7936\n",
      "Epoch 2745/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4421 - binary_accuracy: 0.8348 - val_loss: 0.5442 - val_binary_accuracy: 0.7936\n",
      "Epoch 2746/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4421 - binary_accuracy: 0.8352 - val_loss: 0.5442 - val_binary_accuracy: 0.7936\n",
      "Epoch 2747/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4421 - binary_accuracy: 0.8350 - val_loss: 0.5442 - val_binary_accuracy: 0.7936\n",
      "Epoch 2748/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4421 - binary_accuracy: 0.8348 - val_loss: 0.5442 - val_binary_accuracy: 0.7936\n",
      "Epoch 2749/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4421 - binary_accuracy: 0.8352 - val_loss: 0.5443 - val_binary_accuracy: 0.7936\n",
      "Epoch 2750/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4421 - binary_accuracy: 0.8352 - val_loss: 0.5443 - val_binary_accuracy: 0.7941\n",
      "Epoch 2751/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4421 - binary_accuracy: 0.8350 - val_loss: 0.5442 - val_binary_accuracy: 0.7936\n",
      "Epoch 2752/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4421 - binary_accuracy: 0.8352 - val_loss: 0.5443 - val_binary_accuracy: 0.7936\n",
      "Epoch 2753/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4421 - binary_accuracy: 0.8353 - val_loss: 0.5443 - val_binary_accuracy: 0.7946\n",
      "Epoch 2754/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4421 - binary_accuracy: 0.8355 - val_loss: 0.5443 - val_binary_accuracy: 0.7936\n",
      "Epoch 2755/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4421 - binary_accuracy: 0.8355 - val_loss: 0.5443 - val_binary_accuracy: 0.7936\n",
      "Epoch 2756/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4421 - binary_accuracy: 0.8355 - val_loss: 0.5443 - val_binary_accuracy: 0.7936\n",
      "Epoch 2757/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4421 - binary_accuracy: 0.8352 - val_loss: 0.5443 - val_binary_accuracy: 0.7936\n",
      "Epoch 2758/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4421 - binary_accuracy: 0.8352 - val_loss: 0.5443 - val_binary_accuracy: 0.7936\n",
      "Epoch 2759/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4421 - binary_accuracy: 0.8352 - val_loss: 0.5443 - val_binary_accuracy: 0.7936\n",
      "Epoch 2760/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4421 - binary_accuracy: 0.8352 - val_loss: 0.5444 - val_binary_accuracy: 0.7931\n",
      "Epoch 2761/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4421 - binary_accuracy: 0.8352 - val_loss: 0.5444 - val_binary_accuracy: 0.7936\n",
      "Epoch 2762/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4420 - binary_accuracy: 0.8357 - val_loss: 0.5444 - val_binary_accuracy: 0.7936\n",
      "Epoch 2763/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4420 - binary_accuracy: 0.8357 - val_loss: 0.5444 - val_binary_accuracy: 0.7936\n",
      "Epoch 2764/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4420 - binary_accuracy: 0.8360 - val_loss: 0.5445 - val_binary_accuracy: 0.7941\n",
      "Epoch 2765/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4420 - binary_accuracy: 0.8360 - val_loss: 0.5445 - val_binary_accuracy: 0.7941\n",
      "Epoch 2766/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4420 - binary_accuracy: 0.8364 - val_loss: 0.5445 - val_binary_accuracy: 0.7946\n",
      "Epoch 2767/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4420 - binary_accuracy: 0.8364 - val_loss: 0.5445 - val_binary_accuracy: 0.7946\n",
      "Epoch 2768/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4420 - binary_accuracy: 0.8367 - val_loss: 0.5446 - val_binary_accuracy: 0.7946\n",
      "Epoch 2769/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4420 - binary_accuracy: 0.8367 - val_loss: 0.5446 - val_binary_accuracy: 0.7946\n",
      "Epoch 2770/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4420 - binary_accuracy: 0.8364 - val_loss: 0.5446 - val_binary_accuracy: 0.7946\n",
      "Epoch 2771/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4420 - binary_accuracy: 0.8362 - val_loss: 0.5445 - val_binary_accuracy: 0.7941\n",
      "Epoch 2772/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4420 - binary_accuracy: 0.8360 - val_loss: 0.5445 - val_binary_accuracy: 0.7946\n",
      "Epoch 2773/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4420 - binary_accuracy: 0.8359 - val_loss: 0.5445 - val_binary_accuracy: 0.7946\n",
      "Epoch 2774/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4420 - binary_accuracy: 0.8357 - val_loss: 0.5445 - val_binary_accuracy: 0.7946\n",
      "Epoch 2775/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4420 - binary_accuracy: 0.8359 - val_loss: 0.5445 - val_binary_accuracy: 0.7946\n",
      "Epoch 2776/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4420 - binary_accuracy: 0.8357 - val_loss: 0.5446 - val_binary_accuracy: 0.7946\n",
      "Epoch 2777/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4420 - binary_accuracy: 0.8360 - val_loss: 0.5446 - val_binary_accuracy: 0.7946\n",
      "Epoch 2778/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4420 - binary_accuracy: 0.8359 - val_loss: 0.5446 - val_binary_accuracy: 0.7946\n",
      "Epoch 2779/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4420 - binary_accuracy: 0.8359 - val_loss: 0.5446 - val_binary_accuracy: 0.7941\n",
      "Epoch 2780/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4420 - binary_accuracy: 0.8359 - val_loss: 0.5446 - val_binary_accuracy: 0.7941\n",
      "Epoch 2781/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4419 - binary_accuracy: 0.8360 - val_loss: 0.5446 - val_binary_accuracy: 0.7946\n",
      "Epoch 2782/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4419 - binary_accuracy: 0.8357 - val_loss: 0.5446 - val_binary_accuracy: 0.7946\n",
      "Epoch 2783/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4419 - binary_accuracy: 0.8359 - val_loss: 0.5446 - val_binary_accuracy: 0.7946\n",
      "Epoch 2784/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4419 - binary_accuracy: 0.8359 - val_loss: 0.5446 - val_binary_accuracy: 0.7941\n",
      "Epoch 2785/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4419 - binary_accuracy: 0.8359 - val_loss: 0.5447 - val_binary_accuracy: 0.7941\n",
      "Epoch 2786/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4419 - binary_accuracy: 0.8360 - val_loss: 0.5447 - val_binary_accuracy: 0.7941\n",
      "Epoch 2787/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4419 - binary_accuracy: 0.8360 - val_loss: 0.5447 - val_binary_accuracy: 0.7941\n",
      "Epoch 2788/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4419 - binary_accuracy: 0.8359 - val_loss: 0.5448 - val_binary_accuracy: 0.7941\n",
      "Epoch 2789/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4419 - binary_accuracy: 0.8362 - val_loss: 0.5448 - val_binary_accuracy: 0.7941\n",
      "Epoch 2790/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4419 - binary_accuracy: 0.8364 - val_loss: 0.5448 - val_binary_accuracy: 0.7941\n",
      "Epoch 2791/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4419 - binary_accuracy: 0.8364 - val_loss: 0.5448 - val_binary_accuracy: 0.7941\n",
      "Epoch 2792/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4419 - binary_accuracy: 0.8364 - val_loss: 0.5448 - val_binary_accuracy: 0.7936\n",
      "Epoch 2793/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4419 - binary_accuracy: 0.8364 - val_loss: 0.5448 - val_binary_accuracy: 0.7936\n",
      "Epoch 2794/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4419 - binary_accuracy: 0.8364 - val_loss: 0.5449 - val_binary_accuracy: 0.7936\n",
      "Epoch 2795/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4419 - binary_accuracy: 0.8362 - val_loss: 0.5449 - val_binary_accuracy: 0.7936\n",
      "Epoch 2796/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4419 - binary_accuracy: 0.8364 - val_loss: 0.5449 - val_binary_accuracy: 0.7941\n",
      "Epoch 2797/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4419 - binary_accuracy: 0.8364 - val_loss: 0.5449 - val_binary_accuracy: 0.7952\n",
      "Epoch 2798/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4419 - binary_accuracy: 0.8364 - val_loss: 0.5450 - val_binary_accuracy: 0.7952\n",
      "Epoch 2799/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4418 - binary_accuracy: 0.8367 - val_loss: 0.5450 - val_binary_accuracy: 0.7946\n",
      "Epoch 2800/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4418 - binary_accuracy: 0.8364 - val_loss: 0.5450 - val_binary_accuracy: 0.7946\n",
      "Epoch 2801/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4419 - binary_accuracy: 0.8364 - val_loss: 0.5450 - val_binary_accuracy: 0.7946\n",
      "Epoch 2802/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4418 - binary_accuracy: 0.8366 - val_loss: 0.5449 - val_binary_accuracy: 0.7952\n",
      "Epoch 2803/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4418 - binary_accuracy: 0.8366 - val_loss: 0.5449 - val_binary_accuracy: 0.7941\n",
      "Epoch 2804/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4418 - binary_accuracy: 0.8366 - val_loss: 0.5449 - val_binary_accuracy: 0.7946\n",
      "Epoch 2805/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4418 - binary_accuracy: 0.8366 - val_loss: 0.5449 - val_binary_accuracy: 0.7946\n",
      "Epoch 2806/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4418 - binary_accuracy: 0.8364 - val_loss: 0.5449 - val_binary_accuracy: 0.7946\n",
      "Epoch 2807/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4418 - binary_accuracy: 0.8360 - val_loss: 0.5449 - val_binary_accuracy: 0.7941\n",
      "Epoch 2808/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4418 - binary_accuracy: 0.8359 - val_loss: 0.5450 - val_binary_accuracy: 0.7941\n",
      "Epoch 2809/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4418 - binary_accuracy: 0.8359 - val_loss: 0.5450 - val_binary_accuracy: 0.7941\n",
      "Epoch 2810/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4418 - binary_accuracy: 0.8360 - val_loss: 0.5450 - val_binary_accuracy: 0.7941\n",
      "Epoch 2811/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4418 - binary_accuracy: 0.8360 - val_loss: 0.5450 - val_binary_accuracy: 0.7936\n",
      "Epoch 2812/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4418 - binary_accuracy: 0.8360 - val_loss: 0.5450 - val_binary_accuracy: 0.7941\n",
      "Epoch 2813/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4418 - binary_accuracy: 0.8359 - val_loss: 0.5450 - val_binary_accuracy: 0.7941\n",
      "Epoch 2814/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4418 - binary_accuracy: 0.8360 - val_loss: 0.5450 - val_binary_accuracy: 0.7946\n",
      "Epoch 2815/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4418 - binary_accuracy: 0.8362 - val_loss: 0.5450 - val_binary_accuracy: 0.7946\n",
      "Epoch 2816/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4418 - binary_accuracy: 0.8359 - val_loss: 0.5451 - val_binary_accuracy: 0.7946\n",
      "Epoch 2817/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4418 - binary_accuracy: 0.8362 - val_loss: 0.5451 - val_binary_accuracy: 0.7946\n",
      "Epoch 2818/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4418 - binary_accuracy: 0.8360 - val_loss: 0.5451 - val_binary_accuracy: 0.7936\n",
      "Epoch 2819/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4417 - binary_accuracy: 0.8359 - val_loss: 0.5452 - val_binary_accuracy: 0.7936\n",
      "Epoch 2820/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4417 - binary_accuracy: 0.8362 - val_loss: 0.5451 - val_binary_accuracy: 0.7931\n",
      "Epoch 2821/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4417 - binary_accuracy: 0.8360 - val_loss: 0.5452 - val_binary_accuracy: 0.7936\n",
      "Epoch 2822/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4417 - binary_accuracy: 0.8360 - val_loss: 0.5452 - val_binary_accuracy: 0.7936\n",
      "Epoch 2823/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4417 - binary_accuracy: 0.8360 - val_loss: 0.5452 - val_binary_accuracy: 0.7936\n",
      "Epoch 2824/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4417 - binary_accuracy: 0.8360 - val_loss: 0.5452 - val_binary_accuracy: 0.7936\n",
      "Epoch 2825/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4417 - binary_accuracy: 0.8359 - val_loss: 0.5452 - val_binary_accuracy: 0.7936\n",
      "Epoch 2826/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4417 - binary_accuracy: 0.8357 - val_loss: 0.5452 - val_binary_accuracy: 0.7936\n",
      "Epoch 2827/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4417 - binary_accuracy: 0.8357 - val_loss: 0.5452 - val_binary_accuracy: 0.7931\n",
      "Epoch 2828/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4417 - binary_accuracy: 0.8355 - val_loss: 0.5452 - val_binary_accuracy: 0.7936\n",
      "Epoch 2829/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4417 - binary_accuracy: 0.8352 - val_loss: 0.5453 - val_binary_accuracy: 0.7936\n",
      "Epoch 2830/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4417 - binary_accuracy: 0.8357 - val_loss: 0.5453 - val_binary_accuracy: 0.7931\n",
      "Epoch 2831/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4417 - binary_accuracy: 0.8357 - val_loss: 0.5453 - val_binary_accuracy: 0.7931\n",
      "Epoch 2832/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4417 - binary_accuracy: 0.8360 - val_loss: 0.5453 - val_binary_accuracy: 0.7931\n",
      "Epoch 2833/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4417 - binary_accuracy: 0.8364 - val_loss: 0.5453 - val_binary_accuracy: 0.7931\n",
      "Epoch 2834/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4417 - binary_accuracy: 0.8366 - val_loss: 0.5453 - val_binary_accuracy: 0.7931\n",
      "Epoch 2835/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4417 - binary_accuracy: 0.8367 - val_loss: 0.5453 - val_binary_accuracy: 0.7931\n",
      "Epoch 2836/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4417 - binary_accuracy: 0.8366 - val_loss: 0.5453 - val_binary_accuracy: 0.7936\n",
      "Epoch 2837/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4417 - binary_accuracy: 0.8367 - val_loss: 0.5453 - val_binary_accuracy: 0.7936\n",
      "Epoch 2838/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4417 - binary_accuracy: 0.8367 - val_loss: 0.5453 - val_binary_accuracy: 0.7936\n",
      "Epoch 2839/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4417 - binary_accuracy: 0.8367 - val_loss: 0.5453 - val_binary_accuracy: 0.7936\n",
      "Epoch 2840/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4417 - binary_accuracy: 0.8369 - val_loss: 0.5454 - val_binary_accuracy: 0.7936\n",
      "Epoch 2841/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4416 - binary_accuracy: 0.8371 - val_loss: 0.5454 - val_binary_accuracy: 0.7936\n",
      "Epoch 2842/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4416 - binary_accuracy: 0.8367 - val_loss: 0.5454 - val_binary_accuracy: 0.7931\n",
      "Epoch 2843/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4416 - binary_accuracy: 0.8366 - val_loss: 0.5454 - val_binary_accuracy: 0.7936\n",
      "Epoch 2844/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4416 - binary_accuracy: 0.8364 - val_loss: 0.5454 - val_binary_accuracy: 0.7936\n",
      "Epoch 2845/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4416 - binary_accuracy: 0.8362 - val_loss: 0.5453 - val_binary_accuracy: 0.7931\n",
      "Epoch 2846/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4416 - binary_accuracy: 0.8360 - val_loss: 0.5453 - val_binary_accuracy: 0.7931\n",
      "Epoch 2847/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4416 - binary_accuracy: 0.8362 - val_loss: 0.5454 - val_binary_accuracy: 0.7931\n",
      "Epoch 2848/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4416 - binary_accuracy: 0.8367 - val_loss: 0.5454 - val_binary_accuracy: 0.7936\n",
      "Epoch 2849/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4416 - binary_accuracy: 0.8371 - val_loss: 0.5455 - val_binary_accuracy: 0.7931\n",
      "Epoch 2850/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4416 - binary_accuracy: 0.8371 - val_loss: 0.5455 - val_binary_accuracy: 0.7931\n",
      "Epoch 2851/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4416 - binary_accuracy: 0.8371 - val_loss: 0.5454 - val_binary_accuracy: 0.7931\n",
      "Epoch 2852/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4416 - binary_accuracy: 0.8369 - val_loss: 0.5454 - val_binary_accuracy: 0.7931\n",
      "Epoch 2853/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4416 - binary_accuracy: 0.8367 - val_loss: 0.5454 - val_binary_accuracy: 0.7931\n",
      "Epoch 2854/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4416 - binary_accuracy: 0.8367 - val_loss: 0.5454 - val_binary_accuracy: 0.7936\n",
      "Epoch 2855/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4416 - binary_accuracy: 0.8362 - val_loss: 0.5454 - val_binary_accuracy: 0.7936\n",
      "Epoch 2856/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4416 - binary_accuracy: 0.8360 - val_loss: 0.5454 - val_binary_accuracy: 0.7936\n",
      "Epoch 2857/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4416 - binary_accuracy: 0.8364 - val_loss: 0.5454 - val_binary_accuracy: 0.7941\n",
      "Epoch 2858/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4416 - binary_accuracy: 0.8364 - val_loss: 0.5454 - val_binary_accuracy: 0.7941\n",
      "Epoch 2859/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4416 - binary_accuracy: 0.8364 - val_loss: 0.5454 - val_binary_accuracy: 0.7941\n",
      "Epoch 2860/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4416 - binary_accuracy: 0.8367 - val_loss: 0.5454 - val_binary_accuracy: 0.7941\n",
      "Epoch 2861/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4416 - binary_accuracy: 0.8371 - val_loss: 0.5454 - val_binary_accuracy: 0.7946\n",
      "Epoch 2862/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4415 - binary_accuracy: 0.8371 - val_loss: 0.5454 - val_binary_accuracy: 0.7946\n",
      "Epoch 2863/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4416 - binary_accuracy: 0.8364 - val_loss: 0.5454 - val_binary_accuracy: 0.7941\n",
      "Epoch 2864/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4415 - binary_accuracy: 0.8359 - val_loss: 0.5455 - val_binary_accuracy: 0.7941\n",
      "Epoch 2865/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4415 - binary_accuracy: 0.8362 - val_loss: 0.5455 - val_binary_accuracy: 0.7936\n",
      "Epoch 2866/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4415 - binary_accuracy: 0.8364 - val_loss: 0.5455 - val_binary_accuracy: 0.7941\n",
      "Epoch 2867/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4415 - binary_accuracy: 0.8362 - val_loss: 0.5455 - val_binary_accuracy: 0.7936\n",
      "Epoch 2868/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4415 - binary_accuracy: 0.8364 - val_loss: 0.5455 - val_binary_accuracy: 0.7946\n",
      "Epoch 2869/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4415 - binary_accuracy: 0.8366 - val_loss: 0.5455 - val_binary_accuracy: 0.7941\n",
      "Epoch 2870/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4415 - binary_accuracy: 0.8367 - val_loss: 0.5455 - val_binary_accuracy: 0.7941\n",
      "Epoch 2871/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4415 - binary_accuracy: 0.8366 - val_loss: 0.5455 - val_binary_accuracy: 0.7941\n",
      "Epoch 2872/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4415 - binary_accuracy: 0.8367 - val_loss: 0.5456 - val_binary_accuracy: 0.7941\n",
      "Epoch 2873/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4415 - binary_accuracy: 0.8367 - val_loss: 0.5456 - val_binary_accuracy: 0.7941\n",
      "Epoch 2874/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4415 - binary_accuracy: 0.8369 - val_loss: 0.5456 - val_binary_accuracy: 0.7936\n",
      "Epoch 2875/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4415 - binary_accuracy: 0.8367 - val_loss: 0.5456 - val_binary_accuracy: 0.7941\n",
      "Epoch 2876/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4415 - binary_accuracy: 0.8364 - val_loss: 0.5457 - val_binary_accuracy: 0.7936\n",
      "Epoch 2877/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4415 - binary_accuracy: 0.8366 - val_loss: 0.5457 - val_binary_accuracy: 0.7936\n",
      "Epoch 2878/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4415 - binary_accuracy: 0.8366 - val_loss: 0.5458 - val_binary_accuracy: 0.7936\n",
      "Epoch 2879/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4415 - binary_accuracy: 0.8366 - val_loss: 0.5458 - val_binary_accuracy: 0.7936\n",
      "Epoch 2880/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4415 - binary_accuracy: 0.8367 - val_loss: 0.5458 - val_binary_accuracy: 0.7936\n",
      "Epoch 2881/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4415 - binary_accuracy: 0.8366 - val_loss: 0.5458 - val_binary_accuracy: 0.7936\n",
      "Epoch 2882/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4415 - binary_accuracy: 0.8364 - val_loss: 0.5458 - val_binary_accuracy: 0.7936\n",
      "Epoch 2883/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4415 - binary_accuracy: 0.8364 - val_loss: 0.5458 - val_binary_accuracy: 0.7936\n",
      "Epoch 2884/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4415 - binary_accuracy: 0.8364 - val_loss: 0.5458 - val_binary_accuracy: 0.7936\n",
      "Epoch 2885/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4415 - binary_accuracy: 0.8366 - val_loss: 0.5459 - val_binary_accuracy: 0.7941\n",
      "Epoch 2886/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4415 - binary_accuracy: 0.8366 - val_loss: 0.5459 - val_binary_accuracy: 0.7941\n",
      "Epoch 2887/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4415 - binary_accuracy: 0.8364 - val_loss: 0.5459 - val_binary_accuracy: 0.7946\n",
      "Epoch 2888/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4414 - binary_accuracy: 0.8366 - val_loss: 0.5459 - val_binary_accuracy: 0.7941\n",
      "Epoch 2889/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4414 - binary_accuracy: 0.8366 - val_loss: 0.5460 - val_binary_accuracy: 0.7941\n",
      "Epoch 2890/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4414 - binary_accuracy: 0.8366 - val_loss: 0.5460 - val_binary_accuracy: 0.7941\n",
      "Epoch 2891/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4414 - binary_accuracy: 0.8366 - val_loss: 0.5460 - val_binary_accuracy: 0.7941\n",
      "Epoch 2892/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4414 - binary_accuracy: 0.8366 - val_loss: 0.5460 - val_binary_accuracy: 0.7946\n",
      "Epoch 2893/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4414 - binary_accuracy: 0.8364 - val_loss: 0.5460 - val_binary_accuracy: 0.7936\n",
      "Epoch 2894/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4414 - binary_accuracy: 0.8366 - val_loss: 0.5460 - val_binary_accuracy: 0.7941\n",
      "Epoch 2895/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4414 - binary_accuracy: 0.8371 - val_loss: 0.5460 - val_binary_accuracy: 0.7941\n",
      "Epoch 2896/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4414 - binary_accuracy: 0.8371 - val_loss: 0.5460 - val_binary_accuracy: 0.7941\n",
      "Epoch 2897/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4414 - binary_accuracy: 0.8371 - val_loss: 0.5460 - val_binary_accuracy: 0.7941\n",
      "Epoch 2898/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4414 - binary_accuracy: 0.8367 - val_loss: 0.5460 - val_binary_accuracy: 0.7946\n",
      "Epoch 2899/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4414 - binary_accuracy: 0.8369 - val_loss: 0.5460 - val_binary_accuracy: 0.7952\n",
      "Epoch 2900/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4414 - binary_accuracy: 0.8366 - val_loss: 0.5460 - val_binary_accuracy: 0.7952\n",
      "Epoch 2901/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4414 - binary_accuracy: 0.8364 - val_loss: 0.5460 - val_binary_accuracy: 0.7952\n",
      "Epoch 2902/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4414 - binary_accuracy: 0.8364 - val_loss: 0.5460 - val_binary_accuracy: 0.7952\n",
      "Epoch 2903/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4414 - binary_accuracy: 0.8367 - val_loss: 0.5460 - val_binary_accuracy: 0.7952\n",
      "Epoch 2904/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4414 - binary_accuracy: 0.8367 - val_loss: 0.5460 - val_binary_accuracy: 0.7946\n",
      "Epoch 2905/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4414 - binary_accuracy: 0.8371 - val_loss: 0.5460 - val_binary_accuracy: 0.7946\n",
      "Epoch 2906/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4414 - binary_accuracy: 0.8376 - val_loss: 0.5460 - val_binary_accuracy: 0.7946\n",
      "Epoch 2907/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4414 - binary_accuracy: 0.8374 - val_loss: 0.5460 - val_binary_accuracy: 0.7946\n",
      "Epoch 2908/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4414 - binary_accuracy: 0.8373 - val_loss: 0.5460 - val_binary_accuracy: 0.7952\n",
      "Epoch 2909/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4414 - binary_accuracy: 0.8371 - val_loss: 0.5461 - val_binary_accuracy: 0.7946\n",
      "Epoch 2910/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4414 - binary_accuracy: 0.8376 - val_loss: 0.5461 - val_binary_accuracy: 0.7952\n",
      "Epoch 2911/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4414 - binary_accuracy: 0.8380 - val_loss: 0.5461 - val_binary_accuracy: 0.7952\n",
      "Epoch 2912/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4414 - binary_accuracy: 0.8374 - val_loss: 0.5461 - val_binary_accuracy: 0.7952\n",
      "Epoch 2913/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4413 - binary_accuracy: 0.8373 - val_loss: 0.5461 - val_binary_accuracy: 0.7952\n",
      "Epoch 2914/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4413 - binary_accuracy: 0.8373 - val_loss: 0.5462 - val_binary_accuracy: 0.7952\n",
      "Epoch 2915/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4413 - binary_accuracy: 0.8376 - val_loss: 0.5462 - val_binary_accuracy: 0.7952\n",
      "Epoch 2916/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4413 - binary_accuracy: 0.8378 - val_loss: 0.5463 - val_binary_accuracy: 0.7941\n",
      "Epoch 2917/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4413 - binary_accuracy: 0.8374 - val_loss: 0.5463 - val_binary_accuracy: 0.7952\n",
      "Epoch 2918/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4413 - binary_accuracy: 0.8373 - val_loss: 0.5463 - val_binary_accuracy: 0.7941\n",
      "Epoch 2919/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4413 - binary_accuracy: 0.8380 - val_loss: 0.5463 - val_binary_accuracy: 0.7952\n",
      "Epoch 2920/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4413 - binary_accuracy: 0.8378 - val_loss: 0.5463 - val_binary_accuracy: 0.7952\n",
      "Epoch 2921/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4413 - binary_accuracy: 0.8380 - val_loss: 0.5463 - val_binary_accuracy: 0.7952\n",
      "Epoch 2922/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4413 - binary_accuracy: 0.8376 - val_loss: 0.5463 - val_binary_accuracy: 0.7946\n",
      "Epoch 2923/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4413 - binary_accuracy: 0.8378 - val_loss: 0.5463 - val_binary_accuracy: 0.7946\n",
      "Epoch 2924/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4413 - binary_accuracy: 0.8382 - val_loss: 0.5463 - val_binary_accuracy: 0.7946\n",
      "Epoch 2925/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4413 - binary_accuracy: 0.8378 - val_loss: 0.5463 - val_binary_accuracy: 0.7952\n",
      "Epoch 2926/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4413 - binary_accuracy: 0.8376 - val_loss: 0.5464 - val_binary_accuracy: 0.7952\n",
      "Epoch 2927/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4413 - binary_accuracy: 0.8382 - val_loss: 0.5464 - val_binary_accuracy: 0.7946\n",
      "Epoch 2928/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4413 - binary_accuracy: 0.8380 - val_loss: 0.5464 - val_binary_accuracy: 0.7952\n",
      "Epoch 2929/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4413 - binary_accuracy: 0.8380 - val_loss: 0.5464 - val_binary_accuracy: 0.7952\n",
      "Epoch 2930/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4413 - binary_accuracy: 0.8383 - val_loss: 0.5464 - val_binary_accuracy: 0.7952\n",
      "Epoch 2931/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4413 - binary_accuracy: 0.8383 - val_loss: 0.5464 - val_binary_accuracy: 0.7952\n",
      "Epoch 2932/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4413 - binary_accuracy: 0.8383 - val_loss: 0.5464 - val_binary_accuracy: 0.7952\n",
      "Epoch 2933/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4413 - binary_accuracy: 0.8383 - val_loss: 0.5465 - val_binary_accuracy: 0.7946\n",
      "Epoch 2934/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4413 - binary_accuracy: 0.8382 - val_loss: 0.5465 - val_binary_accuracy: 0.7941\n",
      "Epoch 2935/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4413 - binary_accuracy: 0.8378 - val_loss: 0.5464 - val_binary_accuracy: 0.7946\n",
      "Epoch 2936/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4413 - binary_accuracy: 0.8378 - val_loss: 0.5465 - val_binary_accuracy: 0.7946\n",
      "Epoch 2937/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4413 - binary_accuracy: 0.8382 - val_loss: 0.5465 - val_binary_accuracy: 0.7946\n",
      "Epoch 2938/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4413 - binary_accuracy: 0.8380 - val_loss: 0.5465 - val_binary_accuracy: 0.7946\n",
      "Epoch 2939/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4413 - binary_accuracy: 0.8383 - val_loss: 0.5465 - val_binary_accuracy: 0.7946\n",
      "Epoch 2940/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4413 - binary_accuracy: 0.8383 - val_loss: 0.5465 - val_binary_accuracy: 0.7946\n",
      "Epoch 2941/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4413 - binary_accuracy: 0.8385 - val_loss: 0.5465 - val_binary_accuracy: 0.7941\n",
      "Epoch 2942/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4412 - binary_accuracy: 0.8383 - val_loss: 0.5465 - val_binary_accuracy: 0.7941\n",
      "Epoch 2943/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4412 - binary_accuracy: 0.8376 - val_loss: 0.5465 - val_binary_accuracy: 0.7941\n",
      "Epoch 2944/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4413 - binary_accuracy: 0.8380 - val_loss: 0.5466 - val_binary_accuracy: 0.7936\n",
      "Epoch 2945/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4412 - binary_accuracy: 0.8378 - val_loss: 0.5466 - val_binary_accuracy: 0.7941\n",
      "Epoch 2946/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4412 - binary_accuracy: 0.8378 - val_loss: 0.5466 - val_binary_accuracy: 0.7941\n",
      "Epoch 2947/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4412 - binary_accuracy: 0.8376 - val_loss: 0.5466 - val_binary_accuracy: 0.7946\n",
      "Epoch 2948/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4412 - binary_accuracy: 0.8376 - val_loss: 0.5466 - val_binary_accuracy: 0.7946\n",
      "Epoch 2949/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4412 - binary_accuracy: 0.8378 - val_loss: 0.5466 - val_binary_accuracy: 0.7936\n",
      "Epoch 2950/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4412 - binary_accuracy: 0.8380 - val_loss: 0.5466 - val_binary_accuracy: 0.7941\n",
      "Epoch 2951/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4412 - binary_accuracy: 0.8378 - val_loss: 0.5466 - val_binary_accuracy: 0.7936\n",
      "Epoch 2952/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4412 - binary_accuracy: 0.8378 - val_loss: 0.5466 - val_binary_accuracy: 0.7936\n",
      "Epoch 2953/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4412 - binary_accuracy: 0.8376 - val_loss: 0.5466 - val_binary_accuracy: 0.7936\n",
      "Epoch 2954/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4412 - binary_accuracy: 0.8373 - val_loss: 0.5466 - val_binary_accuracy: 0.7931\n",
      "Epoch 2955/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4412 - binary_accuracy: 0.8374 - val_loss: 0.5467 - val_binary_accuracy: 0.7936\n",
      "Epoch 2956/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4412 - binary_accuracy: 0.8374 - val_loss: 0.5467 - val_binary_accuracy: 0.7931\n",
      "Epoch 2957/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4412 - binary_accuracy: 0.8373 - val_loss: 0.5467 - val_binary_accuracy: 0.7925\n",
      "Epoch 2958/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4412 - binary_accuracy: 0.8374 - val_loss: 0.5467 - val_binary_accuracy: 0.7931\n",
      "Epoch 2959/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4412 - binary_accuracy: 0.8374 - val_loss: 0.5468 - val_binary_accuracy: 0.7931\n",
      "Epoch 2960/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4412 - binary_accuracy: 0.8373 - val_loss: 0.5468 - val_binary_accuracy: 0.7936\n",
      "Epoch 2961/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4412 - binary_accuracy: 0.8373 - val_loss: 0.5468 - val_binary_accuracy: 0.7931\n",
      "Epoch 2962/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4412 - binary_accuracy: 0.8374 - val_loss: 0.5469 - val_binary_accuracy: 0.7936\n",
      "Epoch 2963/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4412 - binary_accuracy: 0.8378 - val_loss: 0.5469 - val_binary_accuracy: 0.7936\n",
      "Epoch 2964/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4412 - binary_accuracy: 0.8382 - val_loss: 0.5469 - val_binary_accuracy: 0.7941\n",
      "Epoch 2965/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4412 - binary_accuracy: 0.8383 - val_loss: 0.5469 - val_binary_accuracy: 0.7941\n",
      "Epoch 2966/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4412 - binary_accuracy: 0.8387 - val_loss: 0.5470 - val_binary_accuracy: 0.7936\n",
      "Epoch 2967/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4412 - binary_accuracy: 0.8389 - val_loss: 0.5470 - val_binary_accuracy: 0.7936\n",
      "Epoch 2968/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4412 - binary_accuracy: 0.8389 - val_loss: 0.5470 - val_binary_accuracy: 0.7936\n",
      "Epoch 2969/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4412 - binary_accuracy: 0.8389 - val_loss: 0.5471 - val_binary_accuracy: 0.7936\n",
      "Epoch 2970/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4412 - binary_accuracy: 0.8389 - val_loss: 0.5471 - val_binary_accuracy: 0.7936\n",
      "Epoch 2971/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4412 - binary_accuracy: 0.8389 - val_loss: 0.5471 - val_binary_accuracy: 0.7936\n",
      "Epoch 2972/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4412 - binary_accuracy: 0.8389 - val_loss: 0.5471 - val_binary_accuracy: 0.7936\n",
      "Epoch 2973/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4412 - binary_accuracy: 0.8389 - val_loss: 0.5471 - val_binary_accuracy: 0.7936\n",
      "Epoch 2974/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4411 - binary_accuracy: 0.8385 - val_loss: 0.5471 - val_binary_accuracy: 0.7936\n",
      "Epoch 2975/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4411 - binary_accuracy: 0.8387 - val_loss: 0.5471 - val_binary_accuracy: 0.7936\n",
      "Epoch 2976/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4411 - binary_accuracy: 0.8387 - val_loss: 0.5471 - val_binary_accuracy: 0.7931\n",
      "Epoch 2977/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4411 - binary_accuracy: 0.8387 - val_loss: 0.5471 - val_binary_accuracy: 0.7931\n",
      "Epoch 2978/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4411 - binary_accuracy: 0.8385 - val_loss: 0.5471 - val_binary_accuracy: 0.7931\n",
      "Epoch 2979/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4411 - binary_accuracy: 0.8385 - val_loss: 0.5471 - val_binary_accuracy: 0.7931\n",
      "Epoch 2980/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4411 - binary_accuracy: 0.8385 - val_loss: 0.5471 - val_binary_accuracy: 0.7931\n",
      "Epoch 2981/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4411 - binary_accuracy: 0.8385 - val_loss: 0.5471 - val_binary_accuracy: 0.7931\n",
      "Epoch 2982/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4411 - binary_accuracy: 0.8387 - val_loss: 0.5471 - val_binary_accuracy: 0.7931\n",
      "Epoch 2983/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4411 - binary_accuracy: 0.8387 - val_loss: 0.5471 - val_binary_accuracy: 0.7931\n",
      "Epoch 2984/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4411 - binary_accuracy: 0.8389 - val_loss: 0.5472 - val_binary_accuracy: 0.7931\n",
      "Epoch 2985/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4411 - binary_accuracy: 0.8387 - val_loss: 0.5472 - val_binary_accuracy: 0.7936\n",
      "Epoch 2986/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4411 - binary_accuracy: 0.8390 - val_loss: 0.5473 - val_binary_accuracy: 0.7936\n",
      "Epoch 2987/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4411 - binary_accuracy: 0.8390 - val_loss: 0.5472 - val_binary_accuracy: 0.7936\n",
      "Epoch 2988/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4411 - binary_accuracy: 0.8389 - val_loss: 0.5473 - val_binary_accuracy: 0.7936\n",
      "Epoch 2989/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4411 - binary_accuracy: 0.8390 - val_loss: 0.5473 - val_binary_accuracy: 0.7936\n",
      "Epoch 2990/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4411 - binary_accuracy: 0.8390 - val_loss: 0.5473 - val_binary_accuracy: 0.7936\n",
      "Epoch 2991/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4411 - binary_accuracy: 0.8387 - val_loss: 0.5473 - val_binary_accuracy: 0.7936\n",
      "Epoch 2992/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4411 - binary_accuracy: 0.8387 - val_loss: 0.5473 - val_binary_accuracy: 0.7936\n",
      "Epoch 2993/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4411 - binary_accuracy: 0.8389 - val_loss: 0.5473 - val_binary_accuracy: 0.7936\n",
      "Epoch 2994/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4411 - binary_accuracy: 0.8389 - val_loss: 0.5473 - val_binary_accuracy: 0.7936\n",
      "Epoch 2995/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4411 - binary_accuracy: 0.8387 - val_loss: 0.5472 - val_binary_accuracy: 0.7936\n",
      "Epoch 2996/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4411 - binary_accuracy: 0.8389 - val_loss: 0.5472 - val_binary_accuracy: 0.7936\n",
      "Epoch 2997/3000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4411 - binary_accuracy: 0.8389 - val_loss: 0.5471 - val_binary_accuracy: 0.7931\n",
      "Epoch 2998/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4411 - binary_accuracy: 0.8387 - val_loss: 0.5471 - val_binary_accuracy: 0.7936\n",
      "Epoch 2999/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4411 - binary_accuracy: 0.8387 - val_loss: 0.5471 - val_binary_accuracy: 0.7936\n",
      "Epoch 3000/3000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4411 - binary_accuracy: 0.8385 - val_loss: 0.5471 - val_binary_accuracy: 0.7936\n",
      "179/179 [==============================] - 0s 377us/step\n",
      "60/60 [==============================] - 0s 354us/step\n",
      "F1-score: 0.7617801047120418\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# input dimensions\n",
    "D = X_train.shape[1]\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape=(D,), kernel_regularizer=L2(l2=0.003), bias_regularizer=L2(l2=0.003)),\n",
    "    tf.keras.layers.Dense(1, input_shape=(D,), kernel_regularizer=L2(l2=0.003), bias_regularizer=L2(l2=0.03)),\n",
    "    # tf.keras.layers.Dense(4, kernel_regularizer=L2(l2=0.01), bias_regularizer='l2', input_shape=(D,), activation='relu'),\n",
    "    # tf.keras.layers.Dense(2, kernel_regularizer=L2(l2=0.01), bias_regularizer='l2', input_shape=(D,), activation='relu'),\n",
    "    # tf.keras.layers.Dense(1, activation='softmax'),\n",
    "])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(\n",
    "  loss=BinaryCrossentropy(from_logits=True),\n",
    "  optimizer=Adam(learning_rate=0.0001),\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "r = model.fit(\n",
    "  X_train, Y_train,\n",
    "  validation_data=(X_test, Y_test),\n",
    "  epochs=3000,\n",
    "  batch_size=512,\n",
    ")\n",
    "\n",
    "# Plot loss per iteration\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend();\n",
    "\n",
    "# Plot accuracy per iteration\n",
    "plt.plot(r.history['binary_accuracy'], label='train acc')\n",
    "plt.plot(r.history['val_binary_accuracy'], label='val acc')\n",
    "plt.legend();\n",
    "\n",
    "# Test\n",
    "P_train = ((model.predict(X_train) > 0) * 1.0).flatten()\n",
    "P_test = ((model.predict(X_test) > 0) * 1.0).flatten()\n",
    "\n",
    "print('F1-score:', f1_score(Y_test, P_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2d994ed10>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_train = confusion_matrix(Y_train, P_train, normalize='true')\n",
    "disp_train = ConfusionMatrixDisplay(confusion_matrix=cm_train, display_labels=['neutral', 'disaster'])\n",
    "disp_train.plot()\n",
    "cm_test = confusion_matrix(Y_test, P_test, normalize='true')\n",
    "disp_test = ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=['neutral', 'disaster'])\n",
    "disp_test.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_csv('../../datasets/disaster_tweets/test.csv')\n",
    "X_r = vectorizer.transform(df_results['text'])\n",
    "X_r = X_r.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 374us/step\n"
     ]
    }
   ],
   "source": [
    "P_r = ((model.predict(X_r) > 0) * 1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       0\n",
       "4  11       1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = df_results[['id']]\n",
    "results.insert(1, 'target', P_r)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"./disaster_predictions.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use BERT and HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clement/anaconda3/envs/gpu/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoTokenizer, AutoConfig, TrainingArguments, AutoModelForSequenceClassification, Trainer, pipeline\n",
    "from torchinfo import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from torchinfo import summary\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../../datasets/disaster_tweets/train.csv')\n",
    "df_train = df_train[['text', 'target']]\n",
    "df_train = df_train.rename(columns={\"target\": \"label\", 'text':'sentence'})\n",
    "df_train.to_csv('../../datasets/disaster_tweets/BERT_train.csv', index=None)\n",
    "\n",
    "df_test = pd.read_csv('../../datasets/disaster_tweets/test.csv')\n",
    "df_test = df_test[['text']]\n",
    "df_test = df_test.rename(columns={'text':'sentence'})\n",
    "df_test.to_csv('../../datasets/disaster_tweets/BERT_test.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 9020.01it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 710.54it/s]\n",
      "Generating train split: 0 examples [00:00, ? examples/s]/Users/clement/anaconda3/envs/gpu/lib/python3.9/site-packages/pyarrow/pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n",
      "Generating train split: 7613 examples [00:00, 450955.21 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset('csv', data_files='../../datasets/disaster_tweets/BERT_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 7613\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = train_dataset['train'].train_test_split(test_size=0.1, seed=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 15.5kB/s]\n",
      "config.json: 100%|██████████| 571/571 [00:00<00:00, 1.86MB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 2.37MB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 9.50MB/s]\n"
     ]
    }
   ],
   "source": [
    "checkpoint = 'bert-large-uncased' #'distilbert-base-cased'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6851/6851 [00:00<00:00, 42719.10 examples/s]\n",
      "Map: 100%|██████████| 762/762 [00:00<00:00, 48393.62 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_fn(batch):\n",
    "  return tokenizer(batch['sentence'], truncation=True)\n",
    "\n",
    "tokenized_datasets = split.map(tokenize_fn, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'other', 1: 'disaster'}\n",
      "{'other': 0, 'disaster': 1}\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(checkpoint)\n",
    "target_map = {'other': 0, 'disaster': 1}\n",
    "config.id2label = {v:k for k, v in target_map.items()}\n",
    "config.label2id = target_map\n",
    "print(config.id2label)\n",
    "print(config.label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 1.34G/1.34G [02:54<00:00, 7.69MB/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "BertForSequenceClassification                           --\n",
       "├─BertModel: 1-1                                        --\n",
       "│    └─BertEmbeddings: 2-1                              --\n",
       "│    │    └─Embedding: 3-1                              31,254,528\n",
       "│    │    └─Embedding: 3-2                              524,288\n",
       "│    │    └─Embedding: 3-3                              2,048\n",
       "│    │    └─LayerNorm: 3-4                              2,048\n",
       "│    │    └─Dropout: 3-5                                --\n",
       "│    └─BertEncoder: 2-2                                 --\n",
       "│    │    └─ModuleList: 3-6                             302,309,376\n",
       "│    └─BertPooler: 2-3                                  --\n",
       "│    │    └─Linear: 3-7                                 1,049,600\n",
       "│    │    └─Tanh: 3-8                                   --\n",
       "├─Dropout: 1-2                                          --\n",
       "├─Linear: 1-3                                           2,050\n",
       "================================================================================\n",
       "Total params: 335,143,938\n",
       "Trainable params: 335,143,938\n",
       "Non-trainable params: 0\n",
       "================================================================================"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 20%|██        | 429/2145 [03:49<13:44,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.48177939653396606, 'eval_accuracy': 0.8083989501312336, 'eval_f1': 0.7997912467607255, 'eval_runtime': 5.5239, 'eval_samples_per_second': 137.946, 'eval_steps_per_second': 2.172, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 500/2145 [04:29<13:34,  2.02it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4313, 'learning_rate': 3.834498834498835e-05, 'epoch': 1.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 40%|████      | 858/2145 [07:49<10:22,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5405387282371521, 'eval_accuracy': 0.800524934383202, 'eval_f1': 0.7917987877219095, 'eval_runtime': 6.3385, 'eval_samples_per_second': 120.218, 'eval_steps_per_second': 1.893, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1000/2145 [09:12<10:20,  1.84it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4909, 'learning_rate': 2.6689976689976692e-05, 'epoch': 2.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 60%|██████    | 1287/2145 [12:00<06:47,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5091909766197205, 'eval_accuracy': 0.7979002624671916, 'eval_f1': 0.7870504119333648, 'eval_runtime': 6.3177, 'eval_samples_per_second': 120.614, 'eval_steps_per_second': 1.899, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 1338/2145 [12:32<08:43,  1.54it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 26\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m: acc, \u001b[39m'\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m'\u001b[39m: f1}\n\u001b[1;32m     17\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     18\u001b[0m     model,\n\u001b[1;32m     19\u001b[0m     training_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     compute_metrics\u001b[39m=\u001b[39mcompute_metrics,\n\u001b[1;32m     24\u001b[0m )\n\u001b[0;32m---> 26\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/anaconda3/envs/gpu/lib/python3.9/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1556\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1557\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1558\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1559\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1560\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/gpu/lib/python3.9/site-packages/transformers/trainer.py:1837\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1834\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m   1836\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1837\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1839\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1840\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1841\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1842\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1843\u001b[0m ):\n\u001b[1;32m   1844\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1845\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/anaconda3/envs/gpu/lib/python3.9/site-packages/transformers/trainer.py:2693\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         scaled_loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m   2692\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2693\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccelerator\u001b[39m.\u001b[39;49mbackward(loss)\n\u001b[1;32m   2695\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mdetach() \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m~/anaconda3/envs/gpu/lib/python3.9/site-packages/accelerate/accelerator.py:1989\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1987\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mscale(loss)\u001b[39m.\u001b[39mbackward(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1988\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1989\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/gpu/lib/python3.9/site-packages/torch/_tensor.py:505\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    497\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    498\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    503\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    504\u001b[0m     )\n\u001b[0;32m--> 505\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    506\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    507\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/gpu/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m     tensors,\n\u001b[1;32m    268\u001b[0m     grad_tensors_,\n\u001b[1;32m    269\u001b[0m     retain_graph,\n\u001b[1;32m    270\u001b[0m     create_graph,\n\u001b[1;32m    271\u001b[0m     inputs,\n\u001b[1;32m    272\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    273\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    274\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "  output_dir='disaster_prediction_trainer',\n",
    "  evaluation_strategy='epoch',\n",
    "  save_strategy='epoch',\n",
    "  num_train_epochs=5,\n",
    "  per_device_train_batch_size=16,\n",
    "  per_device_eval_batch_size=64,\n",
    ")\n",
    "\n",
    "def compute_metrics(logits_and_labels):\n",
    "  logits, labels = logits_and_labels\n",
    "  predictions = np.argmax(logits, axis=-1)\n",
    "  acc = np.mean(predictions == labels)\n",
    "  f1 = f1_score(labels, predictions, average='macro')\n",
    "  return {'accuracy': acc, 'f1': f1}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We take the best model from the best f1-score epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_model = pipeline('text-classification',\n",
    "                      model='disaster_prediction_trainer/checkpoint-1287',\n",
    "                      device='mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = disaster_model(split['test']['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'disaster', 'score': 0.9710727334022522},\n",
       " {'label': 'other', 'score': 0.8660871386528015},\n",
       " {'label': 'disaster', 'score': 0.9649932384490967}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = [d['label'] for d in test_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['disaster', 'other', 'disaster']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels = [config.id2label[x] for x in split['test']['label']]\n",
    "test_labels[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8451443569553806\n",
      "f1-score: 0.8364176193629609\n"
     ]
    }
   ],
   "source": [
    "print(\"acc:\", accuracy_score(test_labels, test_pred))\n",
    "print(\"f1-score:\", f1_score(test_labels, test_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2f7776580>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(test_labels, test_pred, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['other', 'disaster'])\n",
    "disp.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 7002.18it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 515.46it/s]\n",
      "Generating train split: 0 examples [00:00, ? examples/s]/Users/clement/anaconda3/envs/gpu/lib/python3.9/site-packages/pyarrow/pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n",
      "Generating train split: 3263 examples [00:00, 330500.22 examples/s]\n"
     ]
    }
   ],
   "source": [
    "eval_data = load_dataset('csv', data_files='../../datasets/disaster_tweets/BERT_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence'],\n",
       "        num_rows: 3263\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pred = disaster_model(eval_data['train']['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_pred = [config.label2id[d['label']] for d in eval_pred]\n",
    "eval_pred[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       1\n",
       "4  11       1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.read_csv('../../datasets/disaster_tweets/test.csv')\n",
    "results = df_results[['id']]\n",
    "results.insert(1, 'target', eval_pred)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"./disaster_predictions_BERT.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
